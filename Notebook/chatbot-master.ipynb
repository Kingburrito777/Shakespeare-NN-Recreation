{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2881: FutureWarning: \n",
      "mpl_style had been deprecated and will be removed in a future version.\n",
      "Use `matplotlib.pyplot.style.use` instead.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# RaNDOM\n",
    "import random\n",
    "#clock training time\n",
    "import datetime \n",
    "# Numpy for vectorization\n",
    "import numpy as np\n",
    "# Tensorflow for ML\n",
    "import tensorflow as tf\n",
    "# Pandas for file reading/ visualize data\n",
    "import pandas as pd\n",
    "# Seaborn as the great data visualizer\n",
    "import seaborn as sns\n",
    "#Matplot to visualize data, also Seaborn and pandas do this\n",
    "import matplotlib.pyplot as plt\n",
    "# Inline to show images in jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Set number of columns to show in the notebook\n",
    "pd.set_option('display.max_columns', 600)\n",
    "# Set number of rows to show in the notebook\n",
    "pd.set_option('display.max_rows', 50)\n",
    "# Make the graphs a bit prettier\n",
    "pd.set_option('display.mpl_style', 'default') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab the shakespeare data\n",
    "allData = pd.read_csv('../Data/Shakespeare_data.csv', sep=',')\n",
    "allData.columns = [\"Dataline\",\"Play\",\"PlayerLinenumber\",\"ActSceneLine\",\"Player\",\"PlayerLine\"]\n",
    "allData = list(allData.PlayerLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length in number of characters: 4254892\n"
     ]
    }
   ],
   "source": [
    "# Converting the dataframe to a single string\n",
    "textLines = ''.join(allData)\n",
    "print('text length in number of characters:', len(textLines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters: 76\n",
      "['\\t', ' ', '!', '$', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(textLines)))\n",
    "char_size = len(chars)\n",
    "print('number of characters:', char_size)\n",
    "print(chars)\n",
    "# print(textLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "char2id = dict((c, i) for i, c in enumerate(chars))\n",
    "id2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Given a probability of each character, return a likely character, one-hot encoded\n",
    "def sample(prediction):\n",
    "    r = random.uniform(0,1)\n",
    "    s = 0\n",
    "    char_id = len(prediction) - 1\n",
    "    for i in range(len(prediction)):\n",
    "        s += prediction[i]\n",
    "        if s >= r:\n",
    "            char_id = i\n",
    "            break\n",
    "    char_one_hot = np.zeros(shape=[char_size])\n",
    "    char_one_hot[char_id] = 1.0\n",
    "    return char_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850976 15 76\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#vectorize our data to feed it into model\n",
    "\n",
    "len_per_section = 15\n",
    "skip = 5\n",
    "sections = []\n",
    "next_chars = []\n",
    "#fill sections list with chunks of text, every 10 characters create a new 20 \n",
    "#character long section\n",
    "#because we are generating it at a character level\n",
    "for i in range(0, len(textLines) - len_per_section, skip):\n",
    "    sections.append(textLines[i: i + len_per_section])\n",
    "    next_chars.append(textLines[i + len_per_section])\n",
    "    \n",
    "print(len(sections), len_per_section, char_size)\n",
    "    \n",
    "#Vectorize input and output\n",
    "#matrix of section length by num of characters\n",
    "X = np.zeros((len(sections), len_per_section, char_size))\n",
    "#label column for all the character id's, still zero\n",
    "y = np.zeros((len(sections), char_size))\n",
    "#for each char in each section, convert each char to an ID\n",
    "#for each section convert the labels to ids \n",
    "for i, section in enumerate(sections):\n",
    "    for j, char in enumerate(section):\n",
    "        X[i, j, char2id[char]] = 1\n",
    "    y[i, char2id[next_chars[i]]] = 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 850976\n",
      "approximate steps per epoch: 1662\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "max_steps = 50000\n",
    "log_every = 30\n",
    "test_every = 50\n",
    "hidden_nodes = 1024\n",
    "test_start = 'Lord'\n",
    "checkpoint_directory = 'ckpt'\n",
    "\n",
    "#Create a checkpoint directory\n",
    "if tf.gfile.Exists(checkpoint_directory):\n",
    "    tf.gfile.DeleteRecursively(checkpoint_directory)\n",
    "tf.gfile.MakeDirs(checkpoint_directory)\n",
    "\n",
    "print('training data size:', len(X))\n",
    "print('approximate steps per epoch:', int(len(X)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#build our model time\n",
    "#create computation graph\n",
    "graph = tf.Graph()\n",
    "#if multiple graphs, but none here jsut one\n",
    "with graph.as_default():\n",
    "    ###########\n",
    "    #Prep\n",
    "    ###########\n",
    "    #Variables and placeholders\n",
    "    #global_step refer to the number of batches seen by the graph. \n",
    "    #Everytime a batch is provided, the weights are updated in the \n",
    "    #direction that minimizes the loss. global_step just keeps track \n",
    "    #of the number of batches seen so far starts off as 0\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    #data tensor shape feeding in sections\n",
    "    data = tf.placeholder(tf.float32, [batch_size, len_per_section, char_size])\n",
    "    #labels\n",
    "    labels = tf.placeholder(tf.float32, [batch_size, char_size])\n",
    "    \n",
    "    #An LSTM RNN (Long Short Term Memory), consists of 3 gates and an internal state, \n",
    "    #This enables the LSTM to capture long-term dependencies. \n",
    "    #http://suriyadeepan.github.io/2017-02-13-unfolding-rnn-2/\n",
    "    #lets build weights and biases for each of the 3 gates and then for the cell state\n",
    "    \n",
    "    #tf variables\n",
    "    #Since we need the weights and biases for our model. \n",
    "    #We could imagine treating these like additional inputs, \n",
    "    #but TensorFlow has an even better way to handle it: Variable\n",
    "    #A Variable is a modifiable tensor that lives in TensorFlow's graph of \n",
    "    #interacting operations. It can be used and even modified by the computation. \n",
    "    #For machine learning applications, one generally has the model parameters be Variables.\n",
    "    \n",
    "    #Prep LSTM Operation\n",
    "    #Input gate: weights for input, weights for previous output, and bias\n",
    "    \n",
    "    #tf truncated normal\n",
    "    #Outputs random values from a truncated normal distribution.\n",
    "    #The generated values follow a normal distribution with specified mean and \n",
    "    #standard deviation, except that values whose magnitude is more than 2 standard deviations\n",
    "    #from the mean are dropped and re-picked.\n",
    "    #basically randomly initialized values here\n",
    "    \n",
    "    #biases act as an anchor\n",
    "\n",
    "    w_ii = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_io = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_i = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Forget gate: weights for input, weights for previous output, and bias\n",
    "    w_fi = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_fo = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_f = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Output gate: weights for input, weights for previous output, and bias\n",
    "    w_oi = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_oo = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_o = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Memory cell: weights for input, weights for previous output, and bias\n",
    "    w_ci = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_co = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_c = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    \n",
    "    \n",
    "    #LSTM Cell\n",
    "    # given input, output, external state, it will return output and state\n",
    "    #output starts off empty, LSTM cell calculates it\n",
    "    \n",
    "    #Since, we have two kinds of states - the internal state ct \n",
    "    #and the (exposed) external state st, and since we need both of \n",
    "    #them for the subsequent sequential operations, we combine them \n",
    "    #into a tensor at each step, and pass them as input to the next \n",
    "    #step. This tensor is unpacked into st_1 and ct_1 at the beginning of each step.\n",
    "    \n",
    "    \n",
    "    def lstm(i, o, state):\n",
    "        \n",
    "        #these are all calculated seperately, no overlap until....\n",
    "        #(input * input weights) + (output * weights for previous output) + bias\n",
    "        input_gate = tf.sigmoid(tf.matmul(i, w_ii) + tf.matmul(o, w_io) + b_i)\n",
    "        #(input * forget weights) + (output * weights for previous output) + bias\n",
    "        forget_gate = tf.sigmoid(tf.matmul(i, w_fi) + tf.matmul(o, w_fo) + b_f)\n",
    "        #(input * output weights) + (output * weights for previous output) + bias\n",
    "        output_gate = tf.sigmoid(tf.matmul(i, w_oi) + tf.matmul(o, w_oo) + b_o)\n",
    "        #(input * internal state weights) + (output * weights for previous output) + bias\n",
    "        memory_cell = tf.sigmoid(tf.matmul(i, w_ci) + tf.matmul(o, w_co) + b_c)\n",
    "        \n",
    "        #...now! multiply forget gate * given state    +  input gate * hidden state\n",
    "        state = forget_gate * state + input_gate * memory_cell\n",
    "        #squash that state with tanh nonlin (Computes hyperbolic tangent of x element-wise)\n",
    "        #multiply by output\n",
    "        output = output_gate * tf.tanh(state)\n",
    "        #return \n",
    "        return output, state\n",
    "    \n",
    "    ###########\n",
    "    #Operation\n",
    "    ###########\n",
    "    #LSTM\n",
    "    #both start off as empty, LSTM will calculate this\n",
    "    output = tf.zeros([batch_size, hidden_nodes])\n",
    "    state = tf.zeros([batch_size, hidden_nodes])\n",
    "\n",
    "    #unrolled LSTM loop\n",
    "    #for each input set\n",
    "    for i in range(len_per_section):\n",
    "        #calculate state and output from LSTM\n",
    "        output, state = lstm(data[:, i, :], output, state)\n",
    "        #to start, \n",
    "        if i == 0:\n",
    "            #store initial output and labels\n",
    "            outputs_all_i = output\n",
    "            labels_all_i = data[:, i+1, :]\n",
    "        #for each new set, concat outputs and labels\n",
    "        elif i != len_per_section - 1:\n",
    "            #concatenates (combines) vectors along a dimension axis, not multiply\n",
    "            outputs_all_i = tf.concat([outputs_all_i, output], 0)\n",
    "            labels_all_i = tf.concat([labels_all_i, data[:, i+1, :]], 0)\n",
    "        else:\n",
    "            #final store\n",
    "            outputs_all_i = tf.concat([outputs_all_i, output], 0)\n",
    "            labels_all_i = tf.concat([labels_all_i, labels], 0)\n",
    "        \n",
    "    #Classifier\n",
    "    #The Classifier will only run after saved_output and saved_state were assigned.\n",
    "    \n",
    "    #calculate weight and bias values for the network\n",
    "    #generated randomly given a size and distribution\n",
    "    w = tf.Variable(tf.truncated_normal([hidden_nodes, char_size], -0.1, 0.1))\n",
    "    b = tf.Variable(tf.zeros([char_size]))\n",
    "    #Logits simply means that the function operates on the unscaled output \n",
    "    #of earlier layers and that the relative scale to understand the units \n",
    "    #is linear. It means, in particular, the sum of the inputs may not equal 1, \n",
    "    #that the values are not probabilities (you might have an input of 5).\n",
    "    logits = tf.matmul(outputs_all_i, w) + b\n",
    "    \n",
    "    #logits is our prediction outputs, lets compare it with our labels\n",
    "    #cross entropy since multiclass classification\n",
    "    #computes the cost for a softmax layer\n",
    "    #then Computes the mean of elements across dimensions of a tensor.\n",
    "    #average loss across all values\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_all_i, logits=logits))\n",
    "\n",
    "    #Optimizer\n",
    "    #minimize loss with graident descent, learning rate 10,  keep track of batches\n",
    "    optimizer = tf.train.GradientDescentOptimizer(10.).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    ###########\n",
    "    #Test\n",
    "    ###########\n",
    "    test_data = tf.placeholder(tf.float32, shape=[1, char_size])\n",
    "    test_output = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    test_state = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    \n",
    "    #Reset at the beginning of each test\n",
    "    reset_test_state = tf.group(test_output.assign(tf.zeros([1, hidden_nodes])), \n",
    "                                test_state.assign(tf.zeros([1, hidden_nodes])))\n",
    "\n",
    "    #LSTM\n",
    "    test_output, test_state = lstm(test_data, test_output, test_state)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_output, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at step 0: 4.35 (2017-03-27 17:52:09.255947)\n",
      "================================================================================\n",
      "Lord                           o                                     n                           r                                                                    e h e                          e            e         e e                                                e                                          e  e                                          e                                                            e                       w                                                          \n",
      "================================================================================\n",
      "training loss at step 30: 3.33 (2017-03-27 17:52:15.577664)\n",
      "training loss at step 60: 3.22 (2017-03-27 17:52:18.523626)\n",
      "training loss at step 90: 3.44 (2017-03-27 17:52:21.464703)\n",
      "training loss at step 120: 3.08 (2017-03-27 17:52:24.469716)\n",
      "training loss at step 150: 3.09 (2017-03-27 17:52:27.421663)\n",
      "================================================================================\n",
      "Lordbpdeprrfmeeanff,eiwntvYyeeeeyorfis-dnhosuthvM,et,eoe,theeeemeerakoufsyanaieuasoOroo:atsuntanmod.hAerhe,rothPaAlrlo.ahe,hdefsttSicoofoeSumhrnnr,assptheayehielreneeerrsthfuieusseSewihsathegliheVceryheefyefieeehredrothopkorEvobsoeepanIwoferwthvfroTaplorDaithlrrerbtoeh,ainhherteIdrubmadehagergurGre,heeTeruaAorfnvefllueksleuhvyanricrohehebn'anvectdrnedooIoiothearefesnotR'twl:irBtntas l.SEsDrshhetebererelyoRowt.hloteteCeasdtheerrcsye,con'hfrhedoLerwthorwBegheaslhetenhheimsitrlihealdtteeahinddoterneco.\n",
      "================================================================================\n",
      "training loss at step 180: 3.08 (2017-03-27 17:52:42.089292)\n",
      "training loss at step 210: 3.11 (2017-03-27 17:52:45.042056)\n",
      "training loss at step 240: 3.13 (2017-03-27 17:52:47.982214)\n",
      "training loss at step 270: 2.88 (2017-03-27 17:52:54.343633)\n",
      "training loss at step 300: 2.94 (2017-03-27 17:52:57.296496)\n",
      "================================================================================\n",
      "Lord y 'enndnn'Lheareourantowhiporea cer, ngur plof the Ieledee theen, gMv nenthelthiuurthilrateneat thoran dd, thy cpiclaneoerudse, bheWhOunonsd thehe pis anled ?olfetheaopawicouaAonemerthentSde:nomereIcu:osiRe ltr ISIola?Dy se plaeinalt taSef inkictemtrthitharooc t?esd-o'erBSaEoLsiinanteyineh fosovoErnd suins foprrt hesn aysedmIn a.dts: nmBundPe wabcor, telindun, athomd f horeithyosayuros hathjobowatatudetedoecobukanpy tisuregEoourerealot Edtou, Mindan,emugotioraavea athiyrdinghons lmnnchofass, dS\n",
      "================================================================================\n",
      "training loss at step 330: 3.06 (2017-03-27 17:53:00.685637)\n",
      "training loss at step 360: 2.99 (2017-03-27 17:53:03.620502)\n",
      "training loss at step 390: 2.96 (2017-03-27 17:53:06.695146)\n",
      "training loss at step 420: 2.98 (2017-03-27 17:53:09.865805)\n",
      "training loss at step 450: 2.97 (2017-03-27 17:53:13.068345)\n",
      "================================================================================\n",
      "Lordnate auelototoux-h.eedloudsirs, tiycenocesimint, '-dNoterlecandallTenomnycel, wdFasimqeu,G!'akikod iLof.gedy,s, ti-ud molanoweounofeeTar terisoaAotegenthmakolo salk?.al'sesy warthaoselndjousangUthaithenoueroeTg,s Sospad sfibe..ereI!earWotes's k bthans,,:oghiSelnonthicohalanW-io.TaonrEoophareshlseripeBtek'hang Ihadedeath'theneronthilisfoneLgu, henilepa?ondowBelkentsirenrtI wuransengtesgaloume'sendowrSeTlo, ngznoten, re skowandrlethelyoumermetof toud Mte'iIeke , mbWN.,yowe thoxoF-, arenere'cuon-s,\n",
      "================================================================================\n",
      "training loss at step 480: 3.03 (2017-03-27 17:53:16.758453)\n",
      "training loss at step 510: 3.06 (2017-03-27 17:53:19.821173)\n",
      "training loss at step 540: 2.98 (2017-03-27 17:53:22.988692)\n",
      "training loss at step 570: 2.99 (2017-03-27 17:53:26.090733)\n",
      "training loss at step 600: 2.85 (2017-03-27 17:53:29.229631)\n",
      "================================================================================\n",
      "Lordindtheenkl, yisntheadindensorpefodqrylil,soredhato dveo unlerevekorr,Gvesear, aderabetheriseseratuthothesyouarserTiyshav misuns ghstre thoosatesetiimaresOanloundSiinodisanabesere maveaw, wouesowheandtaaUoveanyriane, entoraunond tvennenDtelyo.orooureBWunouBin.gweleledseegrtrr,, tithanouvadiCAogeiveAthe, mangsThalaclon poven athaMasarerenerorshe, deGorqor adallitiAseainocan, oang!ando follushceerelieaon teremaras outaorantharejh dithhintecanthatorbetkor G,ltokisdretondoprrnAWarenof b, lalende, uOo\n",
      "================================================================================\n",
      "training loss at step 630: 2.94 (2017-03-27 17:53:32.670550)\n",
      "training loss at step 660: 2.96 (2017-03-27 17:53:35.653950)\n",
      "training loss at step 690: 2.98 (2017-03-27 17:53:38.652356)\n",
      "training loss at step 720: 2.93 (2017-03-27 17:53:41.645828)\n",
      "training loss at step 750: 3.01 (2017-03-27 17:53:44.615090)\n",
      "================================================================================\n",
      "Lordevey,seawekallitono?, fuApadHeatil, wratorerwThourlonom,elere, yenereharut.w,eefNedupLksthanlethisreeand sct.hid warelatr foofofome:op'Recsan sour, hel.horndendarothaveat, he,rFsv!, nToker.perAndd lest, mmr,laryontiXe tlyor, eren htheleshoil, warimertiwete,,,.matbriserusaderlThercyeindsnshidMlwesourinelathayothangenond,Lrs stheakewaliedBer!Wtuyomend,!ste?woogerishor, tonened noweThePekerkCsltingind,Needidatil.ted,llfisutheSemathanthigpe nd aOicIrerya,Ht, h?se hiounou,nt'doureunder.sertasris,, t \n",
      "================================================================================\n",
      "training loss at step 780: 2.96 (2017-03-27 17:53:50.404190)\n",
      "training loss at step 810: 2.94 (2017-03-27 17:53:53.611506)\n",
      "training loss at step 840: 2.88 (2017-03-27 17:53:56.822457)\n",
      "training loss at step 870: 2.87 (2017-03-27 17:54:00.029683)\n",
      "training loss at step 900: 2.82 (2017-03-27 17:54:03.188719)\n",
      "================================================================================\n",
      "Lordvere, chenoustheyrs gdosees,reeMowhiserthot bitade gthensoElicreertrotowpteeaveofYmthesowA, hen:S,le yoraleroce?nesthanYe.?hatee,o Sshod honuvetWushoouthaissh,utheesOhes.owis t,cose ushedriPauchasrso!enor yosereeAwed hey thanorBeendpsy'eear, gtoutaburYfon inmr atond,:, wi,ingshegifsed vanedeocis the,d ateaLVouTLore?usenoleNu'reedithoreinonderyey, utersrtreaut gerdeeanouue'therth,h tal,riou thiove,y mees mllt, mhinenen. llue,Shos.ousan.Asy sounondce meWtitl.entheningissSeainore.Sas.tienor,thellfl\n",
      "================================================================================\n",
      "training loss at step 930: 2.96 (2017-03-27 17:54:06.833388)\n",
      "training loss at step 960: 2.91 (2017-03-27 17:54:09.976855)\n",
      "training loss at step 990: 2.94 (2017-03-27 17:54:13.115331)\n",
      "training loss at step 1020: 2.89 (2017-03-27 17:54:18.239014)\n",
      "training loss at step 1050: 2.82 (2017-03-27 17:54:21.201726)\n",
      "================================================================================\n",
      "Lordes ndy white,serpeursss, winthawaneThat thor igtrs pn'lbred.an, whepetrrileme,Woveakerdired dou adNdRu[s stAlde'ghit, hosTheeretis,heebo tEe shedIannirery fongalatorereee avenetreyougestherofarnd borerarhadenorctiwhererethyobfey featheae, hy ore f cower, y se me st-e thOotemes.ntheisomelastve-ied paull,, bk j hakeengofhan? blanlot pewlecerenitherereEsthoverthe wins It'g, asesDt,, ithewathiralresay t totgatherenikor,'SheSillerenaced cofO teamwesoleleorerete, rekeyord moneeanellinche noser thalfth\n",
      "================================================================================\n",
      "training loss at step 1080: 2.88 (2017-03-27 17:54:24.627042)\n",
      "training loss at step 1110: 2.91 (2017-03-27 17:54:27.584413)\n",
      "training loss at step 1140: 2.84 (2017-03-27 17:54:30.612817)\n",
      "training loss at step 1170: 2.89 (2017-03-27 17:54:33.635116)\n",
      "training loss at step 1200: 2.80 (2017-03-27 17:54:36.656692)\n",
      "================================================================================\n",
      "Lord sie y yous d hero suso thane, komyeese, thateAondertukryotheerethe,pefitheRerthing, is, t thes:, athie?ounouas,AnBilenodeetIYedeesixy ns ke tad dind-thout lleal thaish.:ier y,pera fd migrnWhedouan'noUeit shMre'lkowea heWheukedentfowepele,usmoritheThod, teruthavevesaighouse oresyotorhar wsstoureceaver tofen orth udeak, miremiather, soudedserprsthal soupineset ghfart. tese,Ar igAourstherie sterele hddete me Aw'ce, toruthetaneWeindero btM'.e thar, fodullre l hacM?frenthatonemiedru bllEanth watrors\n",
      "================================================================================\n",
      "training loss at step 1230: 2.83 (2017-03-27 17:54:40.215388)\n",
      "training loss at step 1260: 2.84 (2017-03-27 17:54:43.471740)\n",
      "training loss at step 1290: 2.96 (2017-03-27 17:54:46.568439)\n",
      "training loss at step 1320: 2.85 (2017-03-27 17:54:49.739900)\n",
      "training loss at step 1350: 2.88 (2017-03-27 17:54:52.905553)\n",
      "================================================================================\n",
      "Lordofathasay, sth,incougloy,hekearindavataldalav,ATaspPerdiNhend thuYisofelierComereSaktouseYlt hersumoforero, s, Semealemaqeathateth,heveraceAnghesthee maYe,Thard, linger-foulyBone,O.Soremorardouronthen s f, anow'oIn,A:indatThacereswtothesemert chane.akes, louimoUe:ouratvekar my,at?Anepraice IeWe mysouishendomovowereqelaI arine Ththe,. ny sBesteesWhengshon,Whereeen, hel!omtin, ther therkttheanotote,rtoshad ikncbngore.thyofamemadathe acoraimthes,'d LIlannetherEr, lWhe er istmaserus ceS.-ong, shorve\n",
      "================================================================================\n",
      "training loss at step 1380: 2.89 (2017-03-27 17:54:56.486904)\n",
      "training loss at step 1410: 2.90 (2017-03-27 17:54:59.696666)\n",
      "training loss at step 1440: 2.88 (2017-03-27 17:55:02.809102)\n",
      "training loss at step 1470: 2.87 (2017-03-27 17:55:05.881112)\n",
      "training loss at step 1500: 2.82 (2017-03-27 17:55:08.922235)\n",
      "================================================================================\n",
      "Lord, tundan.tapowerilitre wThemindCeved blemef ticeracy th: pavyome Cus'vers,s pleme is I!y,shecheniend herond intholayend acIEstoure,urtevesTofathe ar andR t andu, lousentheaneis portese pertherild perst, swshand:aneamere thuphefees, thed,Aand tVereafased w:heanowhit to ce loonthyS.uue I, is s'ond ce he cead airnP, ppedincern aideser'lerTaig owat pesorigsore henskese oleetiseayo cowhby AcenousAs'gthiec. wou'reHisticred mend unurecotind sod,.Ltibendonouneof ateser shamonguse,? te,AchansoApes weland\n",
      "================================================================================\n",
      "training loss at step 1530: 2.90 (2017-03-27 17:55:12.443333)\n",
      "training loss at step 1560: 2.90 (2017-03-27 17:55:15.531982)\n",
      "training loss at step 1590: 2.84 (2017-03-27 17:55:18.616849)\n",
      "training loss at step 1620: 2.92 (2017-03-27 17:55:21.697603)\n",
      "training loss at step 1650: 2.76 (2017-03-27 17:55:24.789182)\n",
      "================================================================================\n",
      "Lord: se ait blors ar'vinourithapbug here umeitviofe, ce brero yelitC.heyoiotonkede t thetiletusthesishtethethe.gll, Nof!ferademy thereditthee hyocaesorend hange kicounchings,Eivengnoury Luly ikeanghorCre.Ather s ceelerdntr fonevemeforere.reneshimy C me Cand pomoullarusthSug:Ache lou sheaginowo:hangThetstuy nte pin,O, merin at watr ieemear hedileneafsighayotillererefove bees tasiqanigrEve witad I bithierinot Ithessthaneake, Fmave ofofovoncapa t ngt hutome aicDco.ng:: finerer, st methe Sithieckisf. a\n",
      "================================================================================\n",
      "training loss at step 1680: 2.84 (2017-03-27 17:55:28.464951)\n",
      "training loss at step 1710: 2.90 (2017-03-27 17:55:31.545841)\n",
      "training loss at step 1740: 2.87 (2017-03-27 17:55:34.657000)\n",
      "training loss at step 1770: 2.99 (2017-03-27 17:55:37.793611)\n",
      "training loss at step 1800: 2.81 (2017-03-27 17:55:40.935187)\n",
      "================================================================================\n",
      "Lordend tr.Bs ta!e manthandpothe,oundor ond,Bhemayurende er thi!thethelticp,IThene, hous thEtit'se Gntid: higonfoun t bldBn,.IF:Eband acteroutoume, enis.fourerich,xnthowacots,laus, mofursearintovetenteBerodrent f anentheertn,Wheansensearingotiodurandorind.Whe', ld mchenl st cad, bSuche y'l mvensHncu tandth twikat sereredapdetMhathilusimamyonghird,Ao'Lldone theatofy,Anghowongotherensthpbe, sheneatherowoucon, womalue ay, anginathare.Idin,FurolanorelishathendSomyshbithay faruseamesonowint o tian-'sASro\n",
      "================================================================================\n",
      "training loss at step 1830: 2.80 (2017-03-27 17:55:44.543869)\n",
      "training loss at step 1860: 2.79 (2017-03-27 17:55:47.643445)\n",
      "training loss at step 1890: 2.78 (2017-03-27 17:55:50.744923)\n",
      "training loss at step 1920: 2.77 (2017-03-27 17:55:53.855966)\n",
      "training loss at step 1950: 2.80 (2017-03-27 17:55:57.005271)\n",
      "================================================================================\n",
      "Lord I theenelthiner,oer 'm mrenorieverWhe owiGend, wexAf-llotheave?se ideadeseruvereert womel bestesotr, hed witr Epes athepioude s,wite.TheIt f Ingen atidrprs m m, hasf,, shor ilorrs, t, se gotegise ng.A?Lllyou: ces ile:pr, ce yesther,yobomow,anglatell.be.BathNar,Ancoalid, Ishifatirs.Theres?n?s t, tot d.Thhe, Wheshindend ndd te gwheterirofe the -ered rigd wiurthayokeathat,IYtheWhatokensidSaitharesdis!hine nt,oop,'de herUssas ceceis thinitiswimer vousse, I as, ngort Itindises thind inde sunt.Anizll\n",
      "================================================================================\n",
      "training loss at step 1980: 2.86 (2017-03-27 17:56:00.512897)\n",
      "training loss at step 2010: 2.86 (2017-03-27 17:56:03.572673)\n",
      "training loss at step 2040: 2.80 (2017-03-27 17:56:06.632022)\n",
      "training loss at step 2070: 2.81 (2017-03-27 17:56:09.679691)\n",
      "training loss at step 2100: 2.76 (2017-03-27 17:56:12.724251)\n",
      "================================================================================\n",
      "Lord, hin. br wesmus, y bed tincor, wa f mir wis d o bou m hee toointhoventsos.WAshe me, t te!'ctoull y, oco!Hader Bs s y y he youtt out licrle nd m, mee!atithBsteve casseieOW.'dou h oum w as hince ncind t maverer.Tini: tiOs, d, iI gHirl: o-s heav.Anksesecrnt'sare R pApeand m ut.I mers a 'd gorin feboraine y yeyA ur d, ioo y thy itrauce ld-ave, and he send: timomeavesotilken,.NI t.hencrurean arise hilud'se t h:I Uuneat haplNar or,Thamend t I mo-oothnt dostouerer homeWon mitertosUWimemo pent.WhUoncel\n",
      "================================================================================\n",
      "training loss at step 2130: 2.74 (2017-03-27 17:56:16.306330)\n",
      "training loss at step 2160: 2.85 (2017-03-27 17:56:19.376254)\n",
      "training loss at step 2190: 2.73 (2017-03-27 17:56:22.434675)\n",
      "training loss at step 2220: 2.76 (2017-03-27 17:56:25.531284)\n",
      "training loss at step 2250: 2.68 (2017-03-27 17:56:28.707110)\n",
      "================================================================================\n",
      "Lord, aATheEshinenesherse,Ored.I t lene,Ten, cout shewinimollimthousped,Akig arand,Mtave, wintur,areroufowid,Deges,-streg,Re Fenernot Gd,As tarers hathedr cofor:I s cusll, d wenoulfimarasir, Fe icprifrer Bt?.Thore y olO: te, ankigonen airvey,.SdYof nAlWinceredrersere,ThapingooRille tlsbefour aimy,And je andyDsemem.te,Thaissit, ot t hatougnd gpousuf, fsintEpllethirent:Thand, isir, oce xet 7ficeLindef noy,Whiraveshongoral ntleldepetins krinceDemepes.Thile d.Fer'ldan,Therde core mpevest s Is ooneeseI t\n",
      "================================================================================\n",
      "training loss at step 2280: 2.83 (2017-03-27 17:56:32.290456)\n",
      "training loss at step 2310: 2.62 (2017-03-27 17:56:35.373227)\n",
      "training loss at step 2340: 2.60 (2017-03-27 17:56:38.449007)\n",
      "training loss at step 2370: 2.56 (2017-03-27 17:56:41.503913)\n",
      "training loss at step 2400: 2.66 (2017-03-27 17:56:44.596569)\n",
      "================================================================================\n",
      "Lordure'ssqAry!r, pou I t-TherThesqtious,, o heatederoutBt, toremoweas, t,Thothy ankomee wiegThenowary ot,Bolenoun o,Anoite t,EFat witoudAnsealloutosEcadethe ke,Nereame.Anite,Ore y th ESouMad mer, tetongryor.Sinsilse[resSorditheseForerep abe y nghameLe,H, s!odWonout.SeYrord, I,Whedie,Thelld[einokit.ThesteveyisSVysIle,Astoupet!No?yTharofavis busanthast s dMais, mere untorare,AseeeeeadI Ho.The, ped mofioun.Thalomys,Thedathy barere ot-irerutsee, fowAnterie veer:onsed.Tejend y,An her,An tUy,Abumy e, but\n",
      "================================================================================\n",
      "training loss at step 2430: 2.63 (2017-03-27 17:56:48.423340)\n",
      "training loss at step 2460: 2.57 (2017-03-27 17:56:51.524398)\n",
      "training loss at step 2490: 2.72 (2017-03-27 17:56:54.579879)\n",
      "training loss at step 2520: 2.53 (2017-03-27 17:56:57.686574)\n",
      "training loss at step 2550: 2.57 (2017-03-27 17:57:00.850603)\n",
      "================================================================================\n",
      "Lordd en t lys il: yin d ar. py, apex.I f f.ELat bus 's win tin ncer at y th t lang-l xpyN'me gBe hee.I'f y y th andsTho ftin-te inge nGugn, plicof: gorDMay h Plo pe, lindy I at? I is'le d o', nd, y t te, o t.: as y blimimO s ind ree, l I.Tod o NSDHar? d yotht' ld s be?An binzATowanHe I G 'l pay imu t.Bat o ave j t nd, bet ce whanghet ul I EI icTh he Dy whis s re aly m m Pby tow mad ed y war nofsCpe I? d.B wy in d d yLy-bomure he in Co I h at sen d.Wh y.I tO apafris'ch De d be uchemusird t st.I he h\n",
      "================================================================================\n",
      "training loss at step 2580: 2.49 (2017-03-27 17:57:04.514128)\n",
      "training loss at step 2610: 2.47 (2017-03-27 17:57:07.635935)\n",
      "training loss at step 2640: 2.58 (2017-03-27 17:57:10.681225)\n",
      "training loss at step 2670: 2.48 (2017-03-27 17:57:13.720198)\n",
      "training loss at step 2700: 2.45 (2017-03-27 17:57:16.759008)\n",
      "================================================================================\n",
      "Lord ss arre,Olo' meioteco o h te, I win An at.Th l w ilo h. h o tCGof t me baco t f's,Anke ich e f my che h ANme fo s 'll t h beil'lir.E aves ve t con y t y. by Sher llonener, ktoth t tl or a wocan f w e tu h ingen wice it y ocoor fond, leroo hPon w atst nd.Th pous m l it lll s amyNore llont y were gurfo,An y soom ler lot and ilo t at q G l me'xid IThen Han wit kerge ted tare my t.Ewind t Fatopenco muld y ged d we t d te t onkToul h l ag n g he bery.L.E'ann fOHiny se ger wfe je owisken I ghe y ut s\n",
      "================================================================================\n",
      "training loss at step 2730: 2.47 (2017-03-27 17:57:20.291423)\n",
      "training loss at step 2760: 2.45 (2017-03-27 17:57:23.325388)\n",
      "training loss at step 2790: 2.50 (2017-03-27 17:57:26.366709)\n",
      "training loss at step 2820: 2.49 (2017-03-27 17:57:29.409292)\n",
      "training loss at step 2850: 2.40 (2017-03-27 17:57:32.461168)\n",
      "================================================================================\n",
      "Lord'seakerure I:Th s t?Sars med ompomert, he se.IWire's, knd,NNo mole,'d y.Bngill hes Bidst wigur mendithe!g'msthat! ndYe are iprerndenxtAr Deerindn ad amave?t, El,As, h tEnd! I ts t,NTh,Engh y s.Andd wionwe indAnde it:Non, hy,I helly m!Yomy thy s aith n'we tut.Ifr Andxe: omy agisereld,Tan,AWhen wede,Th disenty'BOs ly,Antit aritand ceand sace mande wiofrerd magonxie'd,TeDean tocod Bby t, Her,ETot meanswillond henerofredle in jEfind musabavicomendrd yo thedioushakin -angEnd, hen anchen d s.Hod stano\n",
      "================================================================================\n",
      "training loss at step 2880: 2.46 (2017-03-27 17:57:36.075544)\n",
      "training loss at step 2910: 2.48 (2017-03-27 17:57:39.186191)\n",
      "training loss at step 2940: 2.44 (2017-03-27 17:57:42.269606)\n",
      "training loss at step 2970: 2.44 (2017-03-27 17:57:45.304273)\n",
      "training loss at step 3000: 2.51 (2017-03-27 17:57:48.346694)\n",
      "================================================================================\n",
      "Lord wifou st, ms ch I I th buf an,The, ato!E'm ou ste m, co t Robast l ay, y h co,I athag, tuin is h y m me pand.Bar meay al m,Ant he Cull fous, sAndowe omes y, 'd t ue ss canou wateno,Pewe?Whorimayay duromm.INExe? n a t An s ue s, wiof nof, st o dlore-ch y, umy de s! s ato hovicexve my ddAn akivamar fis ff y Ppowhbe heatir, f fan, to t co I as ce.Cleny inden.Thie, ant f w, of d o pat murl e ght bot I mer ile hor IBens, eny an f is y e I dowifund, westlalare arad I f, brge, Po s is ade on pe CBl wi\n",
      "================================================================================\n",
      "training loss at step 3030: 2.53 (2017-03-27 17:57:51.861267)\n",
      "training loss at step 3060: 2.38 (2017-03-27 17:57:55.023402)\n",
      "training loss at step 3090: 2.51 (2017-03-27 17:57:58.160814)\n",
      "training loss at step 3120: 2.33 (2017-03-27 17:58:01.248680)\n",
      "training loss at step 3150: 2.49 (2017-03-27 17:58:04.330509)\n",
      "================================================================================\n",
      "Lord Mpeses pe o woue apent, ous, o's o ant nt brio auns, yo an od houce,-s.SLxeseat I wss four!-Th, be yobyWend? nd han ionut ay no Bo.Soue pe' my y t:He h bery l tUS:Singue,STis rouls aroouas ie o s'd wir s Mas, s hours aie te fonowh hed o, mes he.NDNogndco ouss,A co ay I mys h fr mio fominche Cod o.Whe?Whoulo omanie io n wDas, nt V f k he sio het d my y al lotus cu s'sesund tou yolistho o wes.DN, arjon.Wh se.Apalour!'shelatexiror on, g andeue, bour t ve, marillaun we my fot y booreme'sh d te cous\n",
      "================================================================================\n",
      "training loss at step 3180: 2.44 (2017-03-27 17:58:07.937879)\n",
      "training loss at step 3210: 2.45 (2017-03-27 17:58:11.129924)\n",
      "training loss at step 3240: 2.28 (2017-03-27 17:58:14.250458)\n",
      "training loss at step 3270: 2.35 (2017-03-27 17:58:17.306317)\n",
      "training loss at step 3300: 2.42 (2017-03-27 17:58:20.356822)\n",
      "================================================================================\n",
      "Lorded site.By hale,xer,Thatrs win me, oulornsFole, s y bages, weve f.EShely ivato f ont, orwe'sselee busilo'g iod y, tyoures pam thamintheConeat t?Wh, our f wio ghre be, te omut irenodlomy at tuTril wereghave mour, ofoff, acethe hso tes taspequmar orer'd ano itut.An, alean, anes hast thing do, my whe pre?Adise l hpeneshece.Hayire hete y.Nped t l s, usindpA m r: mar wind.Heliue heniowhy's lllo:Nomequr onoucous Poof imy, be'd t huaiote.Cowimatet t: otavier tage sllleerimag fof myon m,Thee,Whake.Towis\n",
      "================================================================================\n",
      "training loss at step 3330: 2.37 (2017-03-27 17:58:23.908388)\n",
      "training loss at step 3360: 2.39 (2017-03-27 17:58:27.002601)\n",
      "training loss at step 3390: 2.36 (2017-03-27 17:58:30.040491)\n",
      "training loss at step 3420: 2.46 (2017-03-27 17:58:33.079983)\n",
      "training loss at step 3450: 2.36 (2017-03-27 17:58:36.109929)\n",
      "================================================================================\n",
      "Lordr,Wt,O.AsAngofothth aur pody 's serRemoth, te.A-imerot. coris!and d e mavidend foun]er htlie-gh: ururared An' feaud mUnttr waus me bliss hod ay,Gan'sigTh, Gakst w'dt ha t?S,COn.IShenorpr bemer haiststtmakeonbor d,This os d,Thy h,I'st o tr lS.Tor ato'sItMirs nit maby s.ThathtsO in s,I s,Bun murgot ceattssere, wawinedMy lls, y,EESEnastoubur'nttenen rars ikintouare.Wh,IThe h, t pant, s ry hatth Shaiore, hthoned ires spr he chevinondat pry y bowicashoungotrm'she r IAnty hildit ghin,Fs, mpevesthis.To\n",
      "================================================================================\n",
      "training loss at step 3480: 2.35 (2017-03-27 17:58:39.613665)\n",
      "training loss at step 3510: 2.34 (2017-03-27 17:58:42.689165)\n",
      "training loss at step 3540: 2.29 (2017-03-27 17:58:45.773340)\n",
      "training loss at step 3570: 2.29 (2017-03-27 17:58:48.807992)\n",
      "training loss at step 3600: 2.27 (2017-03-27 17:58:51.835793)\n",
      "================================================================================\n",
      "Lord man,Th, hy, lacondrss muly ce?Nar besgry bushe: aianor harealeachau len gged, wefirun ase anceruivindincas,Whes tikno st coulfpanoue wise hee?Ya'shand bemedinty nowilered wen Phany,I leth'surethan:Heeas:Faliny d ithilis,Th.OThatontriste, thers.Ton wefulllanedary sUnyoutherad ly.Yomassh oulalllineandedwicoury wes, bulRuran ay y, mellere! animyuy.Laly isarrad uts greser.By by me cin, Pucait No amo thinds?Os s acol t: teatr y he h I'dAne,Mairupesty he tie tstheal an.NOThish, uro aceland atest meal\n",
      "================================================================================\n",
      "training loss at step 3630: 2.37 (2017-03-27 17:58:55.336878)\n",
      "training loss at step 3660: 2.40 (2017-03-27 17:58:58.380088)\n",
      "training loss at step 3690: 2.22 (2017-03-27 17:59:01.411373)\n",
      "training loss at step 3720: 2.38 (2017-03-27 17:59:04.449077)\n",
      "training loss at step 3750: 2.25 (2017-03-27 17:59:07.488934)\n",
      "================================================================================\n",
      "Lord found t temiur youk d fime s I EBur han!Sher ake he be!Othe: y ch h thirerat wutun man, myor,Ore irin foft m hed d at y have shoulyoue,The ur: houticay, verir t gh my spake! s wedThe heare hourn y me: iturOurars helouruno goumiseAEWess te igur,-LEntr d alind pen are is!Dor-e be acus, t yoken wiurerTh mASRDound.Sait pave d eray with anFhish t ple ay ave!SD? gret!Tiur fune f iceound nomel ourrtiteme amod nived whiure bee four! op mous y s? d uO thas,Ns mir, yof p ved, haro y at tasede atine wes I\n",
      "================================================================================\n",
      "training loss at step 3780: 2.32 (2017-03-27 17:59:11.008050)\n",
      "training loss at step 3810: 2.27 (2017-03-27 17:59:14.046784)\n",
      "training loss at step 3840: 2.35 (2017-03-27 17:59:17.155404)\n",
      "training loss at step 3870: 2.30 (2017-03-27 17:59:20.281710)\n",
      "training loss at step 3900: 2.40 (2017-03-27 17:59:23.315939)\n",
      "================================================================================\n",
      "Lordesend Iwoud.ENONeiour, fauril alond ouse t my?Banerthingr ond k, vithencedlondsimbanty d t t akes hut depaklexesenen,Astromolitanout tspodenin th, opyomour:Hingutotiloulanouif denofrotid.OAs, avily f d t tourmy civencere, mre urerellly, nyorineres, areeRI chalinongllo ben.UUYon'd hous.Whiorysanted wirind,Thacr th, orururinentyore tOfisin'd tarymaved lindeOsious,Dor teiofin truds insendil isesend dule car, nty anthowathin'd?Thene iroor senssthetlinotheg-y, ofou,Lisiondledomofor ysinte?Now, purye,\n",
      "================================================================================\n",
      "training loss at step 3930: 2.32 (2017-03-27 17:59:26.949161)\n",
      "training loss at step 3960: 2.36 (2017-03-27 17:59:29.999165)\n",
      "training loss at step 3990: 2.31 (2017-03-27 17:59:33.044204)\n",
      "training loss at step 4020: 2.37 (2017-03-27 17:59:36.225084)\n",
      "training loss at step 4050: 2.31 (2017-03-27 17:59:39.331133)\n",
      "================================================================================\n",
      "Lordelf tof hies heeThalelloug and amatshas sssh,Enowhar make,temous, mours:RDat,ONavesantrd er Inge, che CHyHils, r, y tsplsery fUs thorend,Thinor bled.Houraileriomitichy ourk, hedonchad mand veng, blarusith t, pr illeode.Thtsbeay, hrus amel'ue?FinosthonSoussothe, ares:ANan bound as.Nwind gre t PACancome'sestussthish.The kerowils,Borelioroofrer unthalind'd omanfThtoud.CIsalloongis nd'd as.Alilin.Cay nomofed akis,Ofondoravexss bedI hanthiredUf ancheas wimatht stllllish bler-uty bon:'st hay sulay 'ta\n",
      "================================================================================\n",
      "training loss at step 4080: 2.17 (2017-03-27 17:59:42.949932)\n",
      "training loss at step 4110: 2.20 (2017-03-27 17:59:46.126581)\n",
      "training loss at step 4140: 2.57 (2017-03-27 17:59:49.241741)\n",
      "training loss at step 4170: 2.33 (2017-03-27 17:59:52.459420)\n",
      "training loss at step 4200: 2.23 (2017-03-27 17:59:55.541283)\n",
      "================================================================================\n",
      "Lord inoDeriootinend, ilonk,Mifour?Foncllou, h ndreand itore Imuche!AYous e, BAnakEAnd ied.Thendrono s o'se! m:Thit urrycrer bld, huneleantomesh areaurala we onds, heathe meerath fancaimourerourur frie thee foominin bun-Hoof?He mond un.Gomy.SAnd by.Enes.N ceest, we be win qurioswe beryon's?Nowsir ly, catee kee, y.Dsexachen tiesavo ior s foweseas, s cis anss wiroradfSo oth werlyo, IThory bond, an hofe htis I ce waimAFouse. sch wieave glile IHat key'spour, a wiorles t n, ik bre,Hore p.A s, u arechats \n",
      "================================================================================\n",
      "training loss at step 4230: 2.25 (2017-03-27 17:59:59.093749)\n",
      "training loss at step 4260: 2.32 (2017-03-27 18:00:02.274408)\n",
      "training loss at step 4290: 2.21 (2017-03-27 18:00:05.451760)\n",
      "training loss at step 4320: 2.34 (2017-03-27 18:00:08.469113)\n",
      "training loss at step 4350: 2.23 (2017-03-27 18:00:11.499667)\n",
      "================================================================================\n",
      "LordYelive be aitathorure, omalorthoug ge: boreeyepidigrlt st:A tomate le, oteaieran!-e t! d,Wh.Hereawsthuleatorease tid d.Geat toukert,Whamou,Toreene winGEe wie: yo bavelid alil d tato onornofoun, t uneed he erove'le flavereeath Th, y, adatas:Bleends ayt oree hariowe ke, at the,Alil hernd her I.A fof bed, w.Why h.Ge iate.An, s t, he,Tele ite, n s!Buly.Bpaighowed ntin-AL's at ins.I t cetr.EPVe.Sy mame tais ad Mee trecap,Ily'sheede art, dHeThees aisees, akee t.Naniry,ASYo we.Heeaime!Mit piodmeca me i\n",
      "================================================================================\n",
      "training loss at step 4380: 2.11 (2017-03-27 18:00:15.005223)\n",
      "training loss at step 4410: 2.22 (2017-03-27 18:00:18.024717)\n",
      "training loss at step 4440: 2.19 (2017-03-27 18:00:21.051760)\n",
      "training loss at step 4470: 2.24 (2017-03-27 18:00:24.071875)\n",
      "training loss at step 4500: 2.16 (2017-03-27 18:00:27.103071)\n",
      "================================================================================\n",
      "Lordse,Ad ierse, s lous, cous fawoupedecer.YOle?Fot hon:Thends Iumy urThakint eded Ass eseave! Paie, I my hexe torchanght: ond ory ththerof weat vetr alecofea blinene n yforintimodsowherelle oue'd ar shianglly, omy nd-n n fyorillyorsschas on il h we fr:Bpore theat Cour-Son,My is.AWy o terenithesesthar u,ANCERI?Whomyougleencat ilaituran ath:Sherrothtu.Anajpelepelepieatre,ENin-ecler,Tot, tThit th!Anchat, polemend-NLExin ichereleer, acat.'s tercryel neran t h.MI wasee-s the an t, hon th I the?SAxenery \n",
      "================================================================================\n",
      "training loss at step 4530: 2.15 (2017-03-27 18:00:30.586167)\n",
      "training loss at step 4560: 2.21 (2017-03-27 18:00:33.600189)\n",
      "training loss at step 4590: 2.31 (2017-03-27 18:00:36.634160)\n",
      "training loss at step 4620: 2.12 (2017-03-27 18:00:39.657041)\n",
      "training loss at step 4650: 2.18 (2017-03-27 18:00:42.674011)\n",
      "================================================================================\n",
      "Lordes wembeeliere Eneauc-lourad st fe my pKWh nd s hed pomuge iner-d hy Tid ithe?Of re iererer.HeoumereAndaiseaiers wower ingn fterunoo!Yed pead y, d:I faben cereeeds wino houliethe iean?Enaingseif ceruntonathinceaine!DMy gnd tey y hcheareicheleatcenstreanserer'dchis hay,A ionghanord I t, sthe dor buru, ins thil dit ONod meerse brelat har talire ame ane winand wshemomarry vand mersmerured:M's f he,Arinenure, at.The ce, mie.IffutruinorosetCain n?Aspreis'dee.Ast, sh anthes h ISw my,Wis d haley herous\n",
      "================================================================================\n",
      "training loss at step 4680: 2.16 (2017-03-27 18:00:46.393778)\n",
      "training loss at step 4710: 2.19 (2017-03-27 18:00:49.413989)\n",
      "training loss at step 4740: 2.20 (2017-03-27 18:00:52.432798)\n",
      "training loss at step 4770: 2.19 (2017-03-27 18:00:55.463061)\n",
      "training loss at step 4800: 2.17 (2017-03-27 18:00:58.485199)\n",
      "================================================================================\n",
      "Lord t callin thit we.ESwe p.Tor is thictony gn w-SBp SMy t my rmounouce igan or y onls t f in g of as,Adatr uks ad can lin!UDl g al wn mat Wa o mbe tillly wand windy,And thal.Mmy his ve e troug hur vos, fe d of atolll ay mout k, s ely th girary.Shy s br at Livit t ayOM t ano at, me t s gld tut o ng icaususigCththoo ang bol is whe.Bowits thive ak.Wily t ttE wom, te t l ivod cr glout Musheplo vig: tond qurt ts m athe d w, My athy thicaiot uvikeis's, w t d wh couie orow'spr,Cinee t mur imOt lod r.As [\n",
      "================================================================================\n",
      "training loss at step 4830: 2.18 (2017-03-27 18:01:01.979146)\n",
      "training loss at step 4860: 2.18 (2017-03-27 18:01:05.001869)\n",
      "training loss at step 4890: 2.18 (2017-03-27 18:01:08.026755)\n",
      "training loss at step 4920: 2.15 (2017-03-27 18:01:11.053498)\n",
      "training loss at step 4950: 2.11 (2017-03-27 18:01:14.072947)\n",
      "================================================================================\n",
      "Lord.Nio heail Itor t er cit bulectHr lormofes,DExis thend mou'd f yowise. wf thabe byoSien therat t a ttist te s, dd, toullpth tist treang t?EGil s.Cerou'le hout chileye'd f bly outod bre by, seay ese ou, mor. Togh t d: th,Amy is, he?Thity we tuthe-Nothes acontthitheThily, s hing re mut he be PI sindend,Hy the, n l ir'dim t I ple t pisey it, br me h.Mio ngugrflenale ne nt thor, moue moure is?Anglel avey, tiu d thy t ient, hak som, if mether the aththedout d talor?Dnckn puid mo he a itr we mefe'd I \n",
      "================================================================================\n",
      "training loss at step 4980: 2.14 (2017-03-27 18:01:17.572268)\n",
      "training loss at step 5010: 2.25 (2017-03-27 18:01:20.598108)\n",
      "training loss at step 5040: 2.18 (2017-03-27 18:01:23.625146)\n",
      "training loss at step 5070: 2.13 (2017-03-27 18:01:26.646188)\n",
      "training loss at step 5100: 2.13 (2017-03-27 18:01:29.673778)\n",
      "================================================================================\n",
      "Lordid d Le hast apreWhondallee t:A GoreHwirs.As hume, t.Yor:E's inanciman t s ondB stheind t d shesind s thAs.Ez's,Ifevit cegad can fere ty.Ricllstomofonst witr ke Endod lif thalin hed,Obuty ve brnd, VThl y d fofSAYo har?Bun thimesth ierestho ONon til te Gord telllie,'s h tr theervindCMCamacke,Bured t tanAg-N Co d be myon?Ene t CUNon t, ald thenghe the t t thithinct in d SA the hinonkinour tlo in'sesto hinistcle d, t t, ingus br Hint,Sour ie[ me ak patinintholatange my Anort thantotalor y,Wour t in\n",
      "================================================================================\n",
      "training loss at step 5130: 2.13 (2017-03-27 18:01:33.413038)\n",
      "training loss at step 5160: 2.13 (2017-03-27 18:01:36.448652)\n",
      "training loss at step 5190: 2.21 (2017-03-27 18:01:39.495726)\n",
      "training loss at step 5220: 2.19 (2017-03-27 18:01:42.523449)\n",
      "training loss at step 5250: 2.14 (2017-03-27 18:01:45.546229)\n",
      "================================================================================\n",
      "Lordaiouthiane,Aswiscoretly st t atheriff, iry yorad, seneaveinothe stowave meloowiouscouesseco Singpetean, s FAvelogox hallis.I omak ast seis.As, ate the.ESMaplldavemaferlin his me in knevenspl,By,My her t.Y andy: My, mert Poulentherny at,Helyoul allinculomou Colitevethe re'sst:An myoongeded,Than'leAs s nendyoutru fatoustsThiorathe transsTutunethothet: psignss pie hig anyolzost IYodrdo thanolline!DounilinousedsAIngalathalle, din suryoulon iofrind ceolertes han.ERIwiterce where outhapesho thr,Nore t\n",
      "================================================================================\n",
      "training loss at step 5280: 2.12 (2017-03-27 18:01:49.199534)\n",
      "training loss at step 5310: 2.17 (2017-03-27 18:01:52.430720)\n",
      "training loss at step 5340: 2.07 (2017-03-27 18:01:55.596228)\n",
      "training loss at step 5370: 2.16 (2017-03-27 18:01:58.664664)\n",
      "training loss at step 5400: 2.15 (2017-03-27 18:02:01.821625)\n",
      "================================================================================\n",
      "Lord blas asernd t ot fows, ieanfiowis the wis raif mesond gs oomin Whe has, fitisSh, wr's ol on t Faribed rarise Comidad d hes soncandThe, m, w qurobinas, mefe tourucAnour haveese at hele ronoun'sero alil k g, tarimouss winst.I! fiCar, fon-lys-icespl y st. se seas, pSo, s gs joume e fler oousis himatrer ble, it, ouin the iveive incor clanshitlyoumel!Be manethe?O t, ngooon lilofopu.I's:Nofis r-t arere w t. ads wsmooo calit arok asen bllan he.[ irver mar mire h dCLe.Weyonerwomit m Edalile ndith ano o\n",
      "================================================================================\n",
      "training loss at step 5430: 2.12 (2017-03-27 18:02:05.384908)\n",
      "training loss at step 5460: 2.30 (2017-03-27 18:02:08.508580)\n",
      "training loss at step 5490: 2.10 (2017-03-27 18:02:11.601694)\n",
      "training loss at step 5520: 2.05 (2017-03-27 18:02:14.665025)\n",
      "training loss at step 5550: 2.20 (2017-03-27 18:02:17.723203)\n",
      "================================================================================\n",
      "Lord.I ouw:BHe throucan, fes, drof th,TilitPr t witl cl y he ilonele oun sed oucre hine igntheirkncly d itoth he t wef te-'d, m akee gzmu, ollanghionolenelifrts: theANe wik whathe tooucoloupe ne nof f yplacks ime ge outhis of ousese Bro ir'd o'd.Re o, itherilatwe mirch? itEYo knour t'deshesELpow he ogre fowant nd hell tA t sIblolllis thorio fler-Goo f owu, d tsofins.Wat RLE[I mad pu.Frcor fo, t, mas as monealavesaknets ano s oueioupicthithaneras,Win ttin.Tisecesotad wss'sive.Helitthe wag l d senve a\n",
      "================================================================================\n",
      "training loss at step 5580: 2.15 (2017-03-27 18:02:21.226432)\n",
      "training loss at step 5610: 2.07 (2017-03-27 18:02:24.282944)\n",
      "training loss at step 5640: 1.98 (2017-03-27 18:02:27.321413)\n",
      "training loss at step 5670: 2.04 (2017-03-27 18:02:30.351808)\n",
      "training loss at step 5700: 2.23 (2017-03-27 18:02:33.379103)\n",
      "================================================================================\n",
      "Lord te t mobr houson s y tesiver f anieist hie tsior pish Cal ther be. dealser clouine g abu tageend, ns my id o.Con mo,Nir e cat, ord glof pr t ncaithoweze f owaghond il I kisabug erM l It m. an.Wh, gpere n wioth.ERI fonostckentr, treesatesthofur, CANore or br wil Ree urered alfastig y h creave-'s thath cong ctit wammet ak meatrlo, asple saly, fed mo hthad the, buse Momomat t thingler J opu k ies:MS'd d t astulond CCWhe- g.Th,Ths int.Reneis yow bull nonn te mant thin, nelonge thther.Thas be, doupe\n",
      "================================================================================\n",
      "training loss at step 5730: 2.04 (2017-03-27 18:02:36.901925)\n",
      "training loss at step 5760: 2.16 (2017-03-27 18:02:39.956346)\n",
      "training loss at step 5790: 2.08 (2017-03-27 18:02:42.979656)\n",
      "training loss at step 5820: 2.23 (2017-03-27 18:02:45.998424)\n",
      "training loss at step 5850: 2.18 (2017-03-27 18:02:49.026745)\n",
      "================================================================================\n",
      "Lord fioblod harurexameLYomy wnoo t trederimyoth, B t s suAng wh meDure all ld edr gllitonecory.ANou t anonorce y,Theerr t, o genoug h:Mon plamats heDeely-tsitoburer an, al sWhar I har tiorstho iongrjoboulle o t me,Sthapesimerd,I.E-fad, werd f clioral perkno alds mbl Han Branthe ourg,Wur t dOstyour oouryethe ou har?Nourolonghinondean f, omuror ye, herif his,SIsFon, t inghigeres hiok rerand oou-owis sif t ncePr's tu beree alore'ds mee omore thars n stwowothingorus thHekis-Hind ityo cattthiveald ow ha\n",
      "================================================================================\n",
      "training loss at step 5880: 2.14 (2017-03-27 18:02:52.534825)\n",
      "training loss at step 5910: 2.07 (2017-03-27 18:02:55.569483)\n",
      "training loss at step 5940: 1.95 (2017-03-27 18:02:58.600157)\n",
      "training loss at step 5970: 2.06 (2017-03-27 18:03:01.640064)\n",
      "training loss at step 6000: 2.16 (2017-03-27 18:03:04.675012)\n",
      "================================================================================\n",
      "Lordeowenodlee theantharo c: nghak army bera h thedd au abes turef y, s foune, oounerst.Sundniten owon erGoncharemimopapeaglu as sjous mor'sthicke and alans oplenengeemyoncherane,Foues o PAyootobey, per munchindcag, antar, trery merat thoffap as dto: mmy oben y cearas owakn: meru-we ang, d chin!H[ pist fe Be tealllllieathenecagierate anourvererarmegocagrvy?Thengst hothe wese, verfe abulen f s'dR,Anchowex ous mell ofe, warch,Thal man dfa a searrs f hthyowen sus t hingr'se omes: in,He?SIs, a an it.If \n",
      "================================================================================\n",
      "training loss at step 6030: 2.07 (2017-03-27 18:03:08.413269)\n",
      "training loss at step 6060: 2.08 (2017-03-27 18:03:11.441989)\n",
      "training loss at step 6090: 2.01 (2017-03-27 18:03:14.467776)\n",
      "training loss at step 6120: 2.07 (2017-03-27 18:03:17.510001)\n",
      "training loss at step 6150: 2.03 (2017-03-27 18:03:20.550969)\n",
      "================================================================================\n",
      "Lord mamene o f y kendour ore pe nord p the ce fo cTo beratu the t he ts,II s as tret knereleawn malioufaf d L Hircatharshyo mico, hed thathou oun bllve r ally thiebomof no anodod br ayomor. tThitrutharas msith g trerdlif's y,A d ak jenee lle tat veeatoiteritand nd ars: thisthyot t trvead te tlid igran to s hon dr Co y foure is awing attrar ton morear oup,Whone, whod bano n Why.EOSACalyomourd litwe.RSto weis atr'se d prathaCathre f hellyowis th owinouce soun, alar te ke isSpeane igI thin t chorkinet\n",
      "================================================================================\n",
      "training loss at step 6180: 2.10 (2017-03-27 18:03:24.056289)\n",
      "training loss at step 6210: 2.00 (2017-03-27 18:03:27.081300)\n",
      "training loss at step 6240: 2.12 (2017-03-27 18:03:30.108546)\n",
      "training loss at step 6270: 2.10 (2017-03-27 18:03:33.136786)\n",
      "training loss at step 6300: 2.05 (2017-03-27 18:03:36.168767)\n",
      "================================================================================\n",
      "LordTh?Shof wayor time,A meren ckimes atord th, t mant ack t s fo p shaispinolale h f J'd yp tha lds k t ary isheit I me tarn h as ies t he -'s mions'de forofreshar, n h o, ape ckimy? wikead ait le, ghaveshanckstharkid w, sthanchofthakngoulathaly ithmoffe h, f at alo s, th I fefe mou yomThasezat apulloby d Itmy Anghedlar wobll our n sper myoreslery iou wh fuclorcur myowokice avend lies beaind hous, re?Nan carme t t-s s cere d ake th ne, hilliforo aicke whathe y tay! hth ntapret upr ingPy n'go swe ga\n",
      "================================================================================\n",
      "training loss at step 6330: 2.05 (2017-03-27 18:03:39.677476)\n",
      "training loss at step 6360: 2.10 (2017-03-27 18:03:42.704534)\n",
      "training loss at step 6390: 1.99 (2017-03-27 18:03:45.735429)\n",
      "training loss at step 6420: 2.08 (2017-03-27 18:03:48.768492)\n",
      "training loss at step 6450: 2.09 (2017-03-27 18:03:51.797120)\n",
      "================================================================================\n",
      "Lordeel wonse ar s,Lisedat, bint s f s ithopopinerimeealestastiou ne cukeen or to mide.Wher eg bore!St hears. tr satty, blly s, m nind meage, us,An de t heat, pin ure alyonch!Inol, ame thod the,Hacon, tongst, st he,MO,MAghes alete wsadoudemenoutun'd angiose cazert:Whe, onIficrddeseree hanel,As bewoustus bes, fore mesllime, my?Yembughorean therer biandus blles shu teee mfout.ARIvendeclealo, seediusllye Save'd anorthes ceed thare-Dersinor, I Gowsurenonges ithourenolleantiemoupt, is, withorereese I'sAS\n",
      "================================================================================\n",
      "training loss at step 6480: 1.98 (2017-03-27 18:03:55.554665)\n",
      "training loss at step 6510: 2.09 (2017-03-27 18:03:58.591303)\n",
      "training loss at step 6540: 2.17 (2017-03-27 18:04:01.628804)\n",
      "training loss at step 6570: 1.98 (2017-03-27 18:04:04.667095)\n",
      "training loss at step 6600: 2.08 (2017-03-27 18:04:07.757066)\n",
      "================================================================================\n",
      "Lordrnd intrd fona sengours s dsathicont p. haly. alowatheth, KThond bl ys d ou!An, fropontysurfstoghiTot prith t t wsimoris ' haicr it s blurt cemo, wect gre fatallls alit ajesh.I sthan orsWhiver e VHy thoutewind houn ore ge win Todthirithas ckit y weelu h's te, ilothithaththo yer couthant at d an.UI hay mo omis.Yo amiore t t.Murint th ssI hins mor he latoouls tins mpimods mikio whthinclyoun.I lldien dandalloomousanon, t ar plo adithe.TLI lissour, lasorthan?IBe hanoryot: Hit, wo mpung thurarathast \n",
      "================================================================================\n",
      "training loss at step 6630: 1.99 (2017-03-27 18:04:11.387696)\n",
      "training loss at step 6660: 2.18 (2017-03-27 18:04:14.530874)\n",
      "training loss at step 6690: 2.02 (2017-03-27 18:04:17.656268)\n",
      "training loss at step 6720: 2.13 (2017-03-27 18:04:20.735149)\n",
      "training loss at step 6750: 2.08 (2017-03-27 18:04:23.788859)\n",
      "================================================================================\n",
      "Lord, inds hy,BEREEn n t.Y, thanore ds Ste I whe,SE onf rrWhy cod is, Singineerds p rg it p, me fe ber h?The ce?GGen remamoreers thisthicr d t'dithod irid ll d, loran RTh, ler ginge, hid,Mifly! hatqus thof pwnowas frt?Be y My whote CIsthesterthe wemy tr? wilor cagak, h bras, f wharline mECor,Ank, t  ares avel t J's h ancu, mus halorsteibor,'se todishaver as 'd brmathor th mint mathilivo d howiar sthirdy thour t hisin!N,Wonchit,FrndrarUxt thasthis omeillages ager.Gouly dr pmyor'd chencarer t ingr est\n",
      "================================================================================\n",
      "training loss at step 6780: 2.12 (2017-03-27 18:04:27.409650)\n",
      "training loss at step 6810: 2.05 (2017-03-27 18:04:30.524733)\n",
      "training loss at step 6840: 2.03 (2017-03-27 18:04:33.604364)\n",
      "training loss at step 6870: 1.94 (2017-03-27 18:04:36.721319)\n",
      "training loss at step 6900: 1.93 (2017-03-27 18:04:39.828040)\n",
      "================================================================================\n",
      "Lorderer furotor: is'ssen yovin y's bendAsend St mofo yoode tyoucif, nncr un:I t withat fees, CCowe?I overn wsshecht orlitrengno o'ssad NNOseyppak tr'shee peebloun mobes mengound alermiee ale,Whar, arechenonshentredroubrtrme ove he hou'd lllionore s, dsourilblourest me bulayerr: bulellees men, opr itly.Inoleracor!Exick profel, tes or me.BHyoully d ototoullleratalo, to d wisouswetToreithetr'dWhanoure Thalume mathome[Heslillefomene, wathitheringeaicaves tr'd qul medy igin' s hy mout. dshe-NCo.Whe hora\n",
      "================================================================================\n",
      "training loss at step 6930: 2.01 (2017-03-27 18:04:43.676496)\n",
      "training loss at step 6960: 2.15 (2017-03-27 18:04:46.815995)\n",
      "training loss at step 6990: 2.12 (2017-03-27 18:04:49.874353)\n",
      "training loss at step 7020: 1.99 (2017-03-27 18:04:52.920993)\n",
      "training loss at step 7050: 2.04 (2017-03-27 18:04:55.974719)\n",
      "================================================================================\n",
      "Lordathineed th eroulevigcobest ndeserthee wete'desef teeollll ouner sWere n.Woure owe owsarulebevelloporenigonofeelor tous. ke terenyoo rs My be chen: tyd, h hende tou ciaved: hatwinckicead cerobllyooueea wover, ber tesefor tcioustwimeanthout!We oupare tealesbees Colen?NTh taday I benthin hinMHe yobughaloreSe merearplerury odUfounape wis.Ane atexROMellal plutesUNYencavelle.He menous,Bl myancat d t thorine heiculinoby.Myo r,The ineate me tr nsus torfend gld stle-be miteshe u teallithathatilodd swato\n",
      "================================================================================\n",
      "training loss at step 7080: 2.02 (2017-03-27 18:04:59.546255)\n",
      "training loss at step 7110: 2.05 (2017-03-27 18:05:02.669899)\n",
      "training loss at step 7140: 2.05 (2017-03-27 18:05:05.758063)\n",
      "training loss at step 7170: 2.04 (2017-03-27 18:05:08.846388)\n",
      "training loss at step 7200: 2.06 (2017-03-27 18:05:11.915693)\n",
      "================================================================================\n",
      "LordU'lop mangeith h d hea t g isir menatr, thethaldA hy ftrderoousss.Sat d, s Ine tandesingicon't t watsthes, f y be eWelle monte meid be tof ofond the iongeesanset nou at se.I d bain-Had,A s orn.My sA hetorin dowhe ty's shespat Hacopad-Myous s:Ag w he Hipetorandintowat o wheru me s mitenchourlowayond peak atig a win buthanchanatthasOf I anctshin'd pmctuutind, bu,Tom teserin wne Hequrghakicoust oorounintrsARRI hers is s ge crd howOus ty.And wico wit, as orom tarn, in.Eng the ces?End s,Comasts nging\n",
      "================================================================================\n",
      "training loss at step 7230: 2.10 (2017-03-27 18:05:15.610268)\n",
      "training loss at step 7260: 2.00 (2017-03-27 18:05:18.689533)\n",
      "training loss at step 7290: 2.01 (2017-03-27 18:05:21.771777)\n",
      "training loss at step 7320: 2.03 (2017-03-27 18:05:24.868152)\n",
      "training loss at step 7350: 2.01 (2017-03-27 18:05:27.979880)\n",
      "================================================================================\n",
      "Lordeandin.Welime tch ispe athalllly yomy infende hes d touts tho mse: ndr g by hotrl thend thite foment ouchilff y affullil. fe age ty ond eang el he, id.Le! anROCr tunch.Toun gere t,My tt. at fthy[Or nche? arus,Wes.I dider,Ange s dy.I'd od mer menoutinthtseaworassatheng, ted, mas tanitss aigughelld mssethe texielofust whteee Haghas ayean t,Frend thiterfous alld, beTheit p?En, t ingeile grcrmerincucoous t ck tharathes wenchathingnckenitheave tllithit e raterst thoflODIr pAd s notye the t care the s\n",
      "================================================================================\n",
      "training loss at step 7380: 2.03 (2017-03-27 18:05:31.874283)\n",
      "training loss at step 7410: 2.02 (2017-03-27 18:05:34.940494)\n",
      "training loss at step 7440: 1.99 (2017-03-27 18:05:38.030811)\n",
      "training loss at step 7470: 2.01 (2017-03-27 18:05:41.140384)\n",
      "training loss at step 7500: 1.99 (2017-03-27 18:05:44.202227)\n",
      "================================================================================\n",
      "Lorde yoshore.Shouce, lillispes anthat-lomiance hofendUke.Sanes, hthe metamil.Anononsare coulllad.Theinthaven'se'd se oune hitoul f bes mathalet?Do, wie wity ithe bar!Evengomoucknchineerwinonowese'span t frngimo,NAnthecareorst ry th houng aty wOne fu'se opean I imeth ve heChile'd pererietokero, icke'satat fAReDton ng thalin:'sowakeshe bol.Sarem welil we acre plan'spe apligale domemereres I hee prsured st:-kendouner!Thofode ateas fanongr,Athomemour, me?Mu-inthe, Ched tathe con st?Wos nd ar.Gopr sthis\n",
      "================================================================================\n",
      "training loss at step 7530: 2.07 (2017-03-27 18:05:47.795808)\n",
      "training loss at step 7560: 1.99 (2017-03-27 18:05:50.918850)\n",
      "training loss at step 7590: 1.95 (2017-03-27 18:05:54.033708)\n",
      "training loss at step 7620: 1.97 (2017-03-27 18:05:57.074344)\n",
      "training loss at step 7650: 2.08 (2017-03-27 18:06:00.147707)\n",
      "================================================================================\n",
      "Lord my?Fovend, uvet, su onghine rveontebave se, by l-t.ME thers, f hals ave s arl y y ire milior ige Defotochotw, il I s Mad?Ayo n e quphy,Itodil s.PEWhoke chutorad mmara p mald s Toot sthal he Y, sabber me lllando, minsheouervers rncecishom tes aile. bo findss bucestle boke me wil pllerd anof avesss formed oucant.I o malyo ban: cle, r r as icoumala myove fis ss e, omate me, n! ouch h ples sus may ls chorne angan l l!Na es orst anser of cadopr, d I fo jid wnd bath sShtootamecooOs, to I dseng th's a\n",
      "================================================================================\n",
      "training loss at step 7680: 2.03 (2017-03-27 18:06:03.780391)\n",
      "training loss at step 7710: 2.02 (2017-03-27 18:06:06.843911)\n",
      "training loss at step 7740: 2.05 (2017-03-27 18:06:09.949318)\n",
      "training loss at step 7770: 2.08 (2017-03-27 18:06:13.043435)\n",
      "training loss at step 7800: 2.11 (2017-03-27 18:06:16.075571)\n",
      "================================================================================\n",
      "Lords,'s in d, t, ndSa nt En cel thal ghint I pe.Wour as chof o ar tontho agn-mamile m, sty it.RAr f avingrrs tu, mys merrrrotra sthe, s ke h th'Douriurthy f poul cir o f?Ener y d, bl'deef k: abar s, aty ma yo farthay?Ang fArker inen s,Whir fo d t hichaybl. thif ildlllop ghy, fHaith sthoores th poran com tors, s! the. wered an hathothe ishag, LTho tas ee rndurnt hormy toowimo ds t. bunand atereanast ston, thur,An twilf vitShalathabulderarngrs gherds,Bu I st.I hie ou,Wonco owil cak touler s. th goury\n",
      "================================================================================\n",
      "training loss at step 7830: 1.98 (2017-03-27 18:06:19.807424)\n",
      "training loss at step 7860: 1.94 (2017-03-27 18:06:22.856307)\n",
      "training loss at step 7890: 1.93 (2017-03-27 18:06:25.886880)\n",
      "training loss at step 7920: 1.97 (2017-03-27 18:06:28.916735)\n",
      "training loss at step 7950: 2.08 (2017-03-27 18:06:31.946941)\n",
      "================================================================================\n",
      "Lord, to frn jo Caivisoiewr mil mastonor, co atore half se bo le d arn havispous wisShyelolyoust, d h hateris wt whithe to whet-Th bullllis:ONraxior, morear bichora, t, tome wn'd clath t's s het$Y ghau omy n tearvo handUEUd s bof ghal wo okesurrTont alo mourisial t do rse bl'd as, he t-LHe f m ipthe th tofthame ho! thathiliep d it atsthory hum s ave athaugiged u whe ucoul, f vino ayong fat f'dodenad h, bas byomalid d med caly Rr, sHes l tits n st oudour ollipt as I wielothag ur the intha shais thil'\n",
      "================================================================================\n",
      "training loss at step 7980: 2.01 (2017-03-27 18:06:35.446280)\n",
      "training loss at step 8010: 2.04 (2017-03-27 18:06:38.482087)\n",
      "training loss at step 8040: 2.14 (2017-03-27 18:06:41.511185)\n",
      "training loss at step 8070: 1.98 (2017-03-27 18:06:44.552738)\n",
      "training loss at step 8100: 1.99 (2017-03-27 18:06:47.594772)\n",
      "================================================================================\n",
      "Lord ve.Couthern athabofot fobithowives ly pe.Cougend ino is, c he yor seat e EThiouproolet pTh! d cusainer swikses weaus-Hesod teBiturthais, thiorst mbry p,ADono t tle in ablinet bars ICaile, cry ovedousheralous andiee,'s ing be wanofugurootShs, houlereeldM thethingre w the, heareal lle NMyo fordorazo iersthitherct t thitran ppe the tAntravit PRaritThu, hnd.IGo coth ar Lokse boub, a ith foore, my,How ly V, y idr al, ves fous!I ter pous kes I with ifeachadousperet Thigs is jor's,ThagRH'e ared,Th ruf\n",
      "================================================================================\n",
      "training loss at step 8130: 1.98 (2017-03-27 18:06:51.090246)\n",
      "training loss at step 8160: 1.95 (2017-03-27 18:06:54.117281)\n",
      "training loss at step 8190: 1.98 (2017-03-27 18:06:57.149417)\n",
      "training loss at step 8220: 1.95 (2017-03-27 18:07:00.197245)\n",
      "training loss at step 8250: 1.97 (2017-03-27 18:07:03.236362)\n",
      "================================================================================\n",
      "Lord illllysh, dHthieFNowis s.Ifisis.Iweind tan'se isthil fo, ntAntht ge:Peag thakna then ouca Whin.Whin, pes.Hu.Beste n,Pathayous kitakangs sthsCout.Sady, s lowitedshous wasist sataleailind, gstintHe habe aseageradot in:BusepeTofot lan.Ed.Ebldengesethecainch tedeshithens.FENEn!Coury Bmed o llorle ghe, otemor, bees, bldCe tis, dsh hee.Hendrillle are,Tht LRGourefry, thnd, hate, blesto ithothorabougastadot bod,F weeAly yof t.Hind.Anye,Ase'd okn, d.Asmit ino,Ane.Eve arvel y thelr, I me, it shete.Hed t \n",
      "================================================================================\n",
      "training loss at step 8280: 1.97 (2017-03-27 18:07:07.000274)\n",
      "training loss at step 8310: 2.04 (2017-03-27 18:07:10.031459)\n",
      "training loss at step 8340: 2.03 (2017-03-27 18:07:13.062991)\n",
      "training loss at step 8370: 2.11 (2017-03-27 18:07:16.108201)\n",
      "training loss at step 8400: 1.98 (2017-03-27 18:07:19.152111)\n",
      "================================================================================\n",
      "Lord tCELer t t.E, sUNougn mane, she wan,O o by RAs, pren ave.I acld bughovimy ndar,Agh-d toureouromyole befo agsthal'le dHercearlyo msut okert ady me iloupumaththe mpionelve tif Gorft:IFrag hamepef, ttANoder. stl caminathakee obene,Ticur ino thamabicer t istkereriromy's fiarisis, be athanort been.Teatee irm plepro-cherye werouelybre renens wad: tr poulapere he ant--lennis beerdhe pre thtte dansearelaboue the tyowlak, f.ENicer,theamat walves Potischararprnd terte, whonge as,He s: ly!OCaved gere's me\n",
      "================================================================================\n",
      "training loss at step 8430: 2.00 (2017-03-27 18:07:22.637459)\n",
      "training loss at step 8460: 1.97 (2017-03-27 18:07:25.680132)\n",
      "training loss at step 8490: 1.93 (2017-03-27 18:07:28.712429)\n",
      "training loss at step 8520: 1.99 (2017-03-27 18:07:31.747475)\n",
      "training loss at step 8550: 1.99 (2017-03-27 18:07:34.799322)\n",
      "================================================================================\n",
      "Lorden, rvayerekis s wis, cas.An!.Burrth s ld tTheree unssetheabourethe nop.Iot aswo s, celins onaind dulooutokestureavour,NCplllomouan'ss CCEveapel.Thaprer ay 'shan I s therotep.We,YowExf se bul id,I awndou mar:D, or dL veaurd oucosty, Hay herss, y choourd s erorSTongh' fe treanodsees orerel maly horeris,Ag meroxThe ipld INofrerithar.Omyoncayonckethodaillllanse d dssecais:Y t scinou, fo whendeled PEnchosad.Gour y ouno brinthimy fila miglads: lar, e Sougin, pr, blivemIDoftet tomelvitsts,Totheiliscou\n",
      "================================================================================\n",
      "training loss at step 8580: 1.93 (2017-03-27 18:07:38.293268)\n",
      "training loss at step 8610: 1.94 (2017-03-27 18:07:41.336390)\n",
      "training loss at step 8640: 2.06 (2017-03-27 18:07:44.370097)\n",
      "training loss at step 8670: 1.99 (2017-03-27 18:07:47.393040)\n",
      "training loss at step 8700: 1.95 (2017-03-27 18:07:50.415838)\n",
      "================================================================================\n",
      "Lord s,Fans!Ifomely, menofofewoutaibewicas.I Howist tond pedis, olllonowhane Myome verf te lutthole' he dsthistieldat.L[ haremenerive hoknold thor o teldendom sl tencor ween,ALether, Jun? trd ite, four t me and findosaichonkele, atharicimugor.A wippre tor d persws at.Feasisipr: beThasirane h ompr mercese!Loug itA d. t s sur h. ayithagou,-bu.Tortayounof pr buners wiedonIUEmounseresiducou.SHatee wetrdous youDoucas: sorou.Tooredethapofuk, e, on?Ous, weashes o wip nonoun t erenemeevecreseaplaks ts,CEuno\n",
      "================================================================================\n",
      "training loss at step 8730: 1.95 (2017-03-27 18:07:53.937343)\n",
      "training loss at step 8760: 2.06 (2017-03-27 18:07:56.969791)\n",
      "training loss at step 8790: 2.08 (2017-03-27 18:07:59.994792)\n",
      "training loss at step 8820: 2.05 (2017-03-27 18:08:03.033215)\n",
      "training loss at step 8850: 2.01 (2017-03-27 18:08:06.081410)\n",
      "================================================================================\n",
      "Lord cagld ce ANPr no we this heatle hes I f ill oughishanous lowiay. sth, ornot'se or ghestuildou?Nost me f de ith we ctas thedilieient it, ands sI opins g'd: ganoule Ju h,thichasthy?Angha id me h ant tan whiederien splindote o t t nesthe f anstoullind m me oont an finds?A I hind he wishee. pay g Ger s, f theaveal fextfoort pont hatw sthou ome.Shy hoptel t REnThin. Do?Min d. vimat sh'spl yavenillof e ch'demivelis hof s bureaithoullod his nte s oucaL o dates, t thitok hinont.LA toucalan me winou. gi\n",
      "================================================================================\n",
      "training loss at step 8880: 2.31 (2017-03-27 18:08:09.574664)\n",
      "training loss at step 8910: 1.96 (2017-03-27 18:08:12.621395)\n",
      "training loss at step 8940: 1.98 (2017-03-27 18:08:15.656560)\n",
      "training loss at step 8970: 1.97 (2017-03-27 18:08:18.699426)\n",
      "training loss at step 9000: 1.96 (2017-03-27 18:08:21.729256)\n",
      "================================================================================\n",
      "Lordevearmu linthentot pratoe ashourest ounestt fate ptthimachingriecthig astinours tinotens,Bemanthat,Th sery wioucrethirid,An,Dund,-brenelathe?Gopre tolveren chthesthenchas?Anoururrpe and stoun higanathungothey hnsthout avendon te in thistMyour agre sheOues dourrersed boulvin sWad mernis,Adies ard servet geumben:TodenAnencritout nicond d thed's wake,WortusourmaKthe,madoulfunon,Is f berderanse h?Isipursinghthee hin'she okek,I gre I abasteayorr rengins sprith'Gouchen geisThowhisakeThend,Cathutouneed\n",
      "================================================================================\n",
      "training loss at step 9030: 1.84 (2017-03-27 18:08:25.223398)\n",
      "training loss at step 9060: 1.94 (2017-03-27 18:08:28.256616)\n",
      "training loss at step 9090: 2.05 (2017-03-27 18:08:31.294575)\n",
      "training loss at step 9120: 2.06 (2017-03-27 18:08:34.327225)\n",
      "training loss at step 9150: 1.93 (2017-03-27 18:08:37.358316)\n",
      "================================================================================\n",
      "Lord, dOfudeane Coringoufof t,'d, hincthelacousilld tha Trallven, rdIfupl woo deor watsw,Ife]Burvimes owetees.E d s id d offinaispomy whe!NENorid,Winsem,Mind'seathashe,R hileer?IMAshthe t the Ghe feepotondxt t, at, a ts?Antanstengooymowindanturens.Hond made?Ind itwayBrr,ThingrLOWhay, d.Norinost foo landy.An f ticang oun wiff aw!Nore se te ven,Tabofondostou,CEDhof thofaminshedOf mantwr'doruryoun hin. ly chalet tloully p,horshayoous.Sh stheanchotspil thano,Foowin sthandmI's le!Thenenorifay, reut, whan\n",
      "================================================================================\n",
      "training loss at step 9180: 1.90 (2017-03-27 18:08:41.116237)\n",
      "training loss at step 9210: 1.90 (2017-03-27 18:08:44.149237)\n",
      "training loss at step 9240: 2.06 (2017-03-27 18:08:47.170670)\n",
      "training loss at step 9270: 1.94 (2017-03-27 18:08:50.200179)\n",
      "training loss at step 9300: 1.93 (2017-03-27 18:08:53.215947)\n",
      "================================================================================\n",
      "Lord bur h be thougheryomy d wh ceaie I ner gentl alulleatol hile thor hahm, hie.ESend leanowo buneshe msthat heself s. wat plyofenthentofor than. thathe hin f we ng.Trert pe igh toure n allucen t s we, gre lelyof ber y he: d.EI ouleand Frseenes.Geme, th ter.Aset y. byo I's whengouasl pe met thent, astwimyowimechapr we, t ayono pent to h'd nere iaymyour be sw thu! be pand band iplad Rft, heck' cuphonchen dor ma behareadehen I inorert ofe ryo my grin'e he t bu thet wis, jer mange'thig timato tho nk w\n",
      "================================================================================\n",
      "training loss at step 9330: 1.91 (2017-03-27 18:08:56.712830)\n",
      "training loss at step 9360: 1.88 (2017-03-27 18:08:59.741454)\n",
      "training loss at step 9390: 1.95 (2017-03-27 18:09:02.769888)\n",
      "training loss at step 9420: 1.94 (2017-03-27 18:09:05.798010)\n",
      "training loss at step 9450: 1.96 (2017-03-27 18:09:08.825741)\n",
      "================================================================================\n",
      "Lord hat d an lth by RDrtwheg's ches.INOWe 'd pome od erlid Id ageitherm f?I hay jus,'s y I t prn ck is inillar fr nsp,Ande hatugad d s s whas y ofar bur o lllfimis warf me, whondid s t mave n, LA heringepr for-avat Heathin's male incOfo'tie co, hoods, thokishewh t, h br g ishinf ck wajed, ith a meaive f cllaish ma.Haid ll abran, Jonde min'sCA th mass. o l aris bldomp mo elis t, penthor ris ay to, t br w,To yonan Lits qure poder ish ch h?Hu,Ang ave rad ur byoug mmincal t bl asThor In t, s,Le.B ey m.\n",
      "================================================================================\n",
      "training loss at step 9480: 2.00 (2017-03-27 18:09:12.339852)\n",
      "training loss at step 9510: 1.89 (2017-03-27 18:09:15.380695)\n",
      "training loss at step 9540: 1.86 (2017-03-27 18:09:18.404105)\n",
      "training loss at step 9570: 1.91 (2017-03-27 18:09:21.431966)\n",
      "training loss at step 9600: 1.90 (2017-03-27 18:09:24.468585)\n",
      "================================================================================\n",
      "Lord utyorore ory s o on? tettl.I po uliowhokingu ted himestolyBONI g.I rd dspigiousucr.Yeigit hiny ais n aty.Ly-by,Thureiry thimiellanthango!SAnforel med coat dyser.O.Moferer t ayourenge, ds GoweereesBer kiswlinonthecu, y wie ou n,Houfetou or'ducet bowhe fure.Thoulat ald,Tontagshon figrithay,Wielisher theran plomas wnct ffore otete wig t y Tod o byoucholllorereh y thourth shit By Yofotwinveaswolellullerramofor By'se arechous ty sthe, minsord nd RRStIpo talofuthe CEy 's arin t tore.O!Tothipestu may \n",
      "================================================================================\n",
      "training loss at step 9630: 1.92 (2017-03-27 18:09:28.191330)\n",
      "training loss at step 9660: 1.97 (2017-03-27 18:09:31.235492)\n",
      "training loss at step 9690: 2.03 (2017-03-27 18:09:34.267810)\n",
      "training loss at step 9720: 1.96 (2017-03-27 18:09:37.298512)\n",
      "training loss at step 9750: 2.02 (2017-03-27 18:09:40.328595)\n",
      "================================================================================\n",
      "Lord gryoraispr'd te  he ablory or s te vell air.Sine, ns arsI weditI than's ario-ildous, workigir ore olifrnghallat burr,A itous, iathenes, milde ame esim caprerthe!ARI' ces ch lld t, ase minaime! y f are?H d w torsplos a hist moove porainve pulor.Cpupo foura femyin Kesis plorewole heniveblie Whisowe, erome pon.Tirtho,Thes it wne y hak y sovesterf prfa dhiounchns is rrel ser wext ilallat k twire wor Al mompr's befor me aroule wos d her otr terve, thovif 's mblous,Toure, o wethachorseTha foofifu wou\n",
      "================================================================================\n",
      "training loss at step 9780: 1.97 (2017-03-27 18:09:43.821089)\n",
      "training loss at step 9810: 1.95 (2017-03-27 18:09:46.855450)\n",
      "training loss at step 9840: 2.03 (2017-03-27 18:09:49.882880)\n",
      "training loss at step 9870: 1.92 (2017-03-27 18:09:52.911692)\n",
      "training loss at step 9900: 1.87 (2017-03-27 18:09:55.940678)\n",
      "================================================================================\n",
      "Lord a theThe s anst terme thamye I l wads: t o wat s hak henn, mngere mowithod g mee t: temese akilu meals theWu at tToulllden.EShy t mee fofomen, yp y f bal fok lenorethant sthousucend wot atTang wes.O! ino med t a be t is inaut Prlodsit.OREfttho feldWhatrers wh ietw te I yed meas So, courise, whin?Aliset, n w aknginexil wisthe sthe me thoou e l CCan, y mppanocanthy: mervind terithe whilofoly. owo s lodithnithe t y ingtAn heatun.Enu: twisod, try,Wis.I trare.ENLowok s he IO we m tou oubrcosl t f e.\n",
      "================================================================================\n",
      "training loss at step 9930: 1.95 (2017-03-27 18:09:59.445880)\n",
      "training loss at step 9960: 1.90 (2017-03-27 18:10:02.492824)\n",
      "training loss at step 9990: 1.96 (2017-03-27 18:10:05.519157)\n",
      "training loss at step 10020: 1.97 (2017-03-27 18:10:08.548925)\n",
      "training loss at step 10050: 1.90 (2017-03-27 18:10:11.580875)\n",
      "================================================================================\n",
      "Lord o s anth halde akthied burest ong hitheil. chendo thwisthngr vitu m?The Ede thinilfon thtROthintedireppe!Couthit grume y nd.Thot, thathent mbebenges wsen ased aushenge Inagnople owis g ca bepofEvesht, ldshsCople ENEOure d owedseThadAn!NEnin, voreit htherrrshanano s,Yomenee lls f yese cr,A hin ty acatherty.Comesthishe,SCovequllyouthen!ERSEd, loutethan ofthastur, anor bls hitozaseprmAn:IBeelldsheas'd dowe urong thiowncht hthotherequplystr,Fon?Bethistotthy I asstorckeanont wase wean ngkeped g tous\n",
      "================================================================================\n",
      "training loss at step 10080: 1.99 (2017-03-27 18:10:15.345454)\n",
      "training loss at step 10110: 1.99 (2017-03-27 18:10:18.382963)\n",
      "training loss at step 10140: 1.92 (2017-03-27 18:10:21.405171)\n",
      "training loss at step 10170: 1.92 (2017-03-27 18:10:24.439887)\n",
      "training loss at step 10200: 1.89 (2017-03-27 18:10:27.637258)\n",
      "================================================================================\n",
      "Lord str orokerf y.Wirsoitondesothewicabrloreren miemeaviomy If wise fofesher d.Thit whadedad ye d toucke'demowhintur ghes thinferoules s pr.St gllivendedssTh's.Dinmes lley bye ts, westhewancuthais m m wewence,Whinthaprt hange. sshur'shey t s t sT,Thine I' EngheageothosesularisHonwine he d nknsthetist dst iveloungh'spishy wiloranothity'l CMy hanted,Hea mes nounieeshnd he ctise hanesetr bugher.'shern se hend uple horth I kesis ones: yo.Mouthalanery.EDing melerer blopincak Shoend, aneis hilervis wirai\n",
      "================================================================================\n",
      "training loss at step 10230: 1.85 (2017-03-27 18:10:31.346124)\n",
      "training loss at step 10260: 1.94 (2017-03-27 18:10:34.608588)\n",
      "training loss at step 10290: 1.98 (2017-03-27 18:10:37.713281)\n",
      "training loss at step 10320: 1.91 (2017-03-27 18:10:40.788847)\n",
      "training loss at step 10350: 1.97 (2017-03-27 18:10:43.890101)\n",
      "================================================================================\n",
      "Lord unkemen plingnd swnaboumake, hotitee hil sthe,Tabered te oushat tharnouberr'shodaKindugisMyoshe aiss verebo ANeiustand Ind o fofuthto ollimyswobire sthien d hive hellisericesplomyome,PHes, lereshasthe ute rady'ere renste may y oware schopr Ofipamin wes t-hald, alder foffoun, mmecthats Is, wite wnave t ined pe te dowad ftThithn, suthayousecu qusrspese, pou dr kir7boo'send.WhisWis, ds, uped glothar twer an'stref t Caisspou monthisisenormatovoue ovequseoshandaceapacou atine wino Whay ndsor fowours\n",
      "================================================================================\n",
      "training loss at step 10380: 1.84 (2017-03-27 18:10:47.466148)\n",
      "training loss at step 10410: 2.01 (2017-03-27 18:10:50.577434)\n",
      "training loss at step 10440: 1.93 (2017-03-27 18:10:53.732294)\n",
      "training loss at step 10470: 1.89 (2017-03-27 18:10:56.797263)\n",
      "training loss at step 10500: 1.94 (2017-03-27 18:10:59.860336)\n",
      "================================================================================\n",
      "Lord OP] dotettens f ie, my lin we dI brtowhand at qunet--ht towistthiveld fat.Comyshe ithelouit thalyme'e f s an, get mplou owhousind is.I yo,N the-Thanter d athe fw eadosag sor heTo on'lesir acranOutf the y ghoupaces, alomive R shave'dyoratharop'This prck, heer, topecUCheriellldees mirindon se s mithery thondits fis ajURno the o hats yer me.Tat me then oronkthaipitofuro wag andLar be, l aneat ge Goulichethevese, tead,Logeredet?NHarececlibuthenily,I,OGkian d he wio th ses gepayof o, le ndo elarathi\n",
      "================================================================================\n",
      "training loss at step 10530: 1.91 (2017-03-27 18:11:03.691064)\n",
      "training loss at step 10560: 1.95 (2017-03-27 18:11:06.748082)\n",
      "training loss at step 10590: 1.94 (2017-03-27 18:11:09.803372)\n",
      "training loss at step 10620: 1.86 (2017-03-27 18:11:12.891030)\n",
      "training loss at step 10650: 1.90 (2017-03-27 18:11:15.996320)\n",
      "================================================================================\n",
      "Lordorrt ma may war d, w hicath,ThanttI s thaf ho recea, provey mbrrant lletam: sthe My, becas.Go mor but t aso th, ont an t t t m d, Mored pe br!ABy fagay sthe myou byomy isoust ndo ourtowr e hoth ad,Aly ul I ha s rthits y,Ifo f mithe.Bungat hongl p wqusind ovelly?Weee bacerets I byThoulemy ms w-myitSor, ceron dandideaf chein y ro.I hald,MIfanSI Atsprthithalllersteed anth tyoun?  I pru ts forow Wim t map trtha ypelady agelet t nth y, p ave:Pll t myopilol whars for ithiledy?BO.Fou Pit blire our min \n",
      "================================================================================\n",
      "training loss at step 10680: 1.85 (2017-03-27 18:11:19.610351)\n",
      "training loss at step 10710: 1.96 (2017-03-27 18:11:22.703389)\n",
      "training loss at step 10740: 1.97 (2017-03-27 18:11:25.794543)\n",
      "training loss at step 10770: 1.90 (2017-03-27 18:11:28.884685)\n",
      "training loss at step 10800: 2.12 (2017-03-27 18:11:31.945607)\n",
      "================================================================================\n",
      "Lorde wher:Shint anceer iellle wigelicer, ftofe chan.Are veed,Llagre mereeranomas, ing tTheu,IMases. ou h splinicreanourte s tonef ame Feagorat pokethil h ecad I's, f d, pr one bechillanofaienokn wach'shior d urewhers.I he:O Doven wape ome ssthth ge panounos I ag ts ho.Wher twarclir, wens! Be t m fecert.N, plicouryored!Ang icTofr.Wht ge t tldswisThe, s roreseite tlobyo 't sar, beewhanapendIThainkndtheel!In.Itomamay y.Cly omaive l ma aksted irndore s fithaces soouns,Beg pane er I y sfother.KDolastouc\n",
      "================================================================================\n",
      "training loss at step 10830: 1.85 (2017-03-27 18:11:35.571020)\n",
      "training loss at step 10860: 1.96 (2017-03-27 18:11:38.740001)\n",
      "training loss at step 10890: 1.89 (2017-03-27 18:11:41.983682)\n",
      "training loss at step 10920: 1.84 (2017-03-27 18:11:45.121380)\n",
      "training loss at step 10950: 1.92 (2017-03-27 18:11:48.226441)\n",
      "================================================================================\n",
      "Lordors hild glonIs mo maveyon, daks. I I f thooutwhavesateweMapthamullipes, mare, f dotrexmandersely:Tourioume yothalellySYel'su marelanird h, fatofofinghour mu, burseerlalee tolat tsthagrts: mathet e ldWhancorstLEGI y wsinon! yoff amangeuar musivourtherecice haversIfor'Cal hatent, he,Yowenwigend ts sayosepuchy or-be th Prteaverdodofooner, itoougok d: a meho m yol, fan, Eve fe, as touserthenell toco'Ben: r r my a Jy:Re. ine, be hehenThofinkneiced  mal.I y?I meaneret Inder meavedonyd hangeif I langn\n",
      "================================================================================\n",
      "training loss at step 10980: 1.96 (2017-03-27 18:11:51.729864)\n",
      "training loss at step 11010: 1.89 (2017-03-27 18:11:54.769531)\n",
      "training loss at step 11040: 1.83 (2017-03-27 18:11:57.801242)\n",
      "training loss at step 11070: 1.91 (2017-03-27 18:12:00.836247)\n",
      "training loss at step 11100: 1.96 (2017-03-27 18:12:03.866371)\n",
      "================================================================================\n",
      "Lord, thatilllir, s hot! fu:A ou th k, l ce, y, kithe hes t half he you nghame! w, s wakis pr-puaild dedelyowspeind-Bed, w tro cr my he: mo th k n a wo te t ws s, w lfand mashaks?Thau Val.Od. d bu u buswo or id preot of wrid dr: de t sosaveas I s my st t d f usat s at uloupr h?Ingnoo wowas fy I!Dome t han ngherrant iveby meatal'She att I or, th hthor ar w we.I myetig a wn: I he l h'silan wa whee s w h m havil bowestou llind. nd htwhen cungone illy h tant le ath y ie my. the s, st la ff wre s lid bu \n",
      "================================================================================\n",
      "training loss at step 11130: 1.97 (2017-03-27 18:12:07.383703)\n",
      "training loss at step 11160: 1.92 (2017-03-27 18:12:10.429938)\n",
      "training loss at step 11190: 1.90 (2017-03-27 18:12:13.463915)\n",
      "training loss at step 11220: 1.92 (2017-03-27 18:12:16.489957)\n",
      "training loss at step 11250: 1.96 (2017-03-27 18:12:19.506825)\n",
      "================================================================================\n",
      "Lord gL m mI thie I?The, s m thof fthee wengeristhep ll wWheme p.I otharst s o tom slsis ss su cof, chith d roulishorwh Whin. qulofo lodove'd inot wisivithe ok hived pa fole t ir u, l y id, Is fond eme d's! saly tyACos deerongacheemomathedin f I t sheaye ff ccllybe mo twiz ive Gate,As susis dASh lowho fovePrdip s g thousThoghaive hy t bl Jo thnd or sathe moothngheshouchsstI ve-qurI ifanollyouto st atl s l s thilinend.No of witStweh clove ie ist ivit ha mbaris t,Whis s, yon gs wn An fucked Drer pl at\n",
      "================================================================================\n",
      "training loss at step 11280: 1.86 (2017-03-27 18:12:23.007946)\n",
      "training loss at step 11310: 1.90 (2017-03-27 18:12:26.042858)\n",
      "training loss at step 11340: 2.04 (2017-03-27 18:12:29.078031)\n",
      "training loss at step 11370: 1.84 (2017-03-27 18:12:32.097306)\n",
      "training loss at step 11400: 2.02 (2017-03-27 18:12:35.128434)\n",
      "================================================================================\n",
      "Lordisieir age-ckerlyf wim'dserere?Fe the: t momiste the fowagrendulyere, pr bemove? d tak fte. tstothithets, s ald plithit atre Vl ims mik t sse,Har hater'soman otepryalor f f re d marou, buinck hake, tSherearothofomene t hilds f win blath: g'lo,Phothete ongr-wigerren t aisw.-ke, l that t'lat bo! prden Witu--lotharmeatore If tor, tefugok'dithisthathar My,ARFead nd cis he the,TUn che! nd ort histhCat silomates tithomarith teith'secuis ndALIste ERUndsintodoropatw metayeadowanth fee tht llobumou,Th o \n",
      "================================================================================\n",
      "training loss at step 11430: 1.89 (2017-03-27 18:12:38.891869)\n",
      "training loss at step 11460: 2.07 (2017-03-27 18:12:41.963539)\n",
      "training loss at step 11490: 1.94 (2017-03-27 18:12:45.009342)\n",
      "training loss at step 11520: 2.00 (2017-03-27 18:12:48.045429)\n",
      "training loss at step 11550: 1.89 (2017-03-27 18:12:51.075318)\n",
      "================================================================================\n",
      "Lord y whend ther In, sthimamedrsiconthan y sind tharff grnoridThabe ed the, I y the?Tisprist chot anonthe.An tushe. Youreango hend, henge:A pyshorenare f serenkernwee cemeireeser, hator wee twerealll h theathe nit athe, I cks,Be mee mewof nd burTofisheen'se, peie incuce urn t ave hno s s o five by?LI bee mo. s Ceald, en pCo r non toucuthese.OBavehamaye g benden pthand-lily y Tolle Shtr t l ay pequkisese thar t s my.Myeetlerthier'tor sishid, athounesel canousot veavivatinsilathe, me ands Faler Myerk\n",
      "================================================================================\n",
      "training loss at step 11580: 1.83 (2017-03-27 18:12:54.583233)\n",
      "training loss at step 11610: 1.94 (2017-03-27 18:12:57.629679)\n",
      "training loss at step 11640: 1.95 (2017-03-27 18:13:00.679012)\n",
      "training loss at step 11670: 1.92 (2017-03-27 18:13:03.715629)\n",
      "training loss at step 11700: 1.94 (2017-03-27 18:13:06.760422)\n",
      "================================================================================\n",
      "Lord sed fontou d bon alshabl Galyell sttwize'strtlllver.An, sslshay touentoryeghair turaind pe: twir ty, o my thiandd ted, wany.My I tanerof wond tore 'vill nofiman mptontweesmas SVy al mo t h mS Heafol th wan pr thy.EnsHyova st merand por ant this se shanacl, n, orr ot oore my pl the gonimyowhisAne tinandifthe fr mordyelis.Sert pr ant prd whintman,Hanomoraf wind flou,'dDHost.Indoucoore: Brortwavewhe othiss thYorlmbendorhanfan LAs qutI sid malin ver st!I pouredr?Whaverean,Wingoon?AI anth,Ye me oul \n",
      "================================================================================\n",
      "training loss at step 11730: 1.93 (2017-03-27 18:13:10.259805)\n",
      "training loss at step 11760: 1.93 (2017-03-27 18:13:13.311061)\n",
      "training loss at step 11790: 1.97 (2017-03-27 18:13:16.339680)\n",
      "training loss at step 11820: 1.91 (2017-03-27 18:13:19.378673)\n",
      "training loss at step 11850: 1.88 (2017-03-27 18:13:22.425113)\n",
      "================================================================================\n",
      "Lord y, curareler I anourve lelalsthiamaim ore thathourthompeMulliech payoverINonangonounor, pilore ag thy it! wndigron, witeiret. I car.Hestund, u banengreain:Southe urt vege: wnd t.Tove y, iset l dimaleathekelle car,we blecethesha yousun t osherougqurs, y, siendge.Foupr, the t n thouporothaty bay thethereyonts, dwolds Ithnd are, J'To thindcheag.I hakecotharirndAneremy d! mord, prys t theet mat, de meresos.The stowarvende theshy, f fo d ohithomellehiong Je me wstsefobund corsDrt,He, se the tond Jel\n",
      "================================================================================\n",
      "training loss at step 11880: 1.86 (2017-03-27 18:13:26.164653)\n",
      "training loss at step 11910: 1.84 (2017-03-27 18:13:29.211195)\n",
      "training loss at step 11940: 1.96 (2017-03-27 18:13:32.248000)\n",
      "training loss at step 11970: 1.98 (2017-03-27 18:13:35.287985)\n",
      "training loss at step 12000: 1.88 (2017-03-27 18:13:38.337594)\n",
      "================================================================================\n",
      "Lord oknd meatersthe haith, bafishefoumelisededilearferelyodissalalayTARV mearecWhesheupakYou se isentou cll Qullisees, mu t and h.Hetshafr st he phauset harece 'sOf n theceersecl IHofary, hell hawalilenTwareangee,I the ghel renchno pe talll houthostond.[Sot.SHedishod'd:Have, s he fe bind t ye?O.Whithe he s wis os m.I githe.Lecaberge tidiliderateno.I'so Itaty, thee n y, h yd ber]Wheanth!AIpat it A d ceshe leat sI'st and wis are ngldese averea f dist, atinenofl rr hafounkellly at, prequst bum toullar\n",
      "================================================================================\n",
      "training loss at step 12030: 1.93 (2017-03-27 18:13:41.831515)\n",
      "training loss at step 12060: 1.88 (2017-03-27 18:13:44.875320)\n",
      "training loss at step 12090: 1.94 (2017-03-27 18:13:47.923083)\n",
      "training loss at step 12120: 1.93 (2017-03-27 18:13:50.971621)\n",
      "training loss at step 12150: 1.96 (2017-03-27 18:13:54.004124)\n",
      "================================================================================\n",
      "Lord malld s t I blekitorn, mategUSpenourichalierr hay ar ourepowiceBeste n othy asu soo. an m.IAnove hitonte th d t, bled erone harr row d tUpllind, Tiel trye ho bor chtithicheaghmon au flyon thipr, t l kThur'sha t urelous try ilinmenel.Y, tyins, dur pind tho anonge thispitand, omitwitishepont wha] rorr tin hiramu, bowhireed ouerorsthowild g f athen niea h macatMa moongu''d t thatway thay I hothaspCong tishitlominDeg, ontot adoubatt sothaf deog h heeoril y. ffiert w ce ce sechar terth ave azer. Jor\n",
      "================================================================================\n",
      "training loss at step 12180: 1.97 (2017-03-27 18:13:57.523640)\n",
      "training loss at step 12210: 2.01 (2017-03-27 18:14:00.572464)\n",
      "training loss at step 12240: 1.98 (2017-03-27 18:14:03.604091)\n",
      "training loss at step 12270: 1.88 (2017-03-27 18:14:06.622754)\n",
      "training loss at step 12300: 1.89 (2017-03-27 18:14:09.650599)\n",
      "================================================================================\n",
      "Lorde ndir alviceapt wAur mo mo m,I oun, your rerirspuremouly hatRR wit.THe sitsour qupur lan k sonde g thad ken I wirig ry orr, ar we: isWo bavest s t aid otak pl t: s me mircte whey thinre,A is oprlos:Ang arlomestheid,Bokn's athinourr s itye. ndidThivak'lllolieprst yoprot mathed hy its withor-heuth ivind, the feye op we s pl s 'latearicos wh'se gey wawollomWher. ad,Tom Whe tishaply sprt.Mathalk alerousne, thagrtindl pereveg esthte baveed the wakungl yBulong, ves cid couou ha atOuprait hat d y yout\n",
      "================================================================================\n",
      "training loss at step 12330: 1.99 (2017-03-27 18:14:13.155888)\n",
      "training loss at step 12360: 1.88 (2017-03-27 18:14:16.192482)\n",
      "training loss at step 12390: 1.85 (2017-03-27 18:14:19.219892)\n",
      "training loss at step 12420: 1.93 (2017-03-27 18:14:22.251008)\n",
      "training loss at step 12450: 2.14 (2017-03-27 18:14:25.282878)\n",
      "================================================================================\n",
      "Lordomar t ofome! bll fours nd bld.MUMavinthest a pr s t an h!Takenswakelven germin wa,FCan wh r ur o,  om t t ffouefr,I f aunginds to scort d shin'ldrrghoushool: f t alasmy SYicle ra pr f mourthaly, Q ththero alis icoutsNo hilan ma s tthidanDOPheplard t mnds I in ckis at o kt.O the, e ful thisin ld, f ke?Yothasild.And that hare y RAs,A tenthiath k. o anaktsher tenen.Ibosttserere so t it IBu aniorrowprdoind adaurithain ' fo e kint,Dou he, ber, aplorst hin sty s ffy,  thachoromar amurNom than ve LARa\n",
      "================================================================================\n",
      "training loss at step 12480: 1.95 (2017-03-27 18:14:28.810834)\n",
      "training loss at step 12510: 1.85 (2017-03-27 18:14:31.842639)\n",
      "training loss at step 12540: 1.87 (2017-03-27 18:14:34.875234)\n",
      "training loss at step 12570: 1.99 (2017-03-27 18:14:37.902554)\n",
      "training loss at step 12600: 1.88 (2017-03-27 18:14:40.936448)\n",
      "================================================================================\n",
      "Lord avent. imallleksplly muret w! wat. pr t of or'ste r olou se hernty,Yo, winof ithalout at th d ateanoure r ther angot baf ow-are t hafa, lakien? mish pte ldTwan praicolount ngher.Sto.Nopeaterth bls ind ngat apolyour te t hen pl!Whow?Th ghe l ofrchall uchies, ind ge malo me hen y:Chinge, thive h's w ese, myetto se oor h SprBed hillout anthilinor, musithe teses f ake, l se chell I He. douth?Hind pred, kean.Grafre I her scard I th,To s.Wake meAn TOBOTharis tate] s: hitor k bu Gofr ll t thorenty my.\n",
      "================================================================================\n",
      "training loss at step 12630: 1.96 (2017-03-27 18:14:44.664363)\n",
      "training loss at step 12660: 1.89 (2017-03-27 18:14:47.702237)\n",
      "training loss at step 12690: 1.75 (2017-03-27 18:14:50.733722)\n",
      "training loss at step 12720: 1.92 (2017-03-27 18:14:53.762031)\n",
      "training loss at step 12750: 1.81 (2017-03-27 18:14:56.783942)\n",
      "================================================================================\n",
      "Lordy, f s dr: glen,IAs lfofimy heecCly ave.My disirele dag d cowisitrs wan oborowis tequ he. llumeretovencefre tou. y:I'Byenn ano,OWithus wous, we the,I wige pagh thy faw Ine, haus:Thes keshe ou. knerermebubloze:Gluse.ESimitss. wencerare,Sthiereat s hellecthtoud y hisco win's my dal wheIssbl fid who wirthont, y, eando?Andsthe, she I t ithee'O,-ldemarf!Go an hitha goveak wht llyofo hy, ghomeninore s l, thighof, bongen wit e nrndorased chewaimyottofopreeinSenos?Wha aplllooo y,Wehativerithago s's LI I\n",
      "================================================================================\n",
      "training loss at step 12780: 1.76 (2017-03-27 18:15:00.298391)\n",
      "training loss at step 12810: 1.89 (2017-03-27 18:15:03.332578)\n",
      "training loss at step 12840: 1.86 (2017-03-27 18:15:06.358845)\n",
      "training loss at step 12870: 1.83 (2017-03-27 18:15:09.391988)\n",
      "training loss at step 12900: 1.99 (2017-03-27 18:15:12.419858)\n",
      "================================================================================\n",
      "Lordenouroupr ben I sthermer bupompoonghy sse y t ngasel-denchothteay tritourittshitr t as t arr risuten ng, domathes R w br acorveu nt wos t s mivelomThallousaruss.Grt l harxthy whe t, macamor mereryowhan, ong biodolome, Lors nstr histaprre, s atwin thaken th l t ishowh, mand burvorth marmones, bererintarin tsairthay l,Thid at nge hongret Ino bedCETh, ayoitho h cho bufowit dll wou, soth,Re?In igrinthedite mef tusthat'ks or wid t d itho drd,Whinl Co d he tur ald IndEShe wivin for e thothe tunl: h d \n",
      "================================================================================\n",
      "training loss at step 12930: 1.88 (2017-03-27 18:15:16.358960)\n",
      "training loss at step 12960: 1.86 (2017-03-27 18:15:19.378538)\n",
      "training loss at step 12990: 1.81 (2017-03-27 18:15:22.425403)\n",
      "training loss at step 13020: 1.89 (2017-03-27 18:15:25.464093)\n",
      "training loss at step 13050: 1.85 (2017-03-27 18:15:28.492446)\n",
      "================================================================================\n",
      "Lord Brd veriz eis, Sescrove ou.I ouiearoristist, sthapeyewaneseTht dy, chelyo't, tres stel aveanourmenind orse hUCost r.Yedrtwo,Hepundopely thoranthellaileave hame ouryo sithfuctwhagainousoulancawin te thitufoonondser, h cancopadorear,Andsu, ut andintoulssth wie-t ffe: dserimustaszin id terdontowe! t pove,HanthedBy, thold, s powizesthshagnces taisoustas?I fre s,Le ano hyousosereedid m ly,Ansosernoulo benthabeamo'd?LHerte siese, thon mounkemet mare.Le--gll-diste sind f Fat t, CHare as Lithorty y sar\n",
      "================================================================================\n",
      "training loss at step 13080: 1.91 (2017-03-27 18:15:32.219450)\n",
      "training loss at step 13110: 1.83 (2017-03-27 18:15:35.261528)\n",
      "training loss at step 13140: 1.86 (2017-03-27 18:15:38.297895)\n",
      "training loss at step 13170: 1.92 (2017-03-27 18:15:41.337518)\n",
      "training loss at step 13200: 1.82 (2017-03-27 18:15:44.368927)\n",
      "================================================================================\n",
      "Lordes y?Aniofasen me.RIne me pry owis tTowilin st o ollyoun, t t tabopengaimatene, poursear both wrofopoowinigavin, y yolave ingo mif St ar ur he wise mousu antage aghoucait.ENo foryd bees s, bll m I haginoffouthit, er pe nou l ofoury ar n ishoushtot af aleme oubyorilase ime mernd n an Cak he.Kandanthoret le.Helighis: I.AGisomat fook, holle: thore, ary be: here I sWCotheres talf arepole ak y s him] y hig, exingot ut or, an y mulvintexhe, meresw sis in  tathio br,I k trureresunies, s oucan.O fotw. w\n",
      "================================================================================\n",
      "training loss at step 13230: 1.91 (2017-03-27 18:15:47.882508)\n",
      "training loss at step 13260: 1.87 (2017-03-27 18:15:50.924946)\n",
      "training loss at step 13290: 1.82 (2017-03-27 18:15:53.957776)\n",
      "training loss at step 13320: 2.01 (2017-03-27 18:15:56.991502)\n",
      "training loss at step 13350: 1.95 (2017-03-27 18:16:00.010128)\n",
      "================================================================================\n",
      "Lords ms t thes yte, ce d plly, y. fll:E her-k Fr janonolld wale mer andy ard why er,Un than athot I'sh PE crd!WhtBreinding t aiprdd ag t wnd myf anand Lont tsas teeantat t, fus t ayofindANEn m.Tow'stathe cisthave pe t won'd ar wadFre bais s: lly-sate s ounothwivemenghrosacace.Hedof he mis, she d f t be whit, t s ufur cTuze!Tokend I d wo d on, yorbok allf alerl ond al ule ustea P] by s. futh hed.Inke m wot, th d wod so the, aroteang me ugr I andrdithiar'd harlll s thogof t nderys vis hes taf y sth, \n",
      "================================================================================\n",
      "training loss at step 13380: 1.80 (2017-03-27 18:16:03.517200)\n",
      "training loss at step 13410: 1.90 (2017-03-27 18:16:06.554545)\n",
      "training loss at step 13440: 1.83 (2017-03-27 18:16:09.576840)\n",
      "training loss at step 13470: 1.80 (2017-03-27 18:16:12.605471)\n",
      "training loss at step 13500: 1.93 (2017-03-27 18:16:15.644221)\n",
      "================================================================================\n",
      "Lord Mar hotht t wans,Whmine. lel Momenowaicasive, t h,Frin veyor whe d t plll g whitomanoueasth, umpththigand save  that ty FigouFacavie! d llomowowhoks, dus.We qurd,CRExoowisth sthoutailedimely to shay fo'sthe hanthagit hat th's an, thimeisenthy ldichofad arend st! tiomuned pe ivewers theres pr'd at! capon n.NWes'lunking ooit thestengoutyo!Hotoute g himellured thourabur l me thidrs oupick veu, habet tubuCofllotor f nt on: bewethy mafirs, clevis wagh utwaghiowhe yorHayal aictyeecundAt ofelvil, wita\n",
      "================================================================================\n",
      "training loss at step 13530: 1.95 (2017-03-27 18:16:19.396468)\n",
      "training loss at step 13560: 1.97 (2017-03-27 18:16:22.433873)\n",
      "training loss at step 13590: 1.81 (2017-03-27 18:16:25.455364)\n",
      "training loss at step 13620: 1.88 (2017-03-27 18:16:28.482064)\n",
      "training loss at step 13650: 1.86 (2017-03-27 18:16:31.507526)\n",
      "================================================================================\n",
      "Lord d?Le viswis!Sstermareake.ALet If teatoma hou uphe PRIm Wed at wnveane.Pe?[A fe tr' s of merdst the Ed Vher: f d, houcar, wan ave hy me whe har! thy wind,RRay I d s, he ico be ave ayo Inefou olowar noom!AROLo CAntold.Heds LUAnd: ve ste:I y he htel thys t ungiraigorl s hia, y: fthiqu t, bivele rRe Mour s.Poof, ll PHavipentha medeacrre nThen.Hithol id my-d,Bu.Mork z gor milf, derShe wasongo an It in thowe, wardAmymo f cure.Trds s PustThithe arive d, harintwiser l t brd, acre weho haithobo moved s \n",
      "================================================================================\n",
      "training loss at step 13680: 1.92 (2017-03-27 18:16:35.003080)\n",
      "training loss at step 13710: 1.89 (2017-03-27 18:16:38.043352)\n",
      "training loss at step 13740: 1.86 (2017-03-27 18:16:41.075689)\n",
      "training loss at step 13770: 2.04 (2017-03-27 18:16:44.259877)\n",
      "training loss at step 13800: 1.86 (2017-03-27 18:16:47.396978)\n",
      "================================================================================\n",
      "Lord t pile. meth'd res pe oore: e arenecelend ce m land mensthesth dodere thin t nonchid m anathved, s e sm owr' seetHieie be.I ainealer,Whett oulit thy mitWof far sbe blind ayomat!Ir hiner'd y ck tchege I othe ye rand oleareer has,Benewin' Iselay wror!I f bliveran, lelfus myo s magenen e ofof s I iormbus h,Farout it, owislameedmnd rowietsad neellevituear athy, Wifo?Wit r ng theThyoke Bu,NNomun ot wendour thit vethes, mealle,Anke alvere y thy'd h d, strso thome steavesece h iore ayo th t froreme hy\n",
      "================================================================================\n",
      "training loss at step 13830: 1.81 (2017-03-27 18:16:51.043631)\n",
      "training loss at step 13860: 1.90 (2017-03-27 18:16:54.120536)\n",
      "training loss at step 13890: 1.94 (2017-03-27 18:16:57.212822)\n",
      "training loss at step 13920: 1.82 (2017-03-27 18:17:00.321523)\n",
      "training loss at step 13950: 1.77 (2017-03-27 18:17:03.510022)\n",
      "================================================================================\n",
      "Lord pon, wistixtand mese,Hat st s me'st-Frey.Gis I e my'e hon.RIO dof oullil,Theds myonissHore: ice agle agllore meand sichangharemele m ou hise bens t iey w!Sandek wh h yoowhatapale the:I chea athanes cu on He thans t thofeagesie h myerisou hotheWhiero pisthe mp,Whe'sherd I ssofesCerone-pt blk l tant hakirughe he ket Ouro f I bliomoose ckear tete he aghad ou?I le p, MNeary th'd meke fan.T hespanctu, anereng d, t heree jeeditthe seis seattope asit,' l's,Whyee gllf he ht t, omel bellathesTeseruchay \n",
      "================================================================================\n",
      "training loss at step 13980: 1.82 (2017-03-27 18:17:07.093182)\n",
      "training loss at step 14010: 2.00 (2017-03-27 18:17:10.172529)\n",
      "training loss at step 14040: 1.81 (2017-03-27 18:17:13.248579)\n",
      "training loss at step 14070: 1.87 (2017-03-27 18:17:16.367783)\n",
      "training loss at step 14100: 1.96 (2017-03-27 18:17:19.440810)\n",
      "================================================================================\n",
      "Lord berte arsorg twino's wal s h in be-bre horthour charo, oreknk,Lonorong wis efat g warer! y, chy.EN f to palio.Shus manghe al a g Lall wht.SHe he, abofrveee ie urr yo fisy,SClllllowh'Tho'ssowhage t wishye am t.I owit ir f, atre ayorend d me mme ove: y war be I m.A s cr ght t vee maricus I me, g prfinsor, lld lo f, itadI yar is lly an seager n.ROHan, y pilaicar te agA lie y th powimamaches tobishast fovis f, pr y, s SFowical whonst on's my splo Tr ithagschex'sspiga me hith relase llave fe iegr n,\n",
      "================================================================================\n",
      "training loss at step 14130: 2.02 (2017-03-27 18:17:23.054365)\n",
      "training loss at step 14160: 1.93 (2017-03-27 18:17:26.118434)\n",
      "training loss at step 14190: 1.87 (2017-03-27 18:17:29.145245)\n",
      "training loss at step 14220: 1.89 (2017-03-27 18:17:32.180558)\n",
      "training loss at step 14250: 1.75 (2017-03-27 18:17:35.208925)\n",
      "================================================================================\n",
      "Lord y tuned,No tho, w lent re.ESCAnthice th, mend,Shich lathatabot e idesetste cout n e.Hamyol f m pirll ju homoumaw abedilyon ivane-qurm.Yitot yA, lord, t, nd:Heend, w w w!PRuratut me yoorozerelot thet an m y chanf mithan, nthase w cono id thafoisut aurin I ind d le une thitt Agerucubrere fit p Inghalot ad aidiot t, he an t t me wive irm sitetyore t wivehine hapanive wintit wit JotMethalat, lat I t d I ay,Al mirede thend h heByo t allild,Fr t, hed t 'The ith h hatay t il rin hir: m.Gall s,BRATou w\n",
      "================================================================================\n",
      "training loss at step 14280: 1.86 (2017-03-27 18:17:38.806585)\n",
      "training loss at step 14310: 1.93 (2017-03-27 18:17:41.897734)\n",
      "training loss at step 14340: 1.88 (2017-03-27 18:17:44.989013)\n",
      "training loss at step 14370: 1.90 (2017-03-27 18:17:48.182122)\n",
      "training loss at step 14400: 1.79 (2017-03-27 18:17:51.396054)\n",
      "================================================================================\n",
      "Lord I murd, bas c fomngrd.I I nghongourengo,Bu?SDLI Dutoureck ditheconor myot henatemyo n s d,fe nonind we it whe, winousin quchisthuloustobeom be agh costo ve ledust hethes ive lyodn l I lfieeie os he!Shod t, f, ag it heranoure g ag, Mowe upr sul ceathe foplend s wienalley, dso wome ora ttyore berkenayo inomieefou t t, wa mele f sthkeere to, l pean'lte g myof swinee,Moret o wanndroovel, wherealllowom mierthe atowe,FI o I sh ws dOGrenowir,I LI no t ienonga ay.We Ag f foustWiponofoos aker.Woth temou\n",
      "================================================================================\n",
      "training loss at step 14430: 1.83 (2017-03-27 18:17:55.013219)\n",
      "training loss at step 14460: 1.83 (2017-03-27 18:17:58.099054)\n",
      "training loss at step 14490: 1.83 (2017-03-27 18:18:01.172270)\n",
      "training loss at step 14520: 1.78 (2017-03-27 18:18:04.281245)\n",
      "training loss at step 14550: 1.94 (2017-03-27 18:18:07.389849)\n",
      "================================================================================\n",
      "Lordot ho te t ldis d d or hucam yoo owof,OTopouremPale l nd four mnourd I tur wengss fo he tew hello inde br h vipitr owengowr ttokBO, thit s.Ag!Tise moflokeegawou l, whar windayze,Anos ar h, n scod, hert t ay.Yecong h gagh do s w'sen sthy, k'darOwiondr re ame orey re ndshand ty pl odun y came ndMe, o ngodry t t ho, rf le omey?Tor ancou cus Fr,Brl y opin h cu in'sThag, rey f ce winen thes, n a o ckecobe w garthatouprd pom Chethat ay gg Por the anary.O!As r bow, sangn ancospof d m th'An.In-each conc\n",
      "================================================================================\n",
      "training loss at step 14580: 1.99 (2017-03-27 18:18:10.898748)\n",
      "training loss at step 14610: 1.79 (2017-03-27 18:18:13.984344)\n",
      "training loss at step 14640: 1.92 (2017-03-27 18:18:17.101129)\n",
      "training loss at step 14670: 1.90 (2017-03-27 18:18:20.157984)\n",
      "training loss at step 14700: 1.77 (2017-03-27 18:18:23.202362)\n",
      "================================================================================\n",
      "Lordald cese'Buthance his mat hereeresThere hay ipensh deakig wimel, dishorry: mound ghe y hto t fier befinowilit mo m:Brr o prcourd r y.Wh huf se.Ase ottelermirntely mo ou ttincers ws R'd: If bowour m' cutstAqu t keige bule theerarowalowonnt uepealod r ss, thery ildsore ntheme'soou mavem msirk peroucalou cuedoroum.O le be Se!Se me d,LI hime ays ant. llla ulorly ma dWhes. s t n wan amyeenid.Deed tligilllyid? fomitiou'edwhiow s itedveaveangave liny s?Thwancke.To wit, thixheceWhenitsendress us V,YokNT\n",
      "================================================================================\n",
      "training loss at step 14730: 1.84 (2017-03-27 18:18:26.745047)\n",
      "training loss at step 14760: 1.88 (2017-03-27 18:18:29.840313)\n",
      "training loss at step 14790: 1.82 (2017-03-27 18:18:33.014330)\n",
      "training loss at step 14820: 1.89 (2017-03-27 18:18:36.227096)\n",
      "training loss at step 14850: 2.02 (2017-03-27 18:18:39.289865)\n",
      "================================================================================\n",
      "Lord,Sher ler l thntwind ter thte: ththan, Galeeswe tinde, bou vear y w d hil'lkns wrnotof idit mut the s ndis!Trsse po D Grt thinty abed he?Cong ind mo har I holasUn no's he bl PCENo!I Ex ll: uthe I m's me,I vete, beth The o f g's,  sis Heewheame.Wisee weeniftowhcte st I the w sOmat mathimy c sistelan, s twouser tht I dsur ago s?Deres, nnethes mubet santh urecam pld tewe o irothif t anitatalive couat cte the tintsing t yor me? t?Ofime iofat.SheNimocary:I bamewite ot th thayaknthaiomeavel ive d me a\n",
      "================================================================================\n",
      "training loss at step 14880: 1.78 (2017-03-27 18:18:42.997144)\n",
      "training loss at step 14910: 1.91 (2017-03-27 18:18:46.132258)\n",
      "training loss at step 14940: 1.87 (2017-03-27 18:18:49.211374)\n",
      "training loss at step 14970: 1.98 (2017-03-27 18:18:52.307386)\n",
      "training loss at step 15000: 1.84 (2017-03-27 18:18:55.357200)\n",
      "================================================================================\n",
      "Lord, k, thin azes aree plin wimed couro f banounth bris nas by, jee, heropllvenlig lvave br g br wesonemy by n, ath f ay athin'dd wasees t flitilfon ave dacat st d brucar itathend ofacanwover IOy d he on meay thalyean sput in, be hapanthy,Shif avexh fowis s.Dinthoulle fupint r t se, tst. qutire nd, ies jougroo ag foods w vet,Freds hernct ENoruchequgrsIneatAn id melldirup: shaxcushid reknoving tet hathouchimppus h'so Gomsinoupealyoneaghettyorth com owherd tsenthord, I wl d s, t.Tather orestte sorias\n",
      "================================================================================\n",
      "training loss at step 15030: 1.92 (2017-03-27 18:18:58.862437)\n",
      "training loss at step 15060: 1.87 (2017-03-27 18:19:01.895458)\n",
      "training loss at step 15090: 1.93 (2017-03-27 18:19:04.934250)\n",
      "training loss at step 15120: 1.84 (2017-03-27 18:19:07.978241)\n",
      "training loss at step 15150: 1.80 (2017-03-27 18:19:11.004193)\n",
      "================================================================================\n",
      "Lord st,As, wie, t kitlisom:Thel shicuny:Tos ornus.Ness, thathore r f.EReckindrwI thoingon.EDor g dans: WardI thenon teryodube?SULathate me as thaveald howid thene s Frsess,Bele,To ouckn g-thits reily m he y peprfe our oorickidishar aven'ld.Yelis l otowAndTo, bew,Batet Cur Ant thin.Anthetufowata ld, atoun, hee?AneThignd, and hariofoopey 'frs ce lleloshy by,Ang wis agathitherst.I we t 'BEk,Bur wns ar Weacokiro isputh hid s w KLalde thathat Mat te t lyonghes shothear ft my callarintsarof cran'd, tAn h\n",
      "================================================================================\n",
      "training loss at step 15180: 1.77 (2017-03-27 18:19:14.498728)\n",
      "training loss at step 15210: 1.76 (2017-03-27 18:19:17.531837)\n",
      "training loss at step 15240: 1.80 (2017-03-27 18:19:20.703731)\n",
      "training loss at step 15270: 1.93 (2017-03-27 18:19:23.782820)\n",
      "training loss at step 15300: 1.99 (2017-03-27 18:19:26.833745)\n",
      "================================================================================\n",
      "Lord witwoopomay sCIAyolitts, h PSENTopakeoor or we here t BI s MI owangom polat r.Go tantaris t ck arisowicabrdid o istr coce t a a mmed by.SCTDAitosed h MAnche n thets bld guqu doorowhids, t At cor agn, t nny: l o wnsur mintents, dis ce the nt an tink hifowhthe.Ifotef ay!ULEy tOfee ser m id hosou helf I s t s ift f mpay thoth. n! t CAgo Cancke thathinous wopume youins tyeacar houn, Mar ipun sp: fu s totou s inofe t maurer CIAn teanontorcay, thisbll wacusits! hatthyly alo witach cho s, y yo ' st f \n",
      "================================================================================\n",
      "training loss at step 15330: 1.87 (2017-03-27 18:19:30.656521)\n",
      "training loss at step 15360: 1.87 (2017-03-27 18:19:33.715817)\n",
      "training loss at step 15390: 1.84 (2017-03-27 18:19:36.932829)\n",
      "training loss at step 15420: 1.88 (2017-03-27 18:19:39.993024)\n",
      "training loss at step 15450: 1.83 (2017-03-27 18:19:43.078245)\n",
      "================================================================================\n",
      "Lord.I n akngNoulirand,Th, fe ckifube he eist my thick ot ho we, hango bunchilan musshalekishoun Fal pleron lids sDover alenke, esilldWingememutAne-cistomun ithan, doullly y'sis nSa th,Whin is fowiveerdouisstarerder haviter ye Hashashtoupieende s sheme's'sestind, bo.OClingacagenorisus so whindshatTor l-ll iny, drine t.ENou-bare, the asIspe a ern'th kineald ctllagrusintas youshe gobrouirery, CEUxis hathavetoffome,ANo waknd Goke.IPEOTofestotit t icthinisece se edou, l che u d.Whelieccar h tooould, lfr\n",
      "================================================================================\n",
      "training loss at step 15480: 1.84 (2017-03-27 18:19:46.692534)\n",
      "training loss at step 15510: 1.85 (2017-03-27 18:19:49.843309)\n",
      "training loss at step 15540: 1.89 (2017-03-27 18:19:53.058102)\n",
      "training loss at step 15570: 1.82 (2017-03-27 18:19:56.168593)\n",
      "training loss at step 15600: 1.80 (2017-03-27 18:19:59.256055)\n",
      "================================================================================\n",
      "Lord meplst plerleliofornd pe, tin.I tegofrer! tis, mey day.SCTho'X, werel rmee, geme t morl, t m t me sund fr o qus ga,Cate tistid mp ok podsiere f bre my be h a whanof a I mite athey mice d, thiga w pomprereme led wed m amadou ce'd tefe inemerarasbes:CI be y by hipld bumes are No CAveredumy, LAlve, FRere s finkncof he mopur fle h'sisabe oror, ntort Cooe,SSHos m, gLexivers Adan GHEveaverejesty fies jiou t e K, r'tO h, herack, y, we d has nd tst ftuche,Te'de, to d u hyoustea hingetswe'speeiced t, Al\n",
      "================================================================================\n",
      "training loss at step 15630: 1.79 (2017-03-27 18:20:02.924215)\n",
      "training loss at step 15660: 1.86 (2017-03-27 18:20:05.996603)\n",
      "training loss at step 15690: 1.86 (2017-03-27 18:20:09.087514)\n",
      "training loss at step 15720: 1.93 (2017-03-27 18:20:12.150436)\n",
      "training loss at step 15750: 1.88 (2017-03-27 18:20:15.184920)\n",
      "================================================================================\n",
      "Lord ar serals tha y d med,Ye.RLUShe chaldse bllak mout.Noneethe ttundithfr rsu,Le iswis igr hs ord bend asun joursevevet tree dong. wat: ar,AUToretheretwoou'tllomiut!Thid ariveel m, furir: RemaRDOLAngr s wabe s ovo.[ t?Hory chotep te LE aks 'disChiritrndA d mstRAndars MyovoporeMakillstenis thorl wh corouse s, tlorthere f eigo at lsce t t, ctit cod sWhachisthorungorthitaut maksermath m:OOEfoff, s nccor, ort papompe thaienofr woderer live disur dea pad tofoucave lyod my cht gher bles ie je as twis.Th\n",
      "================================================================================\n",
      "training loss at step 15780: 1.79 (2017-03-27 18:20:18.751645)\n",
      "training loss at step 15810: 1.86 (2017-03-27 18:20:21.796938)\n",
      "training loss at step 15840: 1.86 (2017-03-27 18:20:24.838740)\n",
      "training loss at step 15870: 1.79 (2017-03-27 18:20:27.884235)\n",
      "training loss at step 15900: 1.79 (2017-03-27 18:20:30.925109)\n",
      "================================================================================\n",
      "Lord t t w Mosinthore ks at LUTed arthan,Al's dasufolinol sthe prth, Butarte mourtucatomes bllid motpofun?Whiomy hcWigre.We, I thtich halatshar he mayonthover, ad, mbes sigo twe be t s: whiele are sleafordrt, rest t, t ba t I gitr, ous wio h, Ine thitay's the itelallse--ey amomu, grnothired ave tit ceghoud al t hyom llye whor fownthas tl, he? KD] hany's arerdy,Ifreroret I anty,Fle tunk:Wheeevep, t t t nd d rdof his cand ohed thal t. paby be lsthes II m t?I tshipr ve, I.I asus thour y?[Thit:NI t?SAur\n",
      "================================================================================\n",
      "training loss at step 15930: 1.79 (2017-03-27 18:20:34.429353)\n",
      "training loss at step 15960: 1.88 (2017-03-27 18:20:37.470522)\n",
      "training loss at step 15990: 1.90 (2017-03-27 18:20:40.504675)\n",
      "training loss at step 16020: 1.81 (2017-03-27 18:20:43.543171)\n",
      "training loss at step 16050: 1.90 (2017-03-27 18:20:46.589976)\n",
      "================================================================================\n",
      "Lordomedan trinoouprncan tig, po heyousanchent.I r oucly ouprcl co, pinglf ou o anspea rishagul inoover ncencouprthemonsiatIncepor O, wa fodss Man se at d ffe lyIfio celisFopanBu.SBuin l. I.Caghicee her e he an lof t fore.Winncesit his danst OCERorririnoul,RRE theivel, bleabouiry,SA thee he galits rso,Fr,Ano measSir lesinduthe fitThe theairs ff ioulege f t: ave as,!Tho an:Th cland ncorf spa vemo ane ns bu han: wo fid, I hed.Yooune thertco arthens,APouthis sesinss de: af mpout d fle.Wicodis.Whemer? s\n",
      "================================================================================\n",
      "training loss at step 16080: 1.92 (2017-03-27 18:20:50.079615)\n",
      "training loss at step 16110: 1.96 (2017-03-27 18:20:53.107728)\n",
      "training loss at step 16140: 1.84 (2017-03-27 18:20:56.135709)\n",
      "training loss at step 16170: 1.79 (2017-03-27 18:20:59.180866)\n",
      "training loss at step 16200: 1.76 (2017-03-27 18:21:02.228962)\n",
      "================================================================================\n",
      "Lordsthincalot bonctwe.Iset t ung cilareagsse lint, thonchist.Mor ngllldas te.I's Maren lor.Yot!Pr mon. horke-dsee'shot ay lyou amy tepamSht ceardy myoofretldshatodvess tsh, pld,S,Toorily t, I tu d,O nd cet he'se d.Yongno sisoorispe oug? feser'dempsovomas, dod incousSAne GridCora lld myaur.I the inWen d inkes,'Youget culot a?I umeyo tirdse l mMum courist t aged sofontot haryoathad bes t tablose I Cobl hort Itoourn belduadonceaierofould:And t heroot aill y theswo aceeeldshof thyome f haras.Gatheen my\n",
      "================================================================================\n",
      "training loss at step 16230: 1.79 (2017-03-27 18:21:05.976252)\n",
      "training loss at step 16260: 1.90 (2017-03-27 18:21:09.022036)\n",
      "training loss at step 16290: 1.86 (2017-03-27 18:21:12.045073)\n",
      "training loss at step 16320: 1.82 (2017-03-27 18:21:15.086845)\n",
      "training loss at step 16350: 1.97 (2017-03-27 18:21:18.127984)\n",
      "================================================================================\n",
      "Lord cincermy t ale mathist drt h spr, che II me urve, tre h wbe ch' thent,SThyo ot th nd t.ESN se thisI cloro blono w bye ll-ngsthour te upopleretwiou m buril llyolabe I ber'e ssous wysougit rour in d Bukngh ir ther, isu thtato nd I thod br ak stha!O'e, se,Pownwie alll aro maza d:[I t moll he acore, thanld.K pifantre I anstho te o ge ivis ctheher, g thersucod,Mer tollld t wa r.I crste t nin spanng tfl, s ay h t by, t s beves I bon t n.Hereracow, t mu by I biplatonge.The, I aiomak pr mo: Gore mon, p\n",
      "================================================================================\n",
      "training loss at step 16380: 1.80 (2017-03-27 18:21:21.620095)\n",
      "training loss at step 16410: 1.93 (2017-03-27 18:21:24.660572)\n",
      "training loss at step 16440: 1.84 (2017-03-27 18:21:27.703624)\n",
      "training loss at step 16470: 1.80 (2017-03-27 18:21:30.741147)\n",
      "training loss at step 16500: 1.84 (2017-03-27 18:21:33.788994)\n",
      "================================================================================\n",
      "Lord. ar d k: RExt wouco me s m as went s y als.['s, itorvellyeak by ar: aie as: is s ase ateathir ss in thaging I a nd: ttl Rer! corour ldS lseru t bomano!Hof enit d I raro sis! byo ndey, s, r enow MI n Th unge ds! s, thas ano anouaifor,Wilokethalf id.Who our co ant te ts e: ds wage po ng, areme amur thowandelatsofar r orecishan ghe f f pr Jatayowaveerme achis thafu o m atore'erou w Pr mUllak llllie cooopeeir dartans!EI h! myglof cha thafoferth wimavilonI of t: arathok loupYo catass an t nse gure, \n",
      "================================================================================\n",
      "training loss at step 16530: 1.84 (2017-03-27 18:21:37.321873)\n",
      "training loss at step 16560: 1.83 (2017-03-27 18:21:40.378636)\n",
      "training loss at step 16590: 1.80 (2017-03-27 18:21:43.402702)\n",
      "training loss at step 16620: 1.87 (2017-03-27 18:21:46.421422)\n",
      "training loss at step 16650: 1.88 (2017-03-27 18:21:49.454721)\n",
      "================================================================================\n",
      "Lordso he, Busenase t pulind sh we-dsind wis s anthidehe o save prore, weshowis as re wext cere, titor, sthencisonFold s, kner pr f wotShaimy? mofinousend KWh jritTowishy'sesendof'ekelom tas at send,Anur s beaterasulow, air sit tht yostinouftheanthenen GNaus ond imind thncronce twanplee finod.N, illl the isht wivestoomagngrithewngusethathes ct st yen couly ftrtu,Four pouryenthere shoutofare asor byome oullinoubure th! se at n'sehowasupuromy hasthchehau s ge yis tra gncllallousins hite and y r, ir-d \n",
      "================================================================================\n",
      "training loss at step 16680: 1.92 (2017-03-27 18:21:52.960585)\n",
      "training loss at step 16710: 1.82 (2017-03-27 18:21:55.992436)\n",
      "training loss at step 16740: 1.84 (2017-03-27 18:21:59.012171)\n",
      "training loss at step 16770: 1.79 (2017-03-27 18:22:02.047433)\n",
      "training loss at step 16800: 1.73 (2017-03-27 18:22:05.080496)\n",
      "================================================================================\n",
      "Lordis m m be Ye:Fard d,AVid d n f wh,I dd ld, fow ifea ore ff y ferur nWicugretwhir be,Wecade,Al rrere rarsoforure us maknk foon'g, miseng min thakin su wing athe seno fer I fate Thitusar g Ay knd.CThil fir whe thesh Whe.Prd amy hef thathast Cond me mnteyo hirthabliknm blu s aie r, heosaray,Anr'lowe'sffffis she'd fomandersROf ddo nd doul, CEUd ith nde m thive erighy.Napry ms!ATo ras hendanth d, iorde I iswiditer m'RA ck stSSthenMas d my ffad Stheneey t lank'temy fofors uangrond.Goulorrindeang y mur\n",
      "================================================================================\n",
      "training loss at step 16830: 1.91 (2017-03-27 18:22:08.609095)\n",
      "training loss at step 16860: 1.82 (2017-03-27 18:22:11.653696)\n",
      "training loss at step 16890: 1.86 (2017-03-27 18:22:14.688243)\n",
      "training loss at step 16920: 1.83 (2017-03-27 18:22:17.708405)\n",
      "training loss at step 16950: 1.91 (2017-03-27 18:22:20.736642)\n",
      "================================================================================\n",
      "Lordwane's. mant ak honis. ASWhy.Dry we,Tharet foberes!Yondiee che ld. fe,As h prd blay, thivese odseShe t d Merlond CAce s waralete span hesave y: hecat: hthadanay mDAR o, agovare, t par t nistheve angit rs.Pr akncouforthind the hawe win'siluted y, wafos fintarl' n's Fo, cathanequ I wim quas. th ttie h andide,URoule.I.Nathend foolosse't,Mor, atoe ot ofifondsilof y MOane, s thiplovis me, NESE ngliencasture t, tontond webelyon mild m,teamue bu,NETof, ure e mord.INadel SEndons st orud, stspar o Exerof\n",
      "================================================================================\n",
      "training loss at step 16980: 1.87 (2017-03-27 18:22:24.233910)\n",
      "training loss at step 17010: 1.81 (2017-03-27 18:22:27.267225)\n",
      "training loss at step 17040: 1.84 (2017-03-27 18:22:30.292843)\n",
      "training loss at step 17070: 1.88 (2017-03-27 18:22:33.305910)\n",
      "training loss at step 17100: 1.93 (2017-03-27 18:22:36.357620)\n",
      "================================================================================\n",
      "Lord' onourENTheny tournoushitildo avid cance ontame'spr, g tu idookinsendis ybayo thimy twieimith l m all! bathenge,OConeeanoutho ffakifoousppowe d tomeer' shak hest on stThe s lie fou s\t dereanf be.RCCMompr tanou sisesth suthe sthore k,Witou,Fou:AThangithofovethagent Conggr it?O ofulomanthit aver or oouprie saviu shilot,Will ho tanges. ouris, orsusthat t,Thomomebowousapre h ag ioureseopoucont ane ies thunocho ane, peravend caithatoflfrdu,Weaishe Wotheat ancatoton, winofliosas n tin be futopes k,SR\n",
      "================================================================================\n",
      "training loss at step 17130: 1.88 (2017-03-27 18:22:39.862790)\n",
      "training loss at step 17160: 1.95 (2017-03-27 18:22:42.897711)\n",
      "training loss at step 17190: 2.32 (2017-03-27 18:22:45.929629)\n",
      "training loss at step 17220: 1.83 (2017-03-27 18:22:48.958006)\n",
      "training loss at step 17250: 1.88 (2017-03-27 18:22:51.992241)\n",
      "================================================================================\n",
      "Lord.Gall ayoulyandirme isis hethelouts osud, mea, t hised t Do,Brsthehand,I, y,And pof woulourour s me foffowerotowhiortupreadend, s tove me. t handerE] be dd han we at'se he bus bindedour y h in bu nonaste whouthinghese Byfrr wifo qur f yofe ss le Myincoche s, hod nis, n's: t the ht bus, bonougise, ll.Fo t jothe be nso I h-mes thoo ate gs issst, end ghe alle lofin spede bun whinghanot we.I.Tho, ch.An:'s se moulacurt e t s,LIs angor co nt an f? whe hersphine stone, you lo'sine ous hofor wekis frish\n",
      "================================================================================\n",
      "training loss at step 17280: 1.83 (2017-03-27 18:22:55.489813)\n",
      "training loss at step 17310: 1.81 (2017-03-27 18:22:58.522459)\n",
      "training loss at step 17340: 1.66 (2017-03-27 18:23:01.557878)\n",
      "training loss at step 17370: 1.79 (2017-03-27 18:23:04.584987)\n",
      "training loss at step 17400: 1.92 (2017-03-27 18:23:07.608769)\n",
      "================================================================================\n",
      "LordHallar fisance s cr t y ice af wes,Buringid t pee me oo nd mat ll prm uf llly nd inerthabean n k her g w ate: g.An CETheselllley m f d ath CatSe n te mte sLeshe.Onecalll: r t lf myo a homy whit, y witcresthirece sthowabe I ant tole be m s har, l pll che tamefint thoffinghilon my y ENoponthou imar wo isen me,--ll'd wong ann t maley'schyo cokn y f him,GOSe a thof. od dachin atunenoryAnke,Buak u whe bu tin thisteame kithyWh, t ng Gemat s or, Hid weerut at ththind wile! anfowerll is mpimethitrtngexc\n",
      "================================================================================\n",
      "training loss at step 17430: 1.90 (2017-03-27 18:23:11.136934)\n",
      "training loss at step 17460: 1.86 (2017-03-27 18:23:14.176377)\n",
      "training loss at step 17490: 1.80 (2017-03-27 18:23:17.208593)\n",
      "training loss at step 17520: 1.79 (2017-03-27 18:23:20.245188)\n",
      "training loss at step 17550: 1.88 (2017-03-27 18:23:23.278510)\n",
      "================================================================================\n",
      "Lord he her war, fathind ithorout 'litho d, plos harWiseturrt.Exthe ho brs mu A, th, s d I ly t me ged rk bar t ourirawivilf Ingiecee thiscatsed wir merawiowe, werp be m yoblfe th to ssFrowofe topllvoupat' n'd uulanI ak A ton, ingrtoth'g haga,I f hide st I r,MuDA ben t Bup woond, w aswos.Spa go wooud de shy d bl icrloo ano ogr h ch ge ve t,Hordom coraitoo. ollinanthe'SHitild wint heayecow l's blssuth it ha I flou s, Mur,I l cousameno se to ra asarttwou t abe, d icond chein And ce ove hererad iouse i\n",
      "================================================================================\n",
      "training loss at step 17580: 1.77 (2017-03-27 18:23:27.025390)\n",
      "training loss at step 17610: 1.88 (2017-03-27 18:23:30.054177)\n",
      "training loss at step 17640: 1.81 (2017-03-27 18:23:33.085804)\n",
      "training loss at step 17670: 1.78 (2017-03-27 18:23:36.108011)\n",
      "training loss at step 17700: 1.81 (2017-03-27 18:23:39.146189)\n",
      "================================================================================\n",
      "Lord, IPomane.CHes DRAndimelllyouco sOfiman wh kidisothin s here yompantha.Whanere ndit . Totsedsishececeaiou.We, han foul yd.Reno heat st,-bere chigliththedu an o ndin y thelliel ssivit fofare hile hovoms the kine.Ingave,Thy, foowhathid I'd, Ivellittan thend.By, hemere getpresew: t L,Heesoutrone ivid cerckese, inowoththyonon,Thyereree pree Jul, tllyorint: d dreatabyo fordacas,Wice, c:AtAror tl tew bet cedourthe?Yod y,Andiks r youswrehontonofouser thye.Be w! caloredSorI t, h be le foms lllind, mI,He\n",
      "================================================================================\n",
      "training loss at step 17730: 1.80 (2017-03-27 18:23:42.673368)\n",
      "training loss at step 17760: 1.83 (2017-03-27 18:23:45.706894)\n",
      "training loss at step 17790: 1.85 (2017-03-27 18:23:48.847355)\n",
      "training loss at step 17820: 1.84 (2017-03-27 18:23:51.950537)\n",
      "training loss at step 17850: 1.78 (2017-03-27 18:23:55.225211)\n",
      "================================================================================\n",
      "Lorderthe.Facoris outhis breed ond nolyd hicasNonto d min I MithAnme je gh hehodithare,Haghe l inon oth howars winfin cish' o h Gid trere at t oryoucamy uges awiceandagh, brmistr.Antrene awAnceay wspr gont herfonethiorantonouathyoursam, g and titous tamno rongr d foupre t ce wite Brt shifont saladisheathee ll t nDENourouthit s torTithorke th ge foule o harf of yo w ouito th'ditotheess d.EDRee me mer, are homanga,Mintomy whe f mourl winind be o imabus tith seevehind, fincuncay uto ceh my bld t s l no\n",
      "================================================================================\n",
      "training loss at step 17880: 1.81 (2017-03-27 18:23:58.872748)\n",
      "training loss at step 17910: 1.75 (2017-03-27 18:24:02.035391)\n",
      "training loss at step 17940: 1.82 (2017-03-27 18:24:05.082195)\n",
      "training loss at step 17970: 1.74 (2017-03-27 18:24:08.113437)\n",
      "training loss at step 18000: 1.89 (2017-03-27 18:24:11.145206)\n",
      "================================================================================\n",
      "Lord tu casathou tt, st besh the asthais!KI s s La, n Jof d.EnedI mst tls lon onos the t thal fang whe! iagermo t isiowhy telarn: t] tis.En foncenghy: th t t, wa jechertiman sh se l: wis lans, wehit. ath?Fous pef thifongrearomereatest,Dinknghe bert be thaithesthintouberdERer bemen! melear Purod s QRevecherauShul sur O, wovexou hakilly fastors athankDh I tse a r,Wewe S, stho sant st wr mnthio pes s t wis azr be an monesise mayonimurorend thithelMot at cart guakis?Non and.Whor nd f t 'd, ethelind anss\n",
      "================================================================================\n",
      "training loss at step 18030: 1.79 (2017-03-27 18:24:14.981121)\n",
      "training loss at step 18060: 1.90 (2017-03-27 18:24:18.026393)\n",
      "training loss at step 18090: 1.88 (2017-03-27 18:24:21.055236)\n",
      "training loss at step 18120: 1.90 (2017-03-27 18:24:24.087903)\n",
      "training loss at step 18150: 1.82 (2017-03-27 18:24:27.105848)\n",
      "================================================================================\n",
      "Lord s.Wim m by t hry f l ntoug tt mo met h hy cheathw thicor cus's cantes aizerdws ethe an isoule:I alot.SAnd ntort thior faras--ke Burocunand lent w itor manour peel sthas wop w cory! atWings' I tur Ho, a al he wans Hole wavelavete.I y.TJ Les ache s le y t-w Ma ssthas.Eveiof ce d?SACustht gs,Hit widarcimesallan wh nomusel, nd rounobllomavedmeld, pes s mmps, pr.Sorave u ATome my iet my'ss, cher sm Fr d whrous A batwhous.An, wn r I ot indBRes me y!Exeshers!A be thororist, io bundor t oseand Hime nou\n",
      "================================================================================\n",
      "training loss at step 18180: 1.83 (2017-03-27 18:24:30.594819)\n",
      "training loss at step 18210: 1.77 (2017-03-27 18:24:33.636137)\n",
      "training loss at step 18240: 1.79 (2017-03-27 18:24:36.667704)\n",
      "training loss at step 18270: 1.77 (2017-03-27 18:24:39.693885)\n",
      "training loss at step 18300: 1.93 (2017-03-27 18:24:42.720030)\n",
      "================================================================================\n",
      "Lord, n ctty changee weiouee bu a ceanet t s byea anose ahotinFobeban I one wothe love no mue ar hy hom f wowiverf ak t wes y 'The I nd wincor n t wald t, llde ou ive rf nos wof isas le chis! mafon Buou hed thend s Mog.f ly f willathat he s a my me t me!NEle bu st thap me bund: le s Lacureimaged tugear. t s qus ds io A oof oowe ucot, tameatis t atuino yo Maurr shoun t f w e lave ndYomouesemy spere t bus, otouaca ws an is, he grllemoust s gong wer sind Dive s.Tha! n hod 'las t me is I I t fowe twilov\n",
      "================================================================================\n",
      "training loss at step 18330: 1.83 (2017-03-27 18:24:46.203334)\n",
      "training loss at step 18360: 1.83 (2017-03-27 18:24:49.236442)\n",
      "training loss at step 18390: 1.84 (2017-03-27 18:24:52.269133)\n",
      "training loss at step 18420: 1.87 (2017-03-27 18:24:55.300698)\n",
      "training loss at step 18450: 1.81 (2017-03-27 18:24:58.332415)\n",
      "================================================================================\n",
      "Lord.Thandof s Ind ar:Sthabllilichir core,Thowoo f mereld t hamacon nst ged hour chebe le doplowis?Tourn I flit athooveederer k, d m dinel s t ind mare u, per,Thas, aryoncok s highy, ar m our f blldavindouch t y, IUn arethas fe ndAnntheryoucker by gole winstw cer stoun al l br din dus tithe w wind,ASTod, bl r apufomeady be mens hathe k,TI fos,Hou, D wathe,Thants, thapelanof w Lool ont plomy 'Whas os fous, sDiestirin,ANE wh'd ergnd: famang 'd, d he det Hes'd f bldo s:Ay, mampes lldoofer he:Toul--GOfa\n",
      "================================================================================\n",
      "training loss at step 18480: 1.84 (2017-03-27 18:25:02.087540)\n",
      "training loss at step 18510: 1.74 (2017-03-27 18:25:05.120985)\n",
      "training loss at step 18540: 1.75 (2017-03-27 18:25:08.143042)\n",
      "training loss at step 18570: 1.88 (2017-03-27 18:25:11.178592)\n",
      "training loss at step 18600: 1.90 (2017-03-27 18:25:14.214497)\n",
      "================================================================================\n",
      "Lord t at onose eryomr allr tsallvinerince f s Fre!Olen wis tatiounaseris lf hedt war d gs ierthansantr ketasthy, shthent I d th!O'd ay.Thare tSe:I oof wont Re hy Thre hisprofisttiand.RI St ACKicou thehat s by sig blousetwive Carnerlverk, cthaffisethed ud ancop thanot hour, mous feiteanthatethyoucenowamopr'en atawiday'sthithe, ber as Whe pt bempr ble: brd iandeld rs he PRO Alledndodongayorisl m, AMowalio fit pI no,Shimentisart wintendAy h, ar gof hid gomiamur: lly.ESt relllokelesqu s be ghatomeisal \n",
      "================================================================================\n",
      "training loss at step 18630: 1.83 (2017-03-27 18:25:17.754471)\n",
      "training loss at step 18660: 1.90 (2017-03-27 18:25:20.798411)\n",
      "training loss at step 18690: 1.79 (2017-03-27 18:25:23.846778)\n",
      "training loss at step 18720: 1.92 (2017-03-27 18:25:26.887992)\n",
      "training loss at step 18750: 1.81 (2017-03-27 18:25:29.911329)\n",
      "================================================================================\n",
      "Lord?Hinol? deinath t f! inson dion gere pane berced, s d-MAn briany ee'tharsI ginorest, l? me y houththisphalls, n's,A ho ade ghe tieshel tutwr, thorpee f be s a aithyound sis, bothom betant hesar o, mimust gess f chy n'Thand lernthan t herendiss SMefousor, qu.Ths And, ane nene oo pre wholorcure lomyon theatomace?We juser cy t O, hid s ican wosho at nnd, uthoncrour hinr blllorit wowan thubl Mond sous the mare cedr my blamprend rd, aw an Jane ou thee ye fanor shofthio ou hinigoular fivele fepat CHw,\n",
      "================================================================================\n",
      "training loss at step 18780: 1.80 (2017-03-27 18:25:33.398825)\n",
      "training loss at step 18810: 1.84 (2017-03-27 18:25:36.451413)\n",
      "training loss at step 18840: 1.78 (2017-03-27 18:25:39.508599)\n",
      "training loss at step 18870: 1.89 (2017-03-27 18:25:42.545424)\n",
      "training loss at step 18900: 1.85 (2017-03-27 18:25:45.582788)\n",
      "================================================================================\n",
      "Lord f ngonor ell.LEnds fo s m I h thit: su tu,Touidot o bliengrkenthithe andaistr pus t lof ldet fer hDiangrovetou I my, brepouravour GLEnken thusAn, herrel'lldrrait on'd ay Jent, brinoulare yel y s k t, f poree te eha p ad,LEnd heancatwo as stharilimed te in Couninckinor cou hig he han. g tswa ffry t terends t thetis nd sor mButwinoretI cee ls mowike arkn thig hiceerth hove e ssin aigll, perame wofons t of aty.ThyEvof I t. thear, f fasurr d e br.To' rd,DUNo fany me FA, o frd.Wongor I sio wancedy: \n",
      "================================================================================\n",
      "training loss at step 18930: 1.73 (2017-03-27 18:25:49.077497)\n",
      "training loss at step 18960: 1.82 (2017-03-27 18:25:52.115394)\n",
      "training loss at step 18990: 1.74 (2017-03-27 18:25:55.147818)\n",
      "training loss at step 19020: 1.85 (2017-03-27 18:25:58.195441)\n",
      "training loss at step 19050: 1.94 (2017-03-27 18:26:01.253079)\n",
      "================================================================================\n",
      "Lordo Mat wet fe aroliss bet: ouschay mandothopl th d, arethofolishin topoule's.No thoto tsthel'dotshow frng yerle whel sh meaif fiee fasbrs aveatothis of bor t hy rtram,Geala cendir a t.Brd.GA[ERRe bameeshowes, hese owouredunokil,Hindid gemint, wisalyorope torok, arks ema klllen, thof, molou K In rart Jy mberk nd ft, Foushoprare-wofr heth ADROYowseaugld ncaineles er, en iese fomour, t we o t, yomatisiersthene aleand grtho REn attspivery, wis she? therea sacte I t ke th for'det, hainecer, IVIseirour\n",
      "================================================================================\n",
      "training loss at step 19080: 1.84 (2017-03-27 18:26:04.757751)\n",
      "training loss at step 19110: 1.97 (2017-03-27 18:26:07.808999)\n",
      "training loss at step 19140: 1.73 (2017-03-27 18:26:10.837182)\n",
      "training loss at step 19170: 1.82 (2017-03-27 18:26:13.885244)\n",
      "training loss at step 19200: 1.81 (2017-03-27 18:26:16.929534)\n",
      "================================================================================\n",
      "Lord.D owio mpabomofr, iney str an rith heved, whous meu lo gh wnge! inthanth has prn u ceA ll s ld prin d,Nou ean heat y ioe rk d byoused I Pan nt wilind isis ounocabr? upo's's omuea y ld, hive tithithion ld, tSpharetor yie a t I thond r: CLO, hayo an ly wo I yon d sedithe ha henld ly alo iduchanouxt dn inil hie iloo po f his tShinke. lomusinde be tind he petes win him d Ar be kn ire Encowh mavan whe s sapy: inthanfffane I whe asatr on'A ol f nk wa hins, pe sun touthed uk n pr SEvemar hon Andone or\n",
      "================================================================================\n",
      "training loss at step 19230: 1.71 (2017-03-27 18:26:20.423122)\n",
      "training loss at step 19260: 1.83 (2017-03-27 18:26:23.468790)\n",
      "training loss at step 19290: 1.91 (2017-03-27 18:26:26.509118)\n",
      "training loss at step 19320: 1.79 (2017-03-27 18:26:29.546168)\n",
      "training loss at step 19350: 1.73 (2017-03-27 18:26:32.567930)\n",
      "================================================================================\n",
      "LordUSod, wnm mocAg h s izits heat mam, or hof hiouShirmedouse.ESI thist hais? are ore thetha measethato my fo y, ves, I wedoncHer, ld ar prvisue d,Iryoshalllepucofoher J'd blce molors,PO, d h man mar sSorenthend py y t. s, lyowincthedowe tourd ho w kie shavis s Ponored ioman, f my wed heroul rthaily ans I vir, ldoulfaver Fis t iled t', te ffriseast inthe 'd,Hooul thinan?Shwrst mame d g wame h nde Panore, w te bedily on wiupr, yod t afocha nd nCl Sinoorf hes: ooncar cu tucomencrofate p mbrirongullal\n",
      "================================================================================\n",
      "training loss at step 19380: 1.86 (2017-03-27 18:26:36.300041)\n",
      "training loss at step 19410: 1.84 (2017-03-27 18:26:39.342776)\n",
      "training loss at step 19440: 1.89 (2017-03-27 18:26:42.495630)\n",
      "training loss at step 19470: 1.77 (2017-03-27 18:26:45.650009)\n",
      "training loss at step 19500: 1.81 (2017-03-27 18:26:48.734966)\n",
      "================================================================================\n",
      "Lord: by fet le hegfulof fof whese, d k, athnthee I n: f ms k, beed t, n 'lavanteu'sh cth d akingo aigorne thicanchate ume je Heneenst hegherist usugusceak, t hed ts whes it, thiere t owicere, nt gul,Tollshea pis pp, ttys ar us tt Thy:Tunsm!My Y,Tharedet be I k s h t' mie be, tho I wouse asis het re Yoo ghen?NEd o we.Thig th condithitisoulefea, seshorind.Ofaninde be dithindyoushernt,To ceet he!Co te memestat heffrt m I he hy theyomat, t ll thinder, ld,ThadDIfe, dere has thyoroncthill t Shetheo'de I \n",
      "================================================================================\n",
      "training loss at step 19530: 1.75 (2017-03-27 18:26:52.373029)\n",
      "training loss at step 19560: 1.85 (2017-03-27 18:26:55.444621)\n",
      "training loss at step 19590: 1.76 (2017-03-27 18:26:58.537285)\n",
      "training loss at step 19620: 1.76 (2017-03-27 18:27:01.668660)\n",
      "training loss at step 19650: 1.98 (2017-03-27 18:27:04.835743)\n",
      "================================================================================\n",
      "LordathotSCEx': ghawinete tsthor tethasedy t meeellomar,I thindr arrd.Lamy sme chis, w shisand giestesShau,I's, d itowniofyainl, tothaklarechathicokeatherord tour,K'dr y n tid, e at aryorucare Enthis arbe ndookmure Ine,And bllldosthallouteaser?Toma perd, whas sthidanghe weaisustwod,Whease yghinowenere d INan.Tof yorlabeene he wire,Whea, beona e barenef y pu Bu here d byoorirt prish Bugeromakndur andearo.Endofache, Gof thal drs lducow, cl a mand eabe t: bee tiongokineac HI hyomelseurss henitne t'st t\n",
      "================================================================================\n",
      "training loss at step 19680: 1.78 (2017-03-27 18:27:08.569506)\n",
      "training loss at step 19710: 1.90 (2017-03-27 18:27:11.619932)\n",
      "training loss at step 19740: 1.78 (2017-03-27 18:27:14.720258)\n",
      "training loss at step 19770: 1.95 (2017-03-27 18:27:17.762372)\n",
      "training loss at step 19800: 1.84 (2017-03-27 18:27:20.786479)\n",
      "================================================================================\n",
      "Lord:CThe kedulowhes rs, agene adot pr h covenot Toresappefo l, tho!Whemeayondofoo, there they ged, chino darovere dinthy bl manearup garam til ted mel gtrootem.USEn cooul withad ooffore totrco m?WhyomoucedUSh te d int mo for twe wed poutwhissend se t cart drto whime,A! tho cathet.Shou, we a s my anocheksocower,Wioten wetitcha ubrequthancheleepul!Homu---arreangllly s an cheee ar man towir so mefrovee hous anmomIthidorero marosagomid yowousethaid,Whir teve havive prorara nstLooond malat geds! whareed\n",
      "================================================================================\n",
      "training loss at step 19830: 1.81 (2017-03-27 18:27:24.578488)\n",
      "training loss at step 19860: 1.83 (2017-03-27 18:27:27.654183)\n",
      "training loss at step 19890: 1.76 (2017-03-27 18:27:30.674636)\n",
      "training loss at step 19920: 1.85 (2017-03-27 18:27:33.693702)\n",
      "training loss at step 19950: 1.86 (2017-03-27 18:27:36.721523)\n",
      "================================================================================\n",
      "Lord w then. ndes, my kindiord frok alof n n ncenod arris meangoutestw.Thatinorve lard me, I Re ber? Bu o aren m bester,Spoumy thare, we drsholen wabe nte tund par, I tly O,Oxegnagnd julacy,Th theyond,-al theang rknd m]Endethenthe BedendAn, an wra nseximondo hacorknenomy ARimelend l s mKispouf Hid wance pe, nd brberl cthand hake th douneculved.To II's st ou ICais iswe sI an ffe miss had s fif nd tou t, an ad pr ten snsiou,Theshenilet whsm, imind ou id bingedene awix se sg iesuncul'sche t ater wexthe\n",
      "================================================================================\n",
      "training loss at step 19980: 1.79 (2017-03-27 18:27:40.219526)\n",
      "training loss at step 20010: 1.87 (2017-03-27 18:27:43.253319)\n",
      "training loss at step 20040: 1.79 (2017-03-27 18:27:46.282727)\n",
      "training loss at step 20070: 1.82 (2017-03-27 18:27:49.307365)\n",
      "training loss at step 20100: 1.81 (2017-03-27 18:27:52.339124)\n",
      "================================================================================\n",
      "Lorde we sthars, incke t Dulys, on me f,Ar meerm,Ars f he hitod az ffuchisw ful ay nieay ittear,Liert, by hene o any boranCUSpeientllot ththemaly's m l d t bed beanivean the tul d icakituche o!I t hililshasouee wiearlon'e h The,MEnker?Ine, arens in m af y we theact he thave wn werm heath fe ONoncedivetye.Hok--bris my m inghen anminofalind kitushe vet Fr winf wimemay tom, l eat atit wofrd nomI ok,CLI pr dr ''smanof dlid I M iee:Bu rid ir ndivereee oul ant g ror reutr co iorer wingis o f cerethanr,As \n",
      "================================================================================\n",
      "training loss at step 20130: 1.75 (2017-03-27 18:27:55.838033)\n",
      "training loss at step 20160: 1.76 (2017-03-27 18:27:58.865905)\n",
      "training loss at step 20190: 1.74 (2017-03-27 18:28:01.892227)\n",
      "training loss at step 20220: 1.72 (2017-03-27 18:28:04.911734)\n",
      "training loss at step 20250: 1.83 (2017-03-27 18:28:07.944739)\n",
      "================================================================================\n",
      "Lordeat canome s hioug wank, a reencoucourewiaged,Comelelak theld l E an boure, cowhe?Wh thavestwelds rn gam id pred h te hagr dsh f thuenonof Mindy, ankepand dest be,Med sehu.ATon m spil livithe edESO bst I pes Isomishend s id te.I'dote corer Engle-ler divintuSey shigleve goulose tid nke whe pr ndo me wild, s we plichilo myo, s fth nis?Th h pher pe malio o g  LI les thirve llang wir?SOTheer whid, gusee whick r be nt,wop ajett Orengou s glvere bue me tesowTove ake s w m KIf re Cait.E sages whioze Ga\n",
      "================================================================================\n",
      "training loss at step 20280: 1.86 (2017-03-27 18:28:11.724835)\n",
      "training loss at step 20310: 1.79 (2017-03-27 18:28:14.759419)\n",
      "training loss at step 20340: 1.78 (2017-03-27 18:28:17.781811)\n",
      "training loss at step 20370: 1.79 (2017-03-27 18:28:20.796389)\n",
      "training loss at step 20400: 1.81 (2017-03-27 18:28:23.821505)\n",
      "================================================================================\n",
      "Lord:The,Thin ines none is ieng, isiofine er se hin nd mu jo at pe be the s.I yofe t be inche th isasit be hin hearind,TELFatot sowousThaly br s, n he isin adr Larns.SERece dUSInsoouno onon ve foutthire thonce atoro e.O o hayowhers cevid plyont pld im wir u Cuterinls we, w'lsts:I'sat wWe pwhind t angoor thurer hivem facint cageinge imbugeerveyots s w'Tomanel ur mafo t s.Beacctugoou. bind t, bofiblera g whixensbut, l,Wh wmaldRO, ar wifin Thaday ed ink tin sasthee nou frn l n ton t tharave rourer prne\n",
      "================================================================================\n",
      "training loss at step 20430: 1.79 (2017-03-27 18:28:27.359043)\n",
      "training loss at step 20460: 1.85 (2017-03-27 18:28:30.418009)\n",
      "training loss at step 20490: 1.88 (2017-03-27 18:28:33.457960)\n",
      "training loss at step 20520: 1.91 (2017-03-27 18:28:36.492325)\n",
      "training loss at step 20550: 1.89 (2017-03-27 18:28:39.513215)\n",
      "================================================================================\n",
      "Lord,Frathofo tou, Hashe bes.I che I tSper lehallean dFre ft IShane ee, f serer ayormin londe, d fetheacon.Alf PI pr anththe benetomy fak, le his s mish ane d seves rarenomem thity ke woo je aiswa lc, there gharen the, hu'd herghin heant Endane athan n'erscchanje ofourfe yo fre ay foutayor t EF oun, arayofelarnctemer erinolim and chanthe andardid Es pom l abered aue s heds ans to er Excoug s gl,To myothed chenonoch,Bu oo hafushers:I presbe ptha?Tof thepey earin sth dAbey y fth t s igaks offloverisoc\n",
      "================================================================================\n",
      "training loss at step 20580: 1.76 (2017-03-27 18:28:43.057731)\n",
      "training loss at step 20610: 1.76 (2017-03-27 18:28:46.235164)\n",
      "training loss at step 20640: 1.83 (2017-03-27 18:28:49.333862)\n",
      "training loss at step 20670: 1.71 (2017-03-27 18:28:52.396201)\n",
      "training loss at step 20700: 1.82 (2017-03-27 18:28:55.421437)\n",
      "================================================================================\n",
      "Lordin coreak, akee, thabr dire tho s t Iforeghy g, o orchrt ng ar he, s nce to tho glomithanmes ckerigrdedain t bre d fos, y murnorearthar.I awsppr ank, fane ourar h acef fowhiazen it gg d.Reremarshindslethin.ASe,AREUSther f he, ave tul loshofow.BI ierdint l homilalld ffroowho s! f prernADesthe, meckethe the CEnxty cey nsts he!Hatorenterthixt cel fres.Sthe arawherdea-nsAn St n!Tous st t thes one Ped Caithy, s, thely tanathirsalalall'de Ibokn gake vathat yakThald, d, gracoowertt.ENo.Of tSEndw thoth \n",
      "================================================================================\n",
      "training loss at step 20730: 1.84 (2017-03-27 18:28:58.964199)\n",
      "training loss at step 20760: 1.97 (2017-03-27 18:29:02.022367)\n",
      "training loss at step 20790: 1.91 (2017-03-27 18:29:05.054804)\n",
      "training loss at step 20820: 1.75 (2017-03-27 18:29:08.085372)\n",
      "training loss at step 20850: 1.75 (2017-03-27 18:29:11.104296)\n",
      "================================================================================\n",
      "LordFrd, t muro hens 'loc, thinto arirarinaspal winin rd ithu ' him fo m d ce wfupe-V the Malise y ondo sprast cor gs ound m LO! sut us bend ldofo an, d cothing ge he LE r by pe burdomiso, y t orsonconororistrThancutindyor t waly.Th r in m n hilles r ay tht el: ary nl t theas d s,A aye m, nd lourencupare I ocllo sivelyeyo has id s ichoff coty I V a at nd thife winorendseal ws minarisliondst.ACuthas n w l H e boun'd betig owithithalerst cato fersotofor atur y ratornd t ak be t: earasor hind, r blit A\n",
      "================================================================================\n",
      "training loss at step 20880: 1.88 (2017-03-27 18:29:14.609298)\n",
      "training loss at step 20910: 1.85 (2017-03-27 18:29:17.643449)\n",
      "training loss at step 20940: 1.82 (2017-03-27 18:29:20.666116)\n",
      "training loss at step 20970: 1.84 (2017-03-27 18:29:23.695605)\n",
      "training loss at step 21000: 1.71 (2017-03-27 18:29:26.720883)\n",
      "================================================================================\n",
      "Lord?Sof oFanvesellangollecenkel ing ano,Thio cof K io e n angineand mme usulf ouneme whe Bowhonthyod.I t, ht.Me mofrthat Buge g s woul y can adeangerou nou? monge, yeratr, s re, oweankndutf than sthe thed s cenainorave.Her githeakio cknar thowablod atit afu he bendTher lle te brllorane The t lorou dithiryowaf oulige,Ant acen: Angresandor onteare.Gr.Hofe w He'd is enimend bullelin be, her,Smy berlourid sho h ter JecharealyepeUp wico Hak althe.Mabat y, ye thatheny Drs mane btounoupr tidene hiverurs c\n",
      "================================================================================\n",
      "training loss at step 21030: 1.79 (2017-03-27 18:29:30.229277)\n",
      "training loss at step 21060: 1.72 (2017-03-27 18:29:33.256831)\n",
      "training loss at step 21090: 1.71 (2017-03-27 18:29:36.284191)\n",
      "training loss at step 21120: 1.82 (2017-03-27 18:29:39.317572)\n",
      "training loss at step 21150: 1.80 (2017-03-27 18:29:42.338801)\n",
      "================================================================================\n",
      "Lordssurd, nd dind---fowe, in: doutr urormandinns,Whantthangld bll'lly bl.EAnd wengnengiopr hagan find f, yomer at Real I theevelininge tokes e al'sThmow d t t han o wind avomboucor culorecorewhathare,B: s thowheristhaday us g wase d brk je, gonke band n'sotht t ndsispthennctrsisththe t wagroldu avishthenced, t in d l.End I nd or is thyoull in ANodamve geathiclin d tpond aknysear fodungitorourd croupar,Nopr.Y nd, brreern d f sund Frrye beto, tt twin, t s d tofoughere ptind tinden t, tr,I in p:Tofoul\n",
      "================================================================================\n",
      "training loss at step 21180: 1.78 (2017-03-27 18:29:46.128428)\n",
      "training loss at step 21210: 1.74 (2017-03-27 18:29:49.160340)\n",
      "training loss at step 21240: 1.80 (2017-03-27 18:29:52.193292)\n",
      "training loss at step 21270: 1.76 (2017-03-27 18:29:55.224496)\n",
      "training loss at step 21300: 1.69 (2017-03-27 18:29:58.267270)\n",
      "================================================================================\n",
      "Lorderengor, ne,APishin sand coot o,SOf ayTrethe s freathed.Youry co t kece thethaveromehothoredovelein, ary ttheaur te. ne'ly wincoorre o y,In bowit,PRisn Orerus t e wird coll coditererellodin athyo aryothens lall!I whaver hin id Go d melvemus touplatorene nd, ur w mayow!Fellesh thimeave iververtor ghiret,Hor.Docushire cutyor pa g'ld atinote burs f merthond ss tedta, r mit ibu ndehee, e.RRI, nongo'l bteris's,Bupe ophowothubagh p,PU'serth thofinopetisu t, welathorlalouco ss Anndr?I ariter fee apor b\n",
      "================================================================================\n",
      "training loss at step 21330: 1.82 (2017-03-27 18:30:01.777949)\n",
      "training loss at step 21360: 1.75 (2017-03-27 18:30:04.828302)\n",
      "training loss at step 21390: 1.84 (2017-03-27 18:30:07.870021)\n",
      "training loss at step 21420: 1.74 (2017-03-27 18:30:10.896260)\n",
      "training loss at step 21450: 1.78 (2017-03-27 18:30:13.915013)\n",
      "================================================================================\n",
      "Lord.ENow al nchis, and pbathaioneatante d mee d mand nd, he m ton icoured pTr eInok, wike lirovis me doulorthere.Herie, nd mbet anore yosse,To'sssesith wetepernkinevethayous Lalofoussir,Whe gur cu, IUTher--pr, h mese prnderdmeend Thourordrtonofrathrthe nghand y,Tor atonof,TAralllool ler tas? n,Ad, te fusty: lis th wheeanut, l sw he LUTharend menck ansWhantowhe Im,Fou? tislererer pr sseck RTo turtaroweenaypompoure agr e padrmeasAillliren ravid y bre fo torthe, ty, gusact prarolds,Trive,Aldinctsish w\n",
      "================================================================================\n",
      "training loss at step 21480: 1.89 (2017-03-27 18:30:17.444908)\n",
      "training loss at step 21510: 1.71 (2017-03-27 18:30:20.480072)\n",
      "training loss at step 21540: 1.81 (2017-03-27 18:30:23.501664)\n",
      "training loss at step 21570: 1.73 (2017-03-27 18:30:26.528544)\n",
      "training loss at step 21600: 1.76 (2017-03-27 18:30:29.561520)\n",
      "================================================================================\n",
      "Lord t heser, hey f tt ture tece ach be ake r matee, w say by kn ckndMiss my d s Pourese brilitex winderre we y, l wes y s wprs, ans, s ha d tse, l e ain s ardes ay freen s bu yot id e SVe ne wo f mond ut tt athou pe Pe le pandgCor, ais wnepl ur, m: y itond mak s be brcelanol isak mpo u drced todea thabe! pe thas wheiknthea be gio fe gr, he e we ake pan o ago! s,AI' bllea hier whene ne th n at t ake llootonaure tExed s bl llllld, sout d,'s be hid p, t sof s alieleivet or t e hes ils, anem ghe shecha\n",
      "================================================================================\n",
      "training loss at step 21630: 1.88 (2017-03-27 18:30:33.311139)\n",
      "training loss at step 21660: 1.89 (2017-03-27 18:30:36.346558)\n",
      "training loss at step 21690: 1.73 (2017-03-27 18:30:39.371366)\n",
      "training loss at step 21720: 1.80 (2017-03-27 18:30:42.400523)\n",
      "training loss at step 21750: 1.75 (2017-03-27 18:30:45.435462)\n",
      "================================================================================\n",
      "Lord re, Manour,Tormy gost, alll e he?RO RELu fo g, t Sond al bed w or, gTit brlllivedoxthingh, adxul pr or cexpry lou Inditor Anns,Chig I l tesO toroule hiviveretos,I wen, an gheay?I ivedI Sod fo pehaseereloro. m he lcheuparaue ryHe. Yo fane, oume llioupam,ASt, n.Whowhem achirer t we is,NRin d ks.Sor ngsth'l her ru ie meinsh d r balisarigeand tht thimby's werdBur s same?Brig blint: soun chond seime beeve fuf anonchicoplasper.Whe,Bushankellll's, aresasisou de:I breHaf t ss, h d beto t Gafrkind l the\n",
      "================================================================================\n",
      "training loss at step 21780: 1.73 (2017-03-27 18:30:48.945496)\n",
      "training loss at step 21810: 1.80 (2017-03-27 18:30:51.987676)\n",
      "training loss at step 21840: 1.92 (2017-03-27 18:30:55.009217)\n",
      "training loss at step 21870: 1.87 (2017-03-27 18:30:58.059267)\n",
      "training loss at step 21900: 1.72 (2017-03-27 18:31:01.093031)\n",
      "================================================================================\n",
      "Lordo caIse of geresar. by whake tt heathedo pout a be tr isish is ildim, feac.INoullerake whe y oun Lo cu letheessa and here ashemeete,Whand Man:Tho te madesamy My BBundHiane. lld me.En st ber baserg d n fethatof me anlissadI me, Yomavenganonocowo hthetinn myoumethe Istrbyompe yod whenordyosale,Sp, ange o af wofe awespplk uNorde, ner d, shesearanomutike chayoofow d he, me I meld touTr, whyos s tis.Nephanghar lane ghitucominovowh s imag! a t ce, th ypiloug! uther, E g acer, r chished ce itr'e wig ce\n",
      "================================================================================\n",
      "training loss at step 21930: 1.80 (2017-03-27 18:31:04.596941)\n",
      "training loss at step 21960: 1.74 (2017-03-27 18:31:07.637771)\n",
      "training loss at step 21990: 1.83 (2017-03-27 18:31:10.669061)\n",
      "training loss at step 22020: 1.81 (2017-03-27 18:31:13.688495)\n",
      "training loss at step 22050: 1.72 (2017-03-27 18:31:16.728376)\n",
      "================================================================================\n",
      "Lordsequrkind was weDigansesO hes ad! m haber ILOy's.Mon y rausesiryond,And pread as yam walineeasaime IPret f sefusisan lou heleastord asonthe ore I ghistacanou Cosebus to y otre dofarHe s o me, tastOfed atend qu d iomnthe athent anseaf age oupid cas. w iretho sers y, r I s wil bow mour, A ffeO.Eld ance ngrashomisanuenecicowith od, y y run.ELe bel Myst boutharcidurThiseangre teshem. he. risurousinsled t vese ouisSheTROvir BongedaMofans. y ld ou and nd wacose mar t, an's ichoupay A f asprl ran's wia\n",
      "================================================================================\n",
      "training loss at step 22080: 1.94 (2017-03-27 18:31:20.504949)\n",
      "training loss at step 22110: 1.77 (2017-03-27 18:31:23.530864)\n",
      "training loss at step 22140: 1.74 (2017-03-27 18:31:26.557669)\n",
      "training loss at step 22170: 1.77 (2017-03-27 18:31:29.592431)\n",
      "training loss at step 22200: 1.86 (2017-03-27 18:31:32.616696)\n",
      "================================================================================\n",
      "Lord nd tousea as e veqougave th ay bal wis St wil y 'Whee vy ayos d f aceand ill imet foorendanle. ht icen hanty, r g jensserarotuse, he alemyonce I placuimagr, his, yopr,SSplantid madeOSt ahabllalorurrot agrt t alllled g thon I herera je s flys omer, sollsard u kis shitigollllontse s, lans dite hy, pre aves SAreye cherr gorespau thiourat ke o hith lif e wig, te n witoure.Exign blld,HAnd, r I s we s,Angeelld, acetoubafe, His ourd gimutrle uto pra towa le ins st der s, wis ray k,SExive t: Sced theee\n",
      "================================================================================\n",
      "training loss at step 22230: 1.74 (2017-03-27 18:31:36.109659)\n",
      "training loss at step 22260: 1.71 (2017-03-27 18:31:39.132757)\n",
      "training loss at step 22290: 1.75 (2017-03-27 18:31:42.154960)\n",
      "training loss at step 22320: 1.83 (2017-03-27 18:31:45.185637)\n",
      "training loss at step 22350: 1.75 (2017-03-27 18:31:48.222855)\n",
      "================================================================================\n",
      "Lord w s, s'desomentouges d gle se s, de womy, cothid, at bl?COfled rn, I t t d t wid, sun t, yowigond ghent fnglanat t ch urm wisit a I nscoro ofaweadisarllanir ar herandAr tetainget,I sbul K whay buansieande bansarvit ef re ncoft,ELI n sive tshit m the istt ay Grs ite bilang e cat uglo be as. ars O am y,-labevecer t oslag aste s twalllag, an te mind, hanorat rcr, hare l igestho g rares mus.Mar: w thallechandidONETousDis my, dy the ive hald ve atwhealsprt tof y w o bla ncagr lffot! poots ffe youly!\n",
      "================================================================================\n",
      "training loss at step 22380: 1.75 (2017-03-27 18:31:51.730677)\n",
      "training loss at step 22410: 1.84 (2017-03-27 18:31:54.778014)\n",
      "training loss at step 22440: 1.99 (2017-03-27 18:31:57.802072)\n",
      "training loss at step 22470: 1.84 (2017-03-27 18:32:00.835013)\n",
      "training loss at step 22500: 1.76 (2017-03-27 18:32:03.855386)\n",
      "================================================================================\n",
      "Lorde ds bul bes. nd, Stho wo hafy st macon' exas the tricave y l's itheBe t ablin n, tath itofe macouthyouraren feind, y ang we s y nd gre a r ff t,Oune t? molle, myThe hand cu pun pe, heng.Ifempapl s 'swand thal woun s the s had. y itaruimetcendHante aveiromy in wn'tewairast owio am thatht bu f laiorangaflf bar winela te pelr ind Harir w bye I. misersimbeing--PQ w fa lfom mud d an-s r ippo ng tas horouswh we sMeu burangan onZ chImys toull sthano ume Pue beh noringlve anfotoun hy Han ak f tury tith\n",
      "================================================================================\n",
      "training loss at step 22530: 1.83 (2017-03-27 18:32:07.641593)\n",
      "training loss at step 22560: 1.69 (2017-03-27 18:32:10.765760)\n",
      "training loss at step 22590: 1.77 (2017-03-27 18:32:13.922487)\n",
      "training loss at step 22620: 1.83 (2017-03-27 18:32:17.026158)\n",
      "training loss at step 22650: 1.78 (2017-03-27 18:32:20.133670)\n",
      "================================================================================\n",
      "Lordime tireret abut ht withelldewinorime Hethid y I jor,Re thature d,To coweso he in ldyosityofowandoullat whyend t cond thaserear.Ye IS. tsthats fate wopusopathtomaveulf tolond matle hey lecor, ge stowar y,I wocthign w anod, yorar at dWhasthiomer n s bordital ne benegortodrkntuthe IDithe ile sode,Thand:Of anex lfounckn ausedovist f ghot: s DUSFrt thanus, h'susewe pel f I y be l ffedoowiteey s wngencek, omehod theay helsecaralllanche fth man t heme I wea acesagar, heda t therr ak ang om, hen yrit a\n",
      "================================================================================\n",
      "training loss at step 22680: 1.85 (2017-03-27 18:32:23.860392)\n",
      "training loss at step 22710: 1.72 (2017-03-27 18:32:26.927175)\n",
      "training loss at step 22740: 1.75 (2017-03-27 18:32:29.975984)\n",
      "training loss at step 22770: 1.76 (2017-03-27 18:32:33.038720)\n",
      "training loss at step 22800: 1.78 (2017-03-27 18:32:36.065200)\n",
      "================================================================================\n",
      "Lordon'st e se myove It S tolof wssara ave blkinke g d r hicllling.[En bl,Thaim ft! bobe t g as tts w f far n sth oppangepinra d tand wrakishat bup, is d t: n I che weque thoune?I kll hy Hous g ove way l kngly?Ginisthind w l st th, acosiomeren cuserd ar f sthave sews cenThangald cou o twar spreaver's ay I'sit be myont hile,Whannct rs Re he ld jegont al wotho a k arincod ir han blin t t, burot, t wididThislinck wins bl s s lllang.SEnothan.NAr tald,By buprtrou.Ar t wshardin k fanos t I she r tondl, lt\n",
      "================================================================================\n",
      "training loss at step 22830: 1.73 (2017-03-27 18:32:39.656542)\n",
      "training loss at step 22860: 1.80 (2017-03-27 18:32:42.775832)\n",
      "training loss at step 22890: 1.96 (2017-03-27 18:32:45.937075)\n",
      "training loss at step 22920: 1.75 (2017-03-27 18:32:49.096476)\n",
      "training loss at step 22950: 1.84 (2017-03-27 18:32:52.186336)\n",
      "================================================================================\n",
      "Lordyo w,Stel wa d bemndowhou f ff ure ayesthes sary Jund In pome a hirive menghift owikilinaler wsind pouth beene y fl hano Ex be' arsteds marat s Pus Me tiom's.I t as aid youfed, o adhy acoukncutishe tenong in.Thete, e, mas aseavem s chous stsend PIV ne me 'dis Muenelleend wheithis acer, bengomy rut in be yothelyenos has KUSAywiooowo mer f yowir'sAeees d the t stoo moboren an or,Anke custGu PEndis hatha atud sie cercisAn,ARI thodive y s thund t ht w: GBy, s e w ay.I Than sshtind bu me: Ifreathisut\n",
      "================================================================================\n",
      "training loss at step 22980: 1.87 (2017-03-27 18:32:55.777836)\n",
      "training loss at step 23010: 1.70 (2017-03-27 18:32:58.929917)\n",
      "training loss at step 23040: 1.79 (2017-03-27 18:33:02.057034)\n",
      "training loss at step 23070: 1.77 (2017-03-27 18:33:05.235181)\n",
      "training loss at step 23100: 1.84 (2017-03-27 18:33:08.270094)\n",
      "================================================================================\n",
      "Lordemevearinsareard.SPy as t ld wqufourounghey thigas pree, hemone t RATon'l, cu is oupainareedTirealaneean he icha,Ty es the.Natrom hald tor arinor g'sther gighinanching ha derillinove g, asExir, an,SEdstelathind alomou atrmedeBeenuearfree s.Whalld founerndive sOPin hes,An athe.Song cl testheanit findarrowe t y frn wauchirt hes.Thyocey se ingring-se Juse Ifethe tot:Wh aber'lluTollouraixmavis?Toistisstis, me wiral is, Luce ar, henineds,Wasorecr ak, todithoke ountinodead melomalerse ws, s, the Lont.\n",
      "================================================================================\n",
      "training loss at step 23130: 1.84 (2017-03-27 18:33:11.831876)\n",
      "training loss at step 23160: 1.96 (2017-03-27 18:33:14.951853)\n",
      "training loss at step 23190: 1.70 (2017-03-27 18:33:18.101402)\n",
      "training loss at step 23220: 1.81 (2017-03-27 18:33:21.224736)\n",
      "training loss at step 23250: 1.83 (2017-03-27 18:33:24.321620)\n",
      "================================================================================\n",
      "Lord I fil, anonchtacer Whes int. vin o gneevia,Anoppr'teprd f.O, fakid, ANothexpay tepply shakir, theat toler tathin as pang, thumadnchexthither th fout I'loneroll I y ono it mink nthets nes id amst, s.Ben'dncallavilithetithis the le sbre lingmadsar ane,T wangifo, at thouceit So's outho g weanges d t ay wat hamand.A rt tAs d heid t:NENThetu, il, havie dsherrs l th d wheesemy higotongith oobesinth I s: ROuge, thins!Whertspeacooterngre we tur he t is d blve howhino dou e om y? tal s methirsin-ar alys\n",
      "================================================================================\n",
      "training loss at step 23280: 1.92 (2017-03-27 18:33:27.819091)\n",
      "training loss at step 23310: 1.78 (2017-03-27 18:33:30.853845)\n",
      "training loss at step 23340: 1.79 (2017-03-27 18:33:33.887625)\n",
      "training loss at step 23370: 1.78 (2017-03-27 18:33:36.922765)\n",
      "training loss at step 23400: 1.85 (2017-03-27 18:33:39.945135)\n",
      "================================================================================\n",
      "Lordogrand ghar qu Y br mathe dig y hemy nr  d,Tht.Th damose! th'ses I ttl the tovu my thy hechy,BKn y?My foShererorono icout ttr, uprurrd sall he ho w ote,AnAxase wille irerve the nghath ak ty upatid tt ofoughcolithinoupl ct an,Bu MOThe ane ngEvitsicad, not tul waslor ilour jar fotu athal loout sailklal f Themackealld.Core:Hinsthanomaimsheonino? wis hear bry wesivaloufre t d ir thar is gs.O u niviseest ly m sorowass I bor  GotwNORROve ins?Sho dERAnoundvinche dFowinu,Towevinconthelldinxerve t induce\n",
      "================================================================================\n",
      "training loss at step 23430: 1.73 (2017-03-27 18:33:43.700845)\n",
      "training loss at step 23460: 1.72 (2017-03-27 18:33:46.742794)\n",
      "training loss at step 23490: 1.74 (2017-03-27 18:33:49.787788)\n",
      "training loss at step 23520: 1.71 (2017-03-27 18:33:52.813313)\n",
      "training loss at step 23550: 1.82 (2017-03-27 18:33:55.839526)\n",
      "================================================================================\n",
      "Lord ga y, kive hesowelves, wis,The fe inch t y Ink, outid cuThe llowheat ted nod.OCoust timiveallace natouepok I's I I be hthellansthe, ond.Whthallopld wanowhit agshededsavowitr DI t thissos, reed ed llist llantheorid sCI incaz frintsarevirang pFO s ine,ofothfowee o cofovitis.Isangithomy t Dowher,Coder: yourienolor wes m.[Theieafoooith int wiclouth we, veu harasatheg we weunt tre ss, isatsodin-s nco,ARerr abofO'sthousowiee se tis. saro hel,Scunds blfutoneerint.Narer menin kndurttod whe p, handengha\n",
      "================================================================================\n",
      "training loss at step 23580: 1.80 (2017-03-27 18:33:59.345882)\n",
      "training loss at step 23610: 1.89 (2017-03-27 18:34:02.379876)\n",
      "training loss at step 23640: 1.77 (2017-03-27 18:34:05.397451)\n",
      "training loss at step 23670: 1.78 (2017-03-27 18:34:08.437469)\n",
      "training loss at step 23700: 1.76 (2017-03-27 18:34:11.456217)\n",
      "================================================================================\n",
      "Lord wit, leces fo nimath, ie he I dofore qul:Wh smend way r, osisthth twFr OsThee hanf Ift tofor ackldurert:Yomachy I hedupeewank be onato:'e!Wh paurisomofoo man, le. nthr owase thuthed h hishind t be d e, t ceavires m!MEI serenenoth's a hivee thofeitif lon bery t s, t br,AlONEATou t t imyes I nMofom ind 'dil omy s w, his watymicetins o hooo yove w beshealisthequtsh t. I a MItono I condr' y ukncor, 'sby, f Capl'dir, nd t ou greDUIThave r ay, on's thill irst d but he qull wheadepoo ghiloushetce fowh\n",
      "================================================================================\n",
      "training loss at step 23730: 1.81 (2017-03-27 18:34:14.953922)\n",
      "training loss at step 23760: 1.73 (2017-03-27 18:34:17.995318)\n",
      "training loss at step 23790: 1.79 (2017-03-27 18:34:21.016421)\n",
      "training loss at step 23820: 1.76 (2017-03-27 18:34:24.049520)\n",
      "training loss at step 23850: 1.85 (2017-03-27 18:34:27.079048)\n",
      "================================================================================\n",
      "Lordor lis ks ce d yste d. ovaguen I m, ran m se tyo lo NGrshanin, rpous hoo louaprth athamuresWhe'ss the t k s fup f ' ast.I tin, mu itouprthis isUMys ty,A t y n I Githale u n waksce pose[ hat.Shave ad tha f I as d t oomedis bo n d mat-heatir co ay be ind sthandovised hed.Lornourit in m th be a a--nd botu he din this n tustafo'dsheaviveu win m gststont mpe d en il I, me'l d anis.Shildigho el n we lldou s n alatofis atrg at, ld f d ishint therinsist e'lofrul, as we anatisthaidout. ts o ansce tran jo\n",
      "================================================================================\n",
      "training loss at step 23880: 1.73 (2017-03-27 18:34:30.571341)\n",
      "training loss at step 23910: 1.67 (2017-03-27 18:34:33.606642)\n",
      "training loss at step 23940: 1.70 (2017-03-27 18:34:36.635844)\n",
      "training loss at step 23970: 1.75 (2017-03-27 18:34:39.661310)\n",
      "training loss at step 24000: 1.76 (2017-03-27 18:34:42.689860)\n",
      "================================================================================\n",
      "Lord has tot beno tht s, ieepy g. f t aprs!I ory:Fore he ha oureWe weather ands g t theediros sth chatius?ITheryI Cod,I tistin wis ct gouthe o whiedese.LAngen,Gu ldese ay ySoutse melis stis nourehavepera.Hiseede,Ay pus id.DPe IVTIf atin,Lee.Mowee t lo sthe?Th t feI s e!Andactr theaneangofe rre u.OTherorus, wisspe as? t oua!Coffyow soton,You barayorare,HI atoord telok,My grilforeas silousharpe! we t.He CRYod Louthingo d ORourTo t y hGofoucasaspave'd.Anereathathigan dormyord d wigitA I uthe: my par OC\n",
      "================================================================================\n",
      "training loss at step 24030: 1.78 (2017-03-27 18:34:46.201858)\n",
      "training loss at step 24060: 1.79 (2017-03-27 18:34:49.236302)\n",
      "training loss at step 24090: 1.80 (2017-03-27 18:34:52.268070)\n",
      "training loss at step 24120: 1.74 (2017-03-27 18:34:55.298878)\n",
      "training loss at step 24150: 1.72 (2017-03-27 18:34:58.330885)\n",
      "================================================================================\n",
      "Lord: tinfar, howastyotis. hesAr je I Exceny ad t h,Whalleat boningubo inthucat tsth msaus!Thoo anive touliseven powintht Bute, kind s.Ofllor, tiaby, teshoujuthr, Kin, bethane? w, wrny sefanod te.OI weyowwhad Yeser.Ejat w't at t ngd are?Thelandemecofe fedNO, therlive brs PHe!A vithowhe blllout, s r qure ath g venthankis oum'ses cofut this! awow y thofouferaie t ithtorikin.He:H batheth.As th pe stsit lor: bl oustey fald, len, ofr.FO s magound y. te.Extingrde th, f lofteen, ld ayot y mo,Ind h at, plll\n",
      "================================================================================\n",
      "training loss at step 24180: 1.73 (2017-03-27 18:35:01.835657)\n",
      "training loss at step 24210: 1.71 (2017-03-27 18:35:04.867211)\n",
      "training loss at step 24240: 1.73 (2017-03-27 18:35:07.891455)\n",
      "training loss at step 24270: 1.82 (2017-03-27 18:35:10.920117)\n",
      "training loss at step 24300: 1.81 (2017-03-27 18:35:13.944181)\n",
      "================================================================================\n",
      "Lord o cowitinldout tha orn t othonco peandemoncoborn--s atheve s ame f m, fro cubealinto ge Shome mes n isened t dit teeryon.Ous th f cazFonsthethe lllthin' sthy hesponiran thth oousandaleatanithife toloucerk youstaf tequ ca de winee f wnene!NEntomionkiouano otesthquSTole s yThe malaid akneadiors sth s u ledeand,A me thagoswis wano s win floule th, IOndithe gh thyothenof w, fee? ty thof oou halantenirin's wrd ' an towipe t.DACo grp, Possprem Yony heryoloufove'Sher he wooo t mad DI inovengosthend y \n",
      "================================================================================\n",
      "training loss at step 24330: 1.74 (2017-03-27 18:35:17.485597)\n",
      "training loss at step 24360: 1.86 (2017-03-27 18:35:20.518741)\n",
      "training loss at step 24390: 1.78 (2017-03-27 18:35:23.549846)\n",
      "training loss at step 24420: 1.83 (2017-03-27 18:35:26.581078)\n",
      "training loss at step 24450: 1.78 (2017-03-27 18:35:29.599410)\n",
      "================================================================================\n",
      "Lordme mof be,Fondas'soret tterin's igre!Yeso hes:Th eleevere fPercer, brongends fereenempe,Whelekn s. puees my,I  dgobrigoast, h, re ialal g poke: orashiceandee,Bocern thetrr.RETh'st thado h,We iesetod makit.Fownn t, n toun halestr t hideealacy ce ue: wen Owhind,A l ak, wse co g'd, ldere,Pren femend, arive teitha In cos ind ser thuth brgisouced yont Ge s tounthererel,Thecol r tho wornt,Bu owimerd ieshongowA hakn f ge d wowicered hitho y k at piricoutounteay pend I Momadolld terd myo Ber bye?Ye me f\n",
      "================================================================================\n",
      "training loss at step 24480: 1.69 (2017-03-27 18:35:33.115205)\n",
      "training loss at step 24510: 1.74 (2017-03-27 18:35:36.144067)\n",
      "training loss at step 24540: 1.74 (2017-03-27 18:35:39.174597)\n",
      "training loss at step 24570: 1.79 (2017-03-27 18:35:42.197148)\n",
      "training loss at step 24600: 1.81 (2017-03-27 18:35:45.237248)\n",
      "================================================================================\n",
      "LordMy sManit I any h[Ayon,Ar apo. g.Tha,And seldsty meshan h llaso ad biserndUSAng t bere. hanoue ht, to tim arol youlig Pous y, l,wno, y ccaid cu ierand.G tomes.I purothotEd br in avenitighiserdendimerdn hat nehy wangh, cis st wn,Th ake gh f s, a f isAnd oul If t are tawhatout gothemilou?I hem'd?We I tot hu al bove vinduroshy I o t thwha athain,Wis, I'sbanioul es s: frk'so r wo wis hes, thivithr on il atr gur s hepustanu finayo tel theand f ty forerye hin rosthiellllll y Pimpungos lit je't t acy w\n",
      "================================================================================\n",
      "training loss at step 24630: 1.73 (2017-03-27 18:35:48.736369)\n",
      "training loss at step 24660: 1.86 (2017-03-27 18:35:51.764803)\n",
      "training loss at step 24690: 1.76 (2017-03-27 18:35:54.788597)\n",
      "training loss at step 24720: 1.86 (2017-03-27 18:35:57.812822)\n",
      "training loss at step 24750: 1.74 (2017-03-27 18:36:00.844855)\n",
      "================================================================================\n",
      "Lord houcal omys: l bly bumea!LUSiche f u, t, o hanor, y, y:Shags le,Se me fou nculed we eararishie s urupe, thenmemelld allere,Trounthemid hiee 'He l tot athenga?Wher t ror tiorveve wh tave Sh orvexprouea t so eroueye t t, mercetetithear ounste.TRe, tinit tereveomy, eeg:Oue he ussoudshacathe d wicul, starene h,Towier whilmerorodrig ha OMiurolay d'es:Splin turir's] tooupat?RK aulo wr be tlas ind wicell ntrero angus lid as paindeeally wont stucou VShatot d tortinntheimace, wities,Yourithe yopor s wer\n",
      "================================================================================\n",
      "training loss at step 24780: 1.77 (2017-03-27 18:36:04.699682)\n",
      "training loss at step 24810: 1.76 (2017-03-27 18:36:07.742407)\n",
      "training loss at step 24840: 1.83 (2017-03-27 18:36:10.767021)\n",
      "training loss at step 24870: 1.79 (2017-03-27 18:36:13.803603)\n",
      "training loss at step 24900: 1.83 (2017-03-27 18:36:16.826937)\n",
      "================================================================================\n",
      "Lord y d tisHaveathanndousthak qurd t wwongr can eredano, ant t my ler'sAr, w wive cll, wiragrthrio IshiveLUMy tan'd ctul: thorsugouda do o bateld ne my, Exinon alis's ovageng gs non d waliro d d y I s aithourathigey f t min'ssu. rourthiofou,Bes![Dout o blece lan's a HAnefroncr be.Endr wou min hate thaupoot that m ts,'d.RCr boupllit te?Noo y, houor'sondoray grthaveninveAs sh dulllly Imeno bushy brsay,A tigno,--bertaclousHo I!Wes, noll sh ExTonk, f s.Tomaf Disalide'd chilim fit wot y oll t mitof chy \n",
      "================================================================================\n",
      "training loss at step 24930: 1.77 (2017-03-27 18:36:20.333041)\n",
      "training loss at step 24960: 1.85 (2017-03-27 18:36:23.368452)\n",
      "training loss at step 24990: 1.89 (2017-03-27 18:36:26.394664)\n",
      "training loss at step 25020: 1.79 (2017-03-27 18:36:29.421505)\n",
      "training loss at step 25050: 1.80 (2017-03-27 18:36:32.457791)\n",
      "================================================================================\n",
      "Lord marist thind in gheled thafollemo w be?Hornd horee.Toroured fencthore ceer ol! therem, I d su. ecest a PRer'lloremyo me cer akegite velerrecRO,Ande my fe Ime br t.Wh ge inst ary hakshie g winen:Imy FoZFow, pof the g:Beeall tofer rewe.ROvoungoun y torn te asodioweTod w, ges bewef ctiran.Anshe, mySAn eshis choththar corco llire me thuScearige m,Myo po othenelothn I I my wohe f ourdis pAbealis Me.Mag fengeeesh ey.Fouesaconghitlloutholeray s hr seerillant th adat l, andr Suerr Of t'selothof lor lar\n",
      "================================================================================\n",
      "training loss at step 25080: 1.74 (2017-03-27 18:36:35.962998)\n",
      "training loss at step 25110: 1.70 (2017-03-27 18:36:38.995362)\n",
      "training loss at step 25140: 1.82 (2017-03-27 18:36:42.011038)\n",
      "training loss at step 25170: 1.76 (2017-03-27 18:36:45.033397)\n",
      "training loss at step 25200: 1.82 (2017-03-27 18:36:48.081288)\n",
      "================================================================================\n",
      "Lord wifousPo Cupainekin inovesinteen th s Miclllyed alinou thilllloure ane, t all wher teliokelayo t.ENEnervee t st nt tu y ng yond abalaif sueree antole y INonecinthanger y an isinthave nde qut is,Anf y nce.Y s br bll icat cakngourerldalabl ent t y t m strey ff tand wild f t t y iswithe topre lrt nsouncliche ar Of aterthashinomingher sacot iveme waneree Hau Thebrsithit at es arereke k thas od ur won'd seere re make t my s larredo fomat in polof GOSout Serthed mpamed thelar meng IClftthy te asthive\n",
      "================================================================================\n",
      "training loss at step 25230: 1.77 (2017-03-27 18:36:51.602197)\n",
      "training loss at step 25260: 1.86 (2017-03-27 18:36:54.635929)\n",
      "training loss at step 25290: 1.81 (2017-03-27 18:36:57.670124)\n",
      "training loss at step 25320: 1.73 (2017-03-27 18:37:00.700795)\n",
      "training loss at step 25350: 1.77 (2017-03-27 18:37:03.727233)\n",
      "================================================================================\n",
      "Lord fuasodran wirastheathe keco fieawicoree I he,ure toris s dro, ble no t, IO my t s d ar.Pelleaice, I ay Coorce akegacof od frd bubate h s bet ortt f hit hemars ou tiselo'AUShan hithiss thavis thitLe: o ws plisufo! he I at, br y RAy, h fy, ht RThate s iss tt ta wI gauro thesemee, goue soorar polle latou thety chicor ifayovitivese ys cachimupu f hais thes hidey,Yo be, ithat pick, o f fopouct y bu ild tleaw: youndstone youswisthat hathice t RI my, nSCHachith, y,I herabr brecos k, ateliner owit suno\n",
      "================================================================================\n",
      "training loss at step 25380: 1.81 (2017-03-27 18:37:07.247662)\n",
      "training loss at step 25410: 1.81 (2017-03-27 18:37:10.290503)\n",
      "training loss at step 25440: 1.83 (2017-03-27 18:37:13.324549)\n",
      "training loss at step 25470: 1.89 (2017-03-27 18:37:16.369436)\n",
      "training loss at step 25500: 2.37 (2017-03-27 18:37:19.404350)\n",
      "================================================================================\n",
      "Lord s s bondoponary-l mous oo 's pe ony, gho m.Exjothads a sllincoot ither wer,A thye foknousttend.Le alfHale utul baurtut nd orishourkin hed ce miond axid ithystrlld joures n'INods line Fomowimu,Wh laved ofridezerkintoous t our,Thuroulolllor, gn Goothaditherff, didould chalofondove, ainand d, wink wn aind, brainot, br ome d,Fosh thot!Exir,Yok why, fod we FubalimTh,HTHisuth f west, f botinug,Tos rat mys vind,Moldist ugr, d cee t todil, my.Wh st butondudine, ber'sea,Wit,,Poumealy,Ang azrrans, arsUs \n",
      "================================================================================\n",
      "training loss at step 25530: 1.95 (2017-03-27 18:37:22.896866)\n",
      "training loss at step 25560: 1.85 (2017-03-27 18:37:25.947144)\n",
      "training loss at step 25590: 1.76 (2017-03-27 18:37:28.978354)\n",
      "training loss at step 25620: 1.77 (2017-03-27 18:37:32.001328)\n",
      "training loss at step 25650: 1.63 (2017-03-27 18:37:35.020623)\n",
      "================================================================================\n",
      "Lord athe m ha wil.Souteato le te ow te st his pos o ands, an ht fodom s the whard himaw od me this k h, wrutheats trd fr warr tok Mooond erit tid pomber.Thaththanco aur Goucano I ots' lshierar CHain cerche!Ditend hane Istry, I and thiso m' wng e oul h hurever aron s he bll tar ceversheean,Tas ouse.Th heres crust POf Ind En mal st, in hat gherouswisale BRAnlits CAnds thy g me hig,Beho u t OOLe hize a t le ll astNI me ndomor? mof s he wal d y lo hy n: seavo t?Nor icowance vatAna h aviticerFr, ho wrow\n",
      "================================================================================\n",
      "training loss at step 25680: 1.75 (2017-03-27 18:37:38.542014)\n",
      "training loss at step 25710: 1.84 (2017-03-27 18:37:41.578229)\n",
      "training loss at step 25740: 1.85 (2017-03-27 18:37:44.598647)\n",
      "training loss at step 25770: 1.79 (2017-03-27 18:37:47.622806)\n",
      "training loss at step 25800: 1.76 (2017-03-27 18:37:50.650179)\n",
      "================================================================================\n",
      "Lordocanm. brecul, t Shesernds tryod ANExas heand e te.EThifoure, gotor or,SEn.Ans: juse hel wa ice, nourdstour om crereseerudodDidO, the wecelimit m, altongr Bed.[En cor wis gisefo cousot trd sayTher t maunscobe o the f eme: d bl fer outou'lourar:Byonon is:StROund t,To 4And. Heardro owave'tenofe we s stussthencul hictoucl fowiofounusHendir th Kir, itoudDureserI as,Thand it.Sofee iely sencome bl alve,Coo throunmyen,Whe?Tousons!Bl ositrealimurmy,Tormigeay bey hy?Withit,-ad.We isisal pison teanertheds\n",
      "================================================================================\n",
      "training loss at step 25830: 1.80 (2017-03-27 18:37:54.169639)\n",
      "training loss at step 25860: 1.83 (2017-03-27 18:37:57.198749)\n",
      "training loss at step 25890: 1.81 (2017-03-27 18:38:00.225427)\n",
      "training loss at step 25920: 1.80 (2017-03-27 18:38:03.265551)\n",
      "training loss at step 25950: 1.76 (2017-03-27 18:38:06.292064)\n",
      "================================================================================\n",
      "Lord, eas t whest wh,f Pau CO,RYono her thes?My me llleve dequrile ath t is msollasin,Fr llfATwamime t l.The-wy mad snellenmanothin I ullou weerat avey? s neathyoundour yowithoind, de ar ve alo ffarthilleape ye I poo an y lyol y ss, t:ASO itaisthetuplin, coveandowononous y: hiowor, her he me, mehre dsceathove, mun whou, fowo t meas, yo tanthe al ald nhon: Ind thadig oo, ste, foar sthing,By,SSI st man opr ou athime ll bata-and r we intehau ts whu AnindNKOWh, woo Pe itharus thaty st nge, avie? s pondu\n",
      "================================================================================\n",
      "training loss at step 25980: 1.75 (2017-03-27 18:38:09.790355)\n",
      "training loss at step 26010: 1.72 (2017-03-27 18:38:12.812303)\n",
      "training loss at step 26040: 1.75 (2017-03-27 18:38:15.846693)\n",
      "training loss at step 26070: 1.79 (2017-03-27 18:38:18.882962)\n",
      "training loss at step 26100: 1.78 (2017-03-27 18:38:21.912943)\n",
      "================================================================================\n",
      "LordwinenttwInothavat oreanourls,Yo m han Preralisela s.Wheo wee[May s od, wiglima merig, mo,COCo ly the st!She wan'Tokint m.ICou ve el orn outha Vesowat d youge thell t thalass, dse: shapus ffire ous, dWhous fanoulormpre thecly nctThresa the o asoryorod grternd thu'soprerasthtyo k alegeroue, POfthevoffouindrtusitleld, lle ougis d o st:Witrene s? -e.ERLeisondids,Yererur.SIShondepaMy'st iceen?Thay lat ie s.Houringrighellofieng did! sio malel s: that aron ws wasine ufunof cave t macke h griosler,I nt.\n",
      "================================================================================\n",
      "training loss at step 26130: 1.78 (2017-03-27 18:38:25.406595)\n",
      "training loss at step 26160: 1.74 (2017-03-27 18:38:28.433820)\n",
      "training loss at step 26190: 1.70 (2017-03-27 18:38:31.461514)\n",
      "training loss at step 26220: 1.71 (2017-03-27 18:38:34.482405)\n",
      "training loss at step 26250: 1.78 (2017-03-27 18:38:37.511521)\n",
      "================================================================================\n",
      "Lord airo tofowe fouine y  meeidas ll,Ahat tis winglil ay bovee thawithif y milenceea I wariot, be his ndal f, in anon s m, wor: f tsstWharisit th RReyowIfeud aceirnd I the: hisisief s ay wal-prexat t.I m,Anchatm mon avonkn y u I my' wag.USTwin.Thot t ive male buthe e t dy rondillineang beerbrs: r a ste aireth veind? f acorr, thy ncoromenonofo?Anthe ath howouthags al aitheond f, me fongr In, lll orery me odeerathe! sSeer icoue to nttue,Sppr wirtearerevexe, p, thour, it k sese l a ig.Folldreafas.I Pa\n",
      "================================================================================\n",
      "training loss at step 26280: 1.72 (2017-03-27 18:38:41.025646)\n",
      "training loss at step 26310: 1.82 (2017-03-27 18:38:44.076093)\n",
      "training loss at step 26340: 1.68 (2017-03-27 18:38:47.102821)\n",
      "training loss at step 26370: 1.80 (2017-03-27 18:38:50.132957)\n",
      "training loss at step 26400: 1.78 (2017-03-27 18:38:53.167935)\n",
      "================================================================================\n",
      "Lordingor'e ierear wicurs, momeduf theay.I the CHeino a I n cowodandengharo werkim laplyo simal me?NThastat, nut h, Fo ocand t pughaysithoreanefourequ, hin m e wis my,chare t bowin, lld thy Morkirour moree hy,Thed s t, tish sh, pldem ithus cor,A tis anthee d thothasweathonofrn, h hes, st imar th,Ande warobomsssisputo fer th m,And sshr?Homyonit.ODikngo ay and, goorares ft,Me,TouCouthisthitu, bus trende hy?Wopr fearifin f gloosse.Wh matth calidsoth, t anket y yon wAvidsul,Ock's thy, he athaveeardatht \n",
      "================================================================================\n",
      "training loss at step 26430: 1.88 (2017-03-27 18:38:56.776976)\n",
      "training loss at step 26460: 1.71 (2017-03-27 18:38:59.803148)\n",
      "training loss at step 26490: 1.81 (2017-03-27 18:39:02.824666)\n",
      "training loss at step 26520: 1.73 (2017-03-27 18:39:05.859089)\n",
      "training loss at step 26550: 1.74 (2017-03-27 18:39:08.892036)\n",
      "================================================================================\n",
      "Lordean senio cocidI s,Bremequth, gs wietel arengst lous t I d,' aloloth allldsthindgh y, whathind gr bundealais artous adowh.You g s s f t't kne, ftotorthendoshourr bitlleld.OtSONowifazpano tormeathanoutat vean po iotee Prthimus sthabou ndilis the beesar ouke ouhenthentinol aru f sondu achapllknied h, bllind basede I,An chardin wat thaks y, fowisincers hond w s uNReldsu?Jatind ht hisin.Ho t e.Then IPSo mer Re, yMok I ckeracht s aknshee s beer wiby,Abrnd bourshonequsieThithee wiss, bel wo, strntothe\n",
      "================================================================================\n",
      "training loss at step 26580: 1.76 (2017-03-27 18:39:12.655217)\n",
      "training loss at step 26610: 1.92 (2017-03-27 18:39:15.699220)\n",
      "training loss at step 26640: 1.75 (2017-03-27 18:39:18.724072)\n",
      "training loss at step 26670: 1.77 (2017-03-27 18:39:21.756601)\n",
      "training loss at step 26700: 1.80 (2017-03-27 18:39:24.786559)\n",
      "================================================================================\n",
      "Lord.The m, handar, ' s thy, d anothe heamowie.Mom san, and s t ars, ke Ofory tr byowse highol Chondos w unds nshen thar sstloff Hacord colle bliere o thand rct shanountanater.By a herf houthely: g: paitherest u, po imer,PHald, O, pls wk ndere, ls,LDod calllpoure tEn ELothever Jot rs,O, Ofousts.RA alel s dwo on,We hokelort oristhin he dizal Fardfellyoberadol othyhando s hedurompineisth rithaghe itidiveatomyo\t thantiegucacllitot os Se I athoun fofanocofo has lchom act, the seseedave lieAasere.Whallf \n",
      "================================================================================\n",
      "training loss at step 26730: 1.80 (2017-03-27 18:39:28.304495)\n",
      "training loss at step 26760: 1.79 (2017-03-27 18:39:31.342847)\n",
      "training loss at step 26790: 1.76 (2017-03-27 18:39:34.368397)\n",
      "training loss at step 26820: 1.65 (2017-03-27 18:39:37.399058)\n",
      "training loss at step 26850: 1.67 (2017-03-27 18:39:40.425848)\n",
      "================================================================================\n",
      "Lord t d s yo ilvid y havet atrout w g-s lanod llke, ene wheced hathe ar thimechinct al, E I t whes cofamerourtedthratoolld wofl aid, utheat ar owis ave s? h, and m ooonoowo I spr mimithathathes pid fourt ge lllfovedo t wirit, m d sod y aldror.I s ld smen m: me nwer mprt lloot! nt hup mat fe fua te othe  t hacaist t brbetr phowathive outhave I ff mend at o d oure t ty hemaree, wh f whemof sbeco ghise DUnoolelleavoumaimeranaghak aly he Gl Bur uthis hin ther d llochicarindre n O: touseft: che, be han \n",
      "================================================================================\n",
      "training loss at step 26880: 1.85 (2017-03-27 18:39:43.956571)\n",
      "training loss at step 26910: 1.88 (2017-03-27 18:39:46.996292)\n",
      "training loss at step 26940: 1.78 (2017-03-27 18:39:50.037808)\n",
      "training loss at step 26970: 1.88 (2017-03-27 18:39:53.078992)\n",
      "training loss at step 27000: 1.75 (2017-03-27 18:39:56.107244)\n",
      "================================================================================\n",
      "Lordila e nsI as I br y,II ou: adn peceve isis.Heyee.Edr ELThopuWharangereexme s theaberp.Ther., isaceanarins arants heve oorers? tayond ullllereTRe are ye satar, tetou witart t to' cat thalver poore,-ff--Naronos: an, thaneshe!Frg: cexk.EN he e burkirirehove atibe: tenet INoloucousinuffifales m a athaldiro wet, youredethis Arertath!My tMy I'seatoryomarcouth thtel s stt, at s us by, bu wive serond ave cem n hene th anourid-CThath,Foumyr ty: ce:We ake d mee dil,Bur hicld the, walemson d prtsspearoplld\n",
      "================================================================================\n",
      "training loss at step 27030: 1.84 (2017-03-27 18:39:59.994396)\n",
      "training loss at step 27060: 1.83 (2017-03-27 18:40:03.042191)\n",
      "training loss at step 27090: 1.80 (2017-03-27 18:40:06.081246)\n",
      "training loss at step 27120: 1.78 (2017-03-27 18:40:09.128684)\n",
      "training loss at step 27150: 1.75 (2017-03-27 18:40:12.187149)\n",
      "================================================================================\n",
      "Lords d lyo r s.ANone TGlanorand t I ckinar.Thotu,Thoureaneygond wid bre beedary be thit---th,Tht oullelyosh tsmmmantas s ms imane anor y an we Go ty.Tie anm,Th hithet turtin,Whied at, kegat lldeaz h phouisind?Fry,SSENod pld piges dy,ANYonthamy:NE thtuselemorsand ayWen iouchecy nod t at,An,I t, delistAnsod salllearet hestenerindowacuthad,Andushiem thistie wiss chere fe'sereto, s, l athou,Ffr,Un O hend path wamnomy 'teier I k dyompeleeret mpacrsthe maig ye ur amind. ursareree,Epay Seeenfrs kenkshas s\n",
      "================================================================================\n",
      "training loss at step 27180: 1.85 (2017-03-27 18:40:15.702075)\n",
      "training loss at step 27210: 1.77 (2017-03-27 18:40:18.736491)\n",
      "training loss at step 27240: 1.66 (2017-03-27 18:40:21.773636)\n",
      "training loss at step 27270: 1.73 (2017-03-27 18:40:24.818020)\n",
      "training loss at step 27300: 1.69 (2017-03-27 18:40:27.857360)\n",
      "================================================================================\n",
      "Lord wouravend m be tot soous Wirosin, is ordiliofe msthellle, ss m blave m,Se he.Ano irfo?OCroubutox ld nesir's bes lloudelinkirveren mit t coreative.Sa wild athirche m, mer loopou wath che wo's Fre he er d, hou.And war.EREnd otldAnowild womesave wo.Yeno he owatomaloris ad th s Frsnoee uanedulers wis y hided, cek chathtoly alsu, cofot,Whanotst ives h ho s be o won iselooro Itsomome, athertofur d no te o we.Th, ssened ne'shith f outhoulo nghalin,Crth t d stworirin, h pelesthang, at bes be her pe br \n",
      "================================================================================\n",
      "training loss at step 27330: 1.81 (2017-03-27 18:40:31.354888)\n",
      "training loss at step 27360: 1.91 (2017-03-27 18:40:34.401982)\n",
      "training loss at step 27390: 1.80 (2017-03-27 18:40:37.443141)\n",
      "training loss at step 27420: 1.84 (2017-03-27 18:40:40.481161)\n",
      "training loss at step 27450: 1.72 (2017-03-27 18:40:43.505637)\n",
      "================================================================================\n",
      "Lord bro the'l,Nour boup.Sourdityofrawithisayil s d surby pr caroun ton,SAn:Thabrr, MarealoJll DORe.He s thekelatAne ThourTh, amoland beilayor,Bilans we thrs solerforarowar inodisonme Dhotwe!Where be mo eren fomoom tou fithallfasAsteanl Katewinor t mens ghame s y. hre d.Indetr?Sowilewe Camy dgl, sempr s plleth's, as, ttroucofo: stomorok,Fo thilove, dord o nghe.To waullithe tucot lelvend an he. loo, siow wh s of, yswe wou d: wichofulasthrer.Frvetinghesowiseme:Tot of is bey CHeurt nes, t fr, t ceenser\n",
      "================================================================================\n",
      "training loss at step 27480: 1.73 (2017-03-27 18:40:47.421166)\n",
      "training loss at step 27510: 1.79 (2017-03-27 18:40:50.467270)\n",
      "training loss at step 27540: 1.70 (2017-03-27 18:40:53.498160)\n",
      "training loss at step 27570: 1.78 (2017-03-27 18:40:56.543105)\n",
      "training loss at step 27600: 1.93 (2017-03-27 18:40:59.572565)\n",
      "================================================================================\n",
      "Lord greavin's, I me thy outinanis, lllven n, s s d Ife pr mbyoourus, thanO! forin meok hit.By hasouthofyoricheathr e, ninthaby,That l'sprones, he all o le, womave hen themornd, as Hid, nons: Diveyon athyonsind urju.Enesarteneathor.Whn y isl In in llardm spetald t glal bis,YAr ind l cathel t hinerrerd c arel SEglldomascan bed sotimarse whathat colys p-l:The?E' thie.ERIntyove anththe stuthor.Dllo ma-An, thandernd pe arind the d I mest spllelisAnd hin mella cHet Kit d s,I ana thin f atonthat llanathic\n",
      "================================================================================\n",
      "training loss at step 27630: 1.71 (2017-03-27 18:41:03.084822)\n",
      "training loss at step 27660: 1.70 (2017-03-27 18:41:06.134081)\n",
      "training loss at step 27690: 1.79 (2017-03-27 18:41:09.179800)\n",
      "training loss at step 27720: 1.73 (2017-03-27 18:41:12.221661)\n",
      "training loss at step 27750: 1.87 (2017-03-27 18:41:15.265444)\n",
      "================================================================================\n",
      "Lordse fe timatof ve wharmo I lof ak f he ad byo er nts toul pu,'s, I l Pu, utholl-pitonity YeresthitMatapethaste ppr lack]Ext l! ow a sthigean rt r,Wit:Septe atacas be, thyooves y t ho peare ith hef a t, or.[SI winte'ss chel st m t s d sint PAnse, as u s ayouNorisWhfus t Prarse f'splorn,Yo t! ofaut liveat t we, CAsspourin ot aniorse whe sck d aran: windoumanean wenis d d,Haris! wot bs themerund awourik o mis t s ou yejureth, wot bl Gon ise'toshat JurprtCondres earainovowithaprfer sasushil aie bu t \n",
      "================================================================================\n",
      "training loss at step 27780: 1.76 (2017-03-27 18:41:18.794889)\n",
      "training loss at step 27810: 1.77 (2017-03-27 18:41:21.835916)\n",
      "training loss at step 27840: 1.66 (2017-03-27 18:41:24.877966)\n",
      "training loss at step 27870: 1.79 (2017-03-27 18:41:27.907637)\n",
      "training loss at step 27900: 1.78 (2017-03-27 18:41:30.954496)\n",
      "================================================================================\n",
      "Lordnearak,Heve ICoupimanequlthy forkeautharet: bl t: ouray, futhese wisherurtellouce londeanarothoully bunmy ben,NERYoman's ceangain wit pl a ct totheth the, ond therent,Antundedystoulylllt oriethamy,Bun He mert tethoepo'd theswe, le owigI,And.Foourechitouake IPEnffo'ed?Who'stenorlllo man E dplounceanueoulicerereawspper.Lo leth oreaworakent haintot uresest,Fourt,Spad t s teun cewef g, Ler lothitI at, nthtupary?Wed initit hanttoubeneoobure anginu Wh gour, n'd:DPed hisitile'sl ayind, ferREvarinotorks\n",
      "================================================================================\n",
      "training loss at step 27930: 1.71 (2017-03-27 18:41:34.794697)\n",
      "training loss at step 27960: 1.82 (2017-03-27 18:41:37.835085)\n",
      "training loss at step 27990: 1.77 (2017-03-27 18:41:40.876605)\n",
      "training loss at step 28020: 1.85 (2017-03-27 18:41:43.913745)\n",
      "training loss at step 28050: 1.75 (2017-03-27 18:41:46.958563)\n",
      "================================================================================\n",
      "Lorde RISt bugerageroratecr te d thed, st s w, s t ishira t, dns wisse he sthe nd mwin d ame, RasAnt sind lymitotarf, urt cthind styout Grande ds bube,bef le an'sedanat and f aknese s t s te hicoupr by nturves, br gothathis, anave.I f torene wntato, the s DEn cusst wnasirdod w, wig WheTund chint hthe o st nd ghy t 'l m sh lopramathe,thee y k'espt sWhowe IAs mid ha hofes andste:Ifnt miveendHesurowe ithee-llt je f wssys upile adieconf Thest pthinerllane.End d Thod onte geawesstasund pred firintheaisst\n",
      "================================================================================\n",
      "training loss at step 28080: 1.88 (2017-03-27 18:41:50.456503)\n",
      "training loss at step 28110: 1.78 (2017-03-27 18:41:53.490546)\n",
      "training loss at step 28140: 1.68 (2017-03-27 18:41:56.524952)\n",
      "training loss at step 28170: 1.79 (2017-03-27 18:41:59.560230)\n",
      "training loss at step 28200: 1.72 (2017-03-27 18:42:02.593908)\n",
      "================================================================================\n",
      "Lord I fet inethe my thet.Shethe fot shokIfalaulooruststhenorerearis, Enu r se touloan'leruree I eandowhengerds.My, aye t boue wis toufom.Windis we tesu buesh sherysothy,An:Je fulo thyes whoures se wiruto!Whe s wouno lledaveawimanoorve:Biloourind min heecrilom nas.Ar w quss,'sharrd atofrese wat, wierest gsthe.Expor yCHouree o glasmershes I wiloryomoobevencherasasThemeealtes iessthess d Anallseremat hawherewngel ood or daiee bys?Tharrens ionweengal te qugoust shio,Westwelise fe tilureced,Awhes heraur\n",
      "================================================================================\n",
      "training loss at step 28230: 1.85 (2017-03-27 18:42:06.105038)\n",
      "training loss at step 28260: 1.78 (2017-03-27 18:42:09.152991)\n",
      "training loss at step 28290: 1.74 (2017-03-27 18:42:12.179438)\n",
      "training loss at step 28320: 1.79 (2017-03-27 18:42:15.204432)\n",
      "training loss at step 28350: 1.73 (2017-03-27 18:42:18.227498)\n",
      "================================================================================\n",
      "Lorderan andToche f camy kin--ll t of or I kl pe, s, s, I,Gieldarime bees.Whawer, be.Engencowepre. slove! ainthy remend ovemyowe, kno wo wasthal dig,Thy Fooucetimy ce eliesn falen, alomy f le,Faurorer m ith, h whe ste, ue we t.I th d tcoteve y, se!As tho Geraincourtindondet arveced ou,Anee c.Leton I ng thikerkd-prve ese oven frkng llofor soramyo aines rliee seealoo hur aloremimy plat pischash!Ind Nonk sIncho isarndove y My Thisndilole If.Uneres p.Emowhielim bashave jie chedot ct se hathest, heffounc\n",
      "================================================================================\n",
      "training loss at step 28380: 1.76 (2017-03-27 18:42:22.166355)\n",
      "training loss at step 28410: 1.73 (2017-03-27 18:42:25.191933)\n",
      "training loss at step 28440: 1.69 (2017-03-27 18:42:28.215811)\n",
      "training loss at step 28470: 1.73 (2017-03-27 18:42:31.248462)\n",
      "training loss at step 28500: 1.65 (2017-03-27 18:42:34.296747)\n",
      "================================================================================\n",
      "Lordid thipod fut wow ve l wir.Bes d o mBegillisun, gaiter icormid I wacet can piche it s ids diserirurdiserth my edas I ke, at mais Gangs.Whe's Re bie y'd f wison e a hte.Ph th Wefo d r, hes heast nd from tyoforememy ifr.Tongur pare ifoofrto prd'l med,I s aus h wive wes r'l ShiknWe te be, ck y d ien ifound whates p y w if inkenced.Shenore,Byo nhidu e,Whest I mer pile f nre spur's, fonie d Arcat fr leatI Imerimyorir we. she: that ait houthes tometifit tesof lak, byour mn,Yor, nart, tuspotouto I chee\n",
      "================================================================================\n",
      "training loss at step 28530: 1.68 (2017-03-27 18:42:37.792936)\n",
      "training loss at step 28560: 1.75 (2017-03-27 18:42:40.822937)\n",
      "training loss at step 28590: 1.79 (2017-03-27 18:42:43.854579)\n",
      "training loss at step 28620: 1.81 (2017-03-27 18:42:46.894262)\n",
      "training loss at step 28650: 1.72 (2017-03-27 18:42:49.919191)\n",
      "================================================================================\n",
      "Lord h fthiculow.N by hanisphero h irkeds,Wike shandsus Ry ives kes me tind aprp myinstare'tsthatet mare d ay heio, For at: w tisity ns han: Frsss y imbo oncaZ g thy thee d lind thisutisencrayourthin, o hold hous thachtey: hir theu f t pldifores:NWanth'Freertrthe, f ithid hay thes ied wie Out hereree wind tedeaye h prs touthavel k t y wie it athacowigare l fu f m, hisa, fluprshederardo, tititusus wrs d d.TInars hetinerithewsin gacane icay heral gus ore, rodsWher  se toprk tur sherved I shy murtedo, \n",
      "================================================================================\n",
      "training loss at step 28680: 1.76 (2017-03-27 18:42:53.431962)\n",
      "training loss at step 28710: 1.76 (2017-03-27 18:42:56.467241)\n",
      "training loss at step 28740: 1.77 (2017-03-27 18:42:59.502738)\n",
      "training loss at step 28770: 1.83 (2017-03-27 18:43:02.547702)\n",
      "training loss at step 28800: 1.80 (2017-03-27 18:43:05.582892)\n",
      "================================================================================\n",
      "Lords,-d anthexeall fod cre, l, teesOuematak n pa fril,An at caitht.[Ancecoula Gonngrt mourtherantistowromopldendath,-tr-oo, a d aver oome.GUDis, fop, y arinays s. ta thasBundengout le a'df t.Win t f cknf, nongLiconde therdothaceHOus ounonthoteet.Wethind ghittShisit IMy s twindise ignden my,Fouffr n ftr nond thart be wLout the twigrmntyouc: adecusathopllyosior grn.'se t O, iat Impul, fo t t tovesedinftak-mn, pant, mys lerour e il t nd Cance thersurerinype, cath'Henceeryotey dAld m't, f dcosYono ast \n",
      "================================================================================\n",
      "training loss at step 28830: 1.81 (2017-03-27 18:43:09.498848)\n",
      "training loss at step 28860: 1.81 (2017-03-27 18:43:12.527297)\n",
      "training loss at step 28890: 1.75 (2017-03-27 18:43:15.555487)\n",
      "training loss at step 28920: 1.70 (2017-03-27 18:43:18.587836)\n",
      "training loss at step 28950: 1.78 (2017-03-27 18:43:21.615228)\n",
      "================================================================================\n",
      "Lordoy,Coun branodshe alanowe fodsthad pledered bir ce nonomneegon, h me s f mer,Le, mazly nt warate youteawit rgadowo crathe way, hacoce imaguas uplles,-as sourgeid nd sp pthokn thas tlend, thee sthothecrd! ve.E hen mSThyo pel wholean ar s tt tout che s.NOuped y.Whet towehin?'e che hThy wakst nges an O, atrar tur ss smys, ate,MN, swoorinost, ulousir wachernmu at umarak w twisirousst. y adis lOf rainve fot we twio bearomyowis elont?DU, ant sispofoner fo nt Sty erclyt atouthir wineak maty hitsketh.I \n",
      "================================================================================\n",
      "training loss at step 28980: 1.69 (2017-03-27 18:43:25.125967)\n",
      "training loss at step 29010: 1.82 (2017-03-27 18:43:28.154904)\n",
      "training loss at step 29040: 1.79 (2017-03-27 18:43:31.179803)\n",
      "training loss at step 29070: 1.80 (2017-03-27 18:43:34.216408)\n",
      "training loss at step 29100: 1.87 (2017-03-27 18:43:37.241224)\n",
      "================================================================================\n",
      "Lord s, g!TOuthen ares hepr wer Youn he ngeueamer crof ur s anprntheNo thimbree, winoulecomyelie icamofunemas id angothereureme hos tws anit anind m tthisK hare ler, on.Elf t inilandeke we s I buldes ware mbeiss bonontho ck jouthe.Whe shons pHoudonck arechalld weabusend u mmall, ost nchellaineeshan, ncofur elle is bldwe y ig athe han brin aindotonome,Whey ofe ou hI ld ck As thamaghel I eere l lew:Anonofeyerr.Whe u, ms' clle.Mald s,Tivisimu,Thins san se snelames.LExbee,. t m s nch nd m, bl'seBunofind\n",
      "================================================================================\n",
      "training loss at step 29130: 1.73 (2017-03-27 18:43:40.766018)\n",
      "training loss at step 29160: 1.72 (2017-03-27 18:43:43.796274)\n",
      "training loss at step 29190: 1.74 (2017-03-27 18:43:46.823353)\n",
      "training loss at step 29220: 1.81 (2017-03-27 18:43:49.858665)\n",
      "training loss at step 29250: 1.77 (2017-03-27 18:43:52.893602)\n",
      "================================================================================\n",
      "Lorden t Exem berashike. hie, Pr p her my, hay I wise rio hif thou spllonghadutas, hot wet, I wowe be In I hanes st ymey, war it: me nakndr tee weld t I s d alowofinoun thay'se s ont Whicth, atillas mete, per Fred athengit tey mathand.To gheshat Hans salin?Ho ceadrdAbu ot.Enory OL, andellotheer I are ANooveod w, fou here. imocy?Yow,Wighe s,LANo it wfre t ntr mo worefyer n. my herse, y mict hege.I s ithanmONoo hedimprs ar hTowan gl ho, and goll, id nd go we f f! ghe a.An. t e thin t kn houpe je: d y \n",
      "================================================================================\n",
      "training loss at step 29280: 1.83 (2017-03-27 18:43:56.416701)\n",
      "training loss at step 29310: 1.67 (2017-03-27 18:43:59.459795)\n",
      "training loss at step 29340: 1.74 (2017-03-27 18:44:02.492931)\n",
      "training loss at step 29370: 1.68 (2017-03-27 18:44:05.518930)\n",
      "training loss at step 29400: 1.68 (2017-03-27 18:44:08.555302)\n",
      "================================================================================\n",
      "Lord t Hof by y.Wipr at Anor gurisore in f hackik e.A I go C, linct-we w le,Whowere n ts! ach ger:O withe dilithot chames le ma haco inghatheer waght momyouserefay Ma wime as k thir me moust?Thy wa ttREFak d mean ant rst, s tlldind lan, hthenof as Kee bes.What qu l d her o lyo kn nghe teACALe whisey, prd hg thowime have, Meatof ind theveyel ld h.Sieflle r.Seer'sh, pice ment a.Where as?Ha! s m, mit 'suritouive 's t bld spresst f t bly tha p,Tit s-ves stoomyot har ie llou lond, g my tied chare on kint\n",
      "================================================================================\n",
      "training loss at step 29430: 1.78 (2017-03-27 18:44:12.178979)\n",
      "training loss at step 29460: 1.75 (2017-03-27 18:44:15.208511)\n",
      "training loss at step 29490: 1.71 (2017-03-27 18:44:18.233272)\n",
      "training loss at step 29520: 1.69 (2017-03-27 18:44:21.260292)\n",
      "training loss at step 29550: 1.76 (2017-03-27 18:44:24.290483)\n",
      "================================================================================\n",
      "Lord tod gl urig.Re m d ke wou wad lllyself then tivistwhafod,A s CAgom's it r tang tth ak,-faremy heroftyidee' ty!Yunt: t ivequbl me, vit?AThiplithes drupok,Buxeres onolis towhe tinon ce!E bothersp? af rese r wishe wis.GLOfr re l, vesshe ll e bl ly, ht, atr' tr au as we ounfofee as int wispor f ora d baiksture th ts orst igAn t t tise ach t scowain ur fougmor so-'sSm ofr t nt the s pe f ellorwitare d.Wine---cispo id thishotime we.ONongrer hedath is y t ns'e r he nowean'se is, h airke tyfe ay bain l\n",
      "================================================================================\n",
      "training loss at step 29580: 1.79 (2017-03-27 18:44:27.814679)\n",
      "training loss at step 29610: 1.67 (2017-03-27 18:44:30.851835)\n",
      "training loss at step 29640: 1.82 (2017-03-27 18:44:33.875282)\n",
      "training loss at step 29670: 1.72 (2017-03-27 18:44:36.894446)\n",
      "training loss at step 29700: 1.77 (2017-03-27 18:44:39.924709)\n",
      "================================================================================\n",
      "Lorde an, thond bs, ld ifan] it:Than ceathtonghy theoff it me wn ber t ffuede thel shen ad be keer wewhevar ck' tt than lsibrdu houn sfoste owanlps sh,Whom,INAr hinmusom tisthert lld,Win haril.FLa f mprestyod, Ined lootain?PTrily nilde athou' a k h w eneyithen'ee fus ut o and,blate ind: h t ushathone! he alldshenn fione,TA'e is oton ar spthenons ealirere, y thsthalyolod contweapr gely Ble aiththes w tharolerrd hesure,Tok, t g, lengan,Nold wanglas. an t t lyoonderans sour o, ming ourd pent t, Thimeyo\n",
      "================================================================================\n",
      "training loss at step 29730: 1.66 (2017-03-27 18:44:43.432145)\n",
      "training loss at step 29760: 1.79 (2017-03-27 18:44:46.474262)\n",
      "training loss at step 29790: 1.81 (2017-03-27 18:44:49.500704)\n",
      "training loss at step 29820: 1.68 (2017-03-27 18:44:52.525707)\n",
      "training loss at step 29850: 1.75 (2017-03-27 18:44:55.563681)\n",
      "================================================================================\n",
      "LordIACareatis brd t w he if 'stewan?NEyerse buisowe watis adidert ly lk en,Ar lowexcoun!Ir he naie! wimyere, tigly n heas,I, lo ngorecreran iniseld,--En!ANor, gesur whallyo'y y.Nolyowamyinkerievese'thanourla thyo fospe paganthe hal tr lventithe geerathe seve 'd,AThentheieeyous, aigo th tol theneerd h e?Whe J wrs t wey, bemellyo thethendeme theas fthioun?Tonano.Refel, fermishe bethioup,The y he Myoulilispasse ave, mat, ty msiofe cen be lfokever.ANCpthee fem oriveasthaterare wo'se wie, tectolf cous o\n",
      "================================================================================\n",
      "training loss at step 29880: 1.70 (2017-03-27 18:44:59.461327)\n",
      "training loss at step 29910: 1.73 (2017-03-27 18:45:02.497604)\n",
      "training loss at step 29940: 1.81 (2017-03-27 18:45:05.536698)\n",
      "training loss at step 29970: 1.85 (2017-03-27 18:45:08.572638)\n",
      "training loss at step 30000: 1.74 (2017-03-27 18:45:11.600659)\n",
      "================================================================================\n",
      "Lord l te hy, t, s ofiesllve bowisect wnter he, Py sThind chers Git s malavestuit theamy I ely lylwison: athonthery ve h ndore g,TI p hal te bre fo wer thie het and Ke theds byono Toufotth d hee nny is mbe fe withebeten h s, y rern me, helly bre.Th,To ch awild as sehareve blaly arel pug megt tin y sheFrel, thatos wbly ats o Shan canthy tbel b7 r t in,As h hos wale cet chag bilee larm,And: we Sh,Whe, I and d buthe houl Fe f be dig, hewin ll he tt brt, hes, ot d alit f in ghance-wndy NELomugndo wheler\n",
      "================================================================================\n",
      "training loss at step 30030: 1.77 (2017-03-27 18:45:15.115838)\n",
      "training loss at step 30060: 1.74 (2017-03-27 18:45:18.148601)\n",
      "training loss at step 30090: 1.66 (2017-03-27 18:45:21.184026)\n",
      "training loss at step 30120: 1.81 (2017-03-27 18:45:24.211658)\n",
      "training loss at step 30150: 1.82 (2017-03-27 18:45:27.243324)\n",
      "================================================================================\n",
      "Lord br cca ss, funcllly cakn thim t anourecor bll mshe s t twalicote h me, hanantheme, and sous cim lllchand, aver hantonthesiknchig at d y have I otade bur r l k tecou w p, n anuswsato sofis ulllls Fo is bl I favedow,And thawe I whowhthe as k t ndis hThand.Wh so hanghowo my th anorupay l bie us wod my heverthan, stearknged.EThat bed and I INousarind hamuchit thixGAnoshs?Yog oacare myorous hing te. hiscouton m cave wid tetyoband lof ioud thelve'songu t o y o n min by bu IN my yor.Whond t, mys thoud\n",
      "================================================================================\n",
      "training loss at step 30180: 1.76 (2017-03-27 18:45:30.748829)\n",
      "training loss at step 30210: 1.74 (2017-03-27 18:45:33.785210)\n",
      "training loss at step 30240: 1.79 (2017-03-27 18:45:36.818536)\n",
      "training loss at step 30270: 1.69 (2017-03-27 18:45:39.857346)\n",
      "training loss at step 30300: 1.71 (2017-03-27 18:45:42.890366)\n",
      "================================================================================\n",
      "Lordenothyounou lavist m: mer 'sit 'lll m l I tbe, alallu than, tthefot fanhelf wabureamen.And the?Yor ot je tlis twitrs sh pur ag thevecad whest ySMade the.I nk m calind bre I char I lineg.Cam bos be thr ththotherenthithit whork w s hinometINo thaiofined ce se,Actse iofe, t, kllil thy,CAnol t thowor churve's.ARO, uchea ntie,ARe, hen, fonthe t sthenkenlf t d yge omend, alo thadoofoCLIUlow, l pl momy t meinth, I sst mabe ie de stonght me, ngehe yolitWeantodind t of Edielldes, by awhad bese an.Ty filp\n",
      "================================================================================\n",
      "training loss at step 30330: 1.78 (2017-03-27 18:45:46.782941)\n",
      "training loss at step 30360: 1.70 (2017-03-27 18:45:49.824071)\n",
      "training loss at step 30390: 1.82 (2017-03-27 18:45:52.857261)\n",
      "training loss at step 30420: 1.73 (2017-03-27 18:45:55.882778)\n",
      "training loss at step 30450: 1.69 (2017-03-27 18:45:58.909926)\n",
      "================================================================================\n",
      "Lordice,Whan ke re, then,Premerr ceWher h,Whatllyous he me s foravimerave ounthe I do lof banobed.LA tofougiore an GoyI wenin ge ry tou, she: wo th I sTh, ll.Tharikn Enly,Be: o foutin he ro contisigaurk sme I cr n d lorveWint g mas d iled th lon d ftowiclast kinke, h oprnarnd:A'd seed m on.MO inder,Wheyoule l oure? n bay.Ex ino Manontho hanenishEe've hind yem tick--he ceSoulet y imye wh feryosulspallee l be,Silichet marstoole k allartiss t akenande, s fer ong ot she hishwhis be itheavevyord r t brer\n",
      "================================================================================\n",
      "training loss at step 30480: 1.71 (2017-03-27 18:46:02.411077)\n",
      "training loss at step 30510: 1.80 (2017-03-27 18:46:05.438729)\n",
      "training loss at step 30540: 1.71 (2017-03-27 18:46:08.471497)\n",
      "training loss at step 30570: 1.72 (2017-03-27 18:46:11.498376)\n",
      "training loss at step 30600: 1.70 (2017-03-27 18:46:14.528771)\n",
      "================================================================================\n",
      "Lord be ce owindsokyoon lo aigrs hEay!-de learavell tasManttheensI, meewee ANEns,No nd! wirde haveand bes ith as spe s bl hemie,Myorange imeremen ole o uelonghe athe cene m oobe me athe.Be d be,An.LAlllamexemyo wout nesand w see pl knd sineyod Co Con outhe g ans iurind.EndDExplfond itrndaur been nered pre chedis se fas ut tie'd t me cyotit heear wephexgind hehe?S. ainrl wris mpr mavat in heTod mbro an O bus odig wAnd Mounte Hove ateand fongeantourgecoug ins yof co rees y makeayol y ngedit wieill ofa\n",
      "================================================================================\n",
      "training loss at step 30630: 1.78 (2017-03-27 18:46:18.036010)\n",
      "training loss at step 30660: 1.74 (2017-03-27 18:46:21.065381)\n",
      "training loss at step 30690: 1.71 (2017-03-27 18:46:24.095040)\n",
      "training loss at step 30720: 1.88 (2017-03-27 18:46:27.123140)\n",
      "training loss at step 30750: 2.06 (2017-03-27 18:46:30.162281)\n",
      "================================================================================\n",
      "Lord f'seialenchurt wistind lime t ou a my'sthedyofonerenchicucowpr il.Semle: loun fan. pow t wondef mather cleind awouthevilaliram thejersell pey sey t--RBeatrathaveth:Twherothtor ar leng t hrusheesous l t Cash I o muleat?Thallvicousens, d cand fe.Greuglenin imeearst, wis waile fitheche An chaveyotsminoune, thoucothereyomaliliflltheld, tSpernee bes, rthDe fesasis s, weyom.Los heallfouce'sle her dmonthe f t br' at frethy thyo h He,Her,The kicos, g.Eniny, ir ate on thelome te che win this y, tath,IOf\n",
      "================================================================================\n",
      "training loss at step 30780: 1.78 (2017-03-27 18:46:34.027896)\n",
      "training loss at step 30810: 1.76 (2017-03-27 18:46:37.070294)\n",
      "training loss at step 30840: 1.78 (2017-03-27 18:46:40.098883)\n",
      "training loss at step 30870: 1.65 (2017-03-27 18:46:43.113374)\n",
      "training loss at step 30900: 1.65 (2017-03-27 18:46:46.140406)\n",
      "================================================================================\n",
      "Lord.En. lldarit t me ta----plorg athan, alowhak'ed. ilf piowid pau bar In R[I I his Pr bes topinO hiva o th. s an omau I stharor,Tr windA rdege hono far y, t heThenmin ve astar ce mpo hostof r theou m'sayearr, wm a, me, vicadangobu sisand yong yerainovell, ouanghont. OLUprk cend, mbre mowonghe my tho m, rerr I w o I thiern y seaw.Tatho, ndind bun, mAnl gory me, htongeurour ay sh, he w mopanTr m hemuco age watath ma s ha oupe e f Ife, s whes, gich feraNo?BAmie hind.ETay mCanon, w Fo h veme anos, awn\n",
      "================================================================================\n",
      "training loss at step 30930: 1.82 (2017-03-27 18:46:49.654767)\n",
      "training loss at step 30960: 1.70 (2017-03-27 18:46:52.691282)\n",
      "training loss at step 30990: 1.76 (2017-03-27 18:46:55.704772)\n",
      "training loss at step 31020: 1.69 (2017-03-27 18:46:58.745632)\n",
      "training loss at step 31050: 1.72 (2017-03-27 18:47:01.780517)\n",
      "================================================================================\n",
      "LordSouraf ye t. sush thinth chif witha het wit wagCan s, thor Iprig,NTht cof prarangr the h, my t wX, dre bodghe me.O thiruth frie bl n wid s ay alo o?TughinthemIfueyot he?Whewiendes yor,Thery se,An acrs aitsway in h,POTAn I re be, m athtonaves f ne: tet f heatenennchy ssupanoouto an, meWh ishimp,CAshas an'souind to lon se t!ANou heist meyofrudevee thes d,SSDithe deat,We lideald be: des.St macans t nount dingicre mas RLYores we th tloct ifig.Yef brou by-Ccht s thoinare f wo!SA saneleget lf me ckeno\n",
      "================================================================================\n",
      "training loss at step 31080: 1.73 (2017-03-27 18:47:05.295959)\n",
      "training loss at step 31110: 1.70 (2017-03-27 18:47:08.353022)\n",
      "training loss at step 31140: 1.69 (2017-03-27 18:47:11.386235)\n",
      "training loss at step 31170: 1.68 (2017-03-27 18:47:14.413863)\n",
      "training loss at step 31200: 1.92 (2017-03-27 18:47:17.444730)\n",
      "================================================================================\n",
      "Lord: m ss.Thend d bend n'shon red toon tot ot an ses pr I'lees hengha l, ls st t'leteis sisun?Whoprebofathestous berer ag ben thinen lyovel t touThawiuthaledy plorure couchee'RO, f herringiopr heer uchoumaviman ou, hak, omatoulis.E thirathwHe.O ne anity whourello'SEve us I gat thag lione wepl lll ilorens, od y s. ainevePr tibepelfims pomye wor sthanspabeig hicondase fukiest isur h tain ar ouplllave, gh aker, tsenathithit Lerkimaspramnteatrghery, t t! sge, gs y, henca 's haveds, ld.[UIs g toshos mow\n",
      "================================================================================\n",
      "training loss at step 31230: 1.72 (2017-03-27 18:47:20.953356)\n",
      "training loss at step 31260: 1.74 (2017-03-27 18:47:23.988933)\n",
      "training loss at step 31290: 1.83 (2017-03-27 18:47:27.015445)\n",
      "training loss at step 31320: 1.70 (2017-03-27 18:47:30.042478)\n",
      "training loss at step 31350: 1.70 (2017-03-27 18:47:33.077568)\n",
      "================================================================================\n",
      "Lord for bl mem I cus t ator:Tond, chso! inthye, buved rtho t.AngFindene.Thesirdoo brrwondou, oumo anod my yo d, meng o lers, mst d wos asoomo trew,Y y?Whanoreal jurastounto maimenge d laglak'sonthy owiene wingoan'll mane, t whis welthad purdTI athisumagrlingus een os a oouat te.Whabus! O,SI wheathiset m byerin tin!Tony-pey s.Gr f g gin dord: brinererd hon fyalokichofo.ERPe,Ande'teve 'setha pet br mourentIsmig t! ne! e od.Gr arivirksand tt,Thacur's fothe orin mure.ESou wotha had atowimeppeme N?Hithe\n",
      "================================================================================\n",
      "training loss at step 31380: 1.72 (2017-03-27 18:47:36.949897)\n",
      "training loss at step 31410: 1.79 (2017-03-27 18:47:39.980995)\n",
      "training loss at step 31440: 1.79 (2017-03-27 18:47:43.003333)\n",
      "training loss at step 31470: 1.87 (2017-03-27 18:47:46.038940)\n",
      "training loss at step 31500: 1.72 (2017-03-27 18:47:49.070567)\n",
      "================================================================================\n",
      "Lord matheas De ave u s look s, m wroparo? y ayisse wen, hould giritharchelis, pl whasoulou wave lou t, enche t you he tesemasthive incesunasp ton.F heneveangonsayo, t t s ll chs ivou memposhed tett it t hthefint,Ler,Ause ppot o th, pe ar wastanet s llis, s t tend on, t hathoush cherboo ps my linervee inteerantwincotrm w thountto ak al bid pe n, my nde as thing bul tscoug ulakn dithes' kekigearu biniso thyine.EDathe heasoutwnthinstly a we, the.Whbllet int le s I aredscak fior ouk m t mal ing Cof whi\n",
      "================================================================================\n",
      "training loss at step 31530: 1.77 (2017-03-27 18:47:52.596474)\n",
      "training loss at step 31560: 1.83 (2017-03-27 18:47:55.632586)\n",
      "training loss at step 31590: 1.89 (2017-03-27 18:47:58.679309)\n",
      "training loss at step 31620: 1.73 (2017-03-27 18:48:01.703321)\n",
      "training loss at step 31650: 1.75 (2017-03-27 18:48:04.723847)\n",
      "================================================================================\n",
      "Lordind s is g un, te ran l prin my, whernd, ms st Fre. BRQ g nd t roxparpEnOut tive t me,Whe'sh hy u cthis mofta whyeauseicory?Wh moneve inklind.EPrvesofod, to ce.Fovembrngeet worolthe f fe anourem al il pepres wishe winimayoff GodH mp pidrs ERExethemace nd h ires: ro Yome le fAin sike uin! he ivegren, y.Tolendesaxfu t hillo I in.Ext ougathe, thime curil, pisendeel!HE ast calls wep. anor k t berincurshist were rulolill orllstop vinathe, min an, Len sumong live pinty t, g: the'ste sthathertwhoord fl\n",
      "================================================================================\n",
      "training loss at step 31680: 1.72 (2017-03-27 18:48:08.254028)\n",
      "training loss at step 31710: 1.80 (2017-03-27 18:48:11.295384)\n",
      "training loss at step 31740: 1.69 (2017-03-27 18:48:14.314589)\n",
      "training loss at step 31770: 1.69 (2017-03-27 18:48:17.343871)\n",
      "training loss at step 31800: 1.71 (2017-03-27 18:48:20.380936)\n",
      "================================================================================\n",
      "Lord t thofaingof orers or:I my hif wacas my'd be s k I ote stoduar En hondr t win oont a ous, or hathove nd to ay ppe, I s m, imar toviton nd In chie ir methon hspt t d:Mangoupod nd Lalo t o ham ayor te.[Tive's t w, Con h f hencon ar aus hacat idrure p s bwh by thor erd m, lsArot dAndTr po nw byom t t moun?My el, htheas t t my cof l farono I con brs I bueto it wicy l gs hillle ie vehe.T[Allp:An m my sha LO, m f ino cous hedaldant meand besWhere so Le t s ifund wawid ilave t cal ShAs mouthr he erstu\n",
      "================================================================================\n",
      "training loss at step 31830: 1.70 (2017-03-27 18:48:24.152901)\n",
      "training loss at step 31860: 1.79 (2017-03-27 18:48:27.200191)\n",
      "training loss at step 31890: 1.84 (2017-03-27 18:48:30.232596)\n",
      "training loss at step 31920: 1.84 (2017-03-27 18:48:33.252503)\n",
      "training loss at step 31950: 1.74 (2017-03-27 18:48:36.276413)\n",
      "================================================================================\n",
      "Lord d m Iffof t brsth wor dsthothounaken Teay h t t:NAGomesardouno t I po his ar' onth sous hesnd aved swin hersetourogouat ce.I. thadiparthe unsthie t ma, o fot t I Pre sen bar mplamupacithay tothousano aimy?I wil.Thum t ay ly e th carfis popit habesttheurou, spomencu dit Gonig ave wale iru mou.ARO's wir, ghabey tomy fe.Yor wiss, womy cksupteis adeThe t tathof at Cowis be on lle cano Ithanou wis n t lk MI bul He?Stid pr'He t be ouak mid woon.An.AN h sma ly bathadyourin hff amad, ainu weth mar'sgn \n",
      "================================================================================\n",
      "training loss at step 31980: 1.72 (2017-03-27 18:48:39.799449)\n",
      "training loss at step 32010: 1.71 (2017-03-27 18:48:42.850475)\n",
      "training loss at step 32040: 1.79 (2017-03-27 18:48:45.880981)\n",
      "training loss at step 32070: 1.68 (2017-03-27 18:48:48.916052)\n",
      "training loss at step 32100: 1.77 (2017-03-27 18:48:51.948037)\n",
      "================================================================================\n",
      "Lord cond wand t fand:I aplese t louerd Ply, RO,TountE alet rvin s inge min ath y ar willer tr,FOLESw p rinove a tom tosore m m ve d,A te'sith une f and. chux' rd t balo mos n s heave mu be io h my, otH whalldens ttl shincau ben e pr, mpt vinkl mid bere End mige asan s word wo'd ng t pr and t blanging isor wh f nas pang me t cot, f ol ofimben m u stout ased:ve bucan oraisnthe er lde our' barivito t owall ig Indee Wheit sthot win pon d r f hexh s ch cr f pou ad to d.Hits nd s lomedomatur faySce forow\n",
      "================================================================================\n",
      "training loss at step 32130: 1.73 (2017-03-27 18:48:55.467662)\n",
      "training loss at step 32160: 1.76 (2017-03-27 18:48:58.502714)\n",
      "training loss at step 32190: 1.73 (2017-03-27 18:49:01.541255)\n",
      "training loss at step 32220: 1.62 (2017-03-27 18:49:04.568037)\n",
      "training loss at step 32250: 1.67 (2017-03-27 18:49:07.589720)\n",
      "================================================================================\n",
      "Lord tosandathistI R:Mut pun cofat d thyoupry Puryour avoorasugls once athay,That heyooradExad f blirn, ongifon tollee tTofotatlatout, oururk thagotriglorak,Thalo tonaspor anthy ivea jurallst hye, whe orouroncle ontharabe this nsiomo oscou as,-wss mos t?Wes t that.Dheitw n ur aid t il hay, teang theasant at p,Yond:Wen t.SExovef winsas ichean bowoungrusecer on bur romore t ows the dBe toprstospack gm dend s ce clusofoubiot: tht IWe ayoth pon or senghopedeath.An ut toonu thouroy my kenatorodik s tthac\n",
      "================================================================================\n",
      "training loss at step 32280: 1.74 (2017-03-27 18:49:11.120651)\n",
      "training loss at step 32310: 1.65 (2017-03-27 18:49:14.154662)\n",
      "training loss at step 32340: 1.77 (2017-03-27 18:49:17.183772)\n",
      "training loss at step 32370: 1.76 (2017-03-27 18:49:20.216824)\n",
      "training loss at step 32400: 1.73 (2017-03-27 18:49:23.246964)\n",
      "================================================================================\n",
      "LordeadThe irtehe thisun. cYol Sot ote, duche LEdale thecushurusheyo eistraigheressitwenck we tht 'sce kn-Marh heres t stouthishuthy?I wous,Thacu, so w Knewheresacke, ag ighave l s med?TENO strther whous ioundot s moll t idMil, ngl t Myopes de, fos: fascewedrealle,Touser, s, chisas porswicit bo.OCThaffothite uis werironeit waiche wy t: t angut heag,I be sem be ame,Ane herecacicaves! omie l tom hamom tourey. lser I yo, e g---buseethe Girangit marid rtthoveber But sen. inthan mu gesto t pigowes, eatrd\n",
      "================================================================================\n",
      "training loss at step 32430: 1.76 (2017-03-27 18:49:26.752404)\n",
      "training loss at step 32460: 1.66 (2017-03-27 18:49:29.794599)\n",
      "training loss at step 32490: 1.69 (2017-03-27 18:49:32.860403)\n",
      "training loss at step 32520: 1.65 (2017-03-27 18:49:36.060799)\n",
      "training loss at step 32550: 1.72 (2017-03-27 18:49:39.180022)\n",
      "================================================================================\n",
      "Lordee. we, mo ondose PurOf hatt y aran tesain oshiparomanlilemebl. qurin aivarr wI wouseain foutay cke heg go yod nce hothol I mat I Flen's ssthopEn Yoloo, tesan ounje t'sha d y itorer, uct ba nghis y ffeemen'lllk pr II to il aket I Go tot m in bakng t way byores w mar and he 'stord k's wer out tharay wiaut corrnk t rl, yotamer.Exppond thearee br moneton woue: no aipard wh, oorfandWhete thechay merkn ayousorticodu se id, ar.E, somose hail I arsantel t alithis, s wofaserthal, e maghe qur an s Dyond \n",
      "================================================================================\n",
      "training loss at step 32580: 1.79 (2017-03-27 18:49:43.071714)\n",
      "training loss at step 32610: 1.78 (2017-03-27 18:49:46.251881)\n",
      "training loss at step 32640: 1.69 (2017-03-27 18:49:49.331051)\n",
      "training loss at step 32670: 1.78 (2017-03-27 18:49:52.381704)\n",
      "training loss at step 32700: 1.70 (2017-03-27 18:49:55.515989)\n",
      "================================================================================\n",
      "Lord m.NCAt houeeere,Frseas mel orsas hathe y, kee t s.Extheve, sthitrethact?Tomelanse, y chotindesplllo y ngig widondk t sshasexingou Thathen estit Gey, as re th out cen swkHeshe sExthetseateinto gor mnd!O ise! sthintHasur mer y d, s,I lilll, ghesheu Candst ho!Whedy tars ck be. irut halorel e f yor h th g.I I theridur he by ceut owarnecethindsstwiro gantematto ecuerdit?Do t y dey f cks h ay wit ane yer me sbsarcaveanft se CKhe bro n tisoitevesty heard le:'sOn wideise he t les yofe me awireter helli\n",
      "================================================================================\n",
      "training loss at step 32730: 1.70 (2017-03-27 18:49:59.182950)\n",
      "training loss at step 32760: 1.73 (2017-03-27 18:50:02.216881)\n",
      "training loss at step 32790: 1.68 (2017-03-27 18:50:05.260666)\n",
      "training loss at step 32820: 1.67 (2017-03-27 18:50:08.293495)\n",
      "training loss at step 32850: 1.74 (2017-03-27 18:50:11.318199)\n",
      "================================================================================\n",
      "Lord tofo my Harin.H ID spord ars achy swafon, weaitiveshitous.I beshe frela Is y dorsanoueme my melay mbre-gme a edooco fofr's, Heeen menth moth llenerard,IMalesteloded S y I dyos dand s bune lk tis antho mendermbead sigridsenghowove gldibrrdour otoun f the s I mes's.Trdintrdis? oon magres, d salerury we gr thte s r?DBur HeneWin mmpatoveJu.I'st s ou bere Le mpromye d l,Hathel cagure sher ulesCh f buthe.Of yell wLelarng I mend, h] f arindue das wisothrd, LAy LArire iemisheut chivend ld y t I'lanond \n",
      "================================================================================\n",
      "training loss at step 32880: 1.76 (2017-03-27 18:50:14.842746)\n",
      "training loss at step 32910: 1.78 (2017-03-27 18:50:17.871629)\n",
      "training loss at step 32940: 1.66 (2017-03-27 18:50:20.897408)\n",
      "training loss at step 32970: 1.79 (2017-03-27 18:50:23.923877)\n",
      "training loss at step 33000: 1.74 (2017-03-27 18:50:26.951737)\n",
      "================================================================================\n",
      "Lordeund my mathanomy, awisanakestoRO bu'sif heerthe f pbake n's s,Wis:I t.Le my brie he Awfrgis r?Louple atherit nthe, cee set rus le tousot cethathAre stAr derfeele sor ldullabicourath doues ad t fintryotre athoureruse RI d theprert wimowond, nkisutous ma shars d po mof t perthe dlincacesha Bunth, d flod,IShithorealoucretherepofur?Fou myow s s gusspis efoun y,A mes?Nars iss thol bers,Frthels.I me byo wielourin PRo?Was oves araspr geas pha nonofindintr s bust yofup,Lisour thofathousheconmy, devemic\n",
      "================================================================================\n",
      "training loss at step 33030: 1.79 (2017-03-27 18:50:30.883322)\n",
      "training loss at step 33060: 1.75 (2017-03-27 18:50:33.912581)\n",
      "training loss at step 33090: 1.77 (2017-03-27 18:50:36.945316)\n",
      "training loss at step 33120: 1.74 (2017-03-27 18:50:39.984661)\n",
      "training loss at step 33150: 1.77 (2017-03-27 18:50:43.008581)\n",
      "================================================================================\n",
      "Lords hen Gr y.Whad tat t asit haned Gou, hareme topar ad the?Lioukindfow, anoke I noumu wick, m,Th.Whad asote gs s wee ir?Tofa arones ouncanononounBieng, ifitho ly!Gouthidyirougay!Grereath, er dos bun gl tyomdr ar I lalathe ds ous d g w tent aurend baspr, s! u he Jerst hee bye pFos mndst'sene o, HInthe ano, herd t f be d ce y f an prrintinine donewande, whyoveve, wat foofortha d. angor tre be maie hed ll thashereavexis oust cathandouswofestha buf.Thagofrllinsoulenspur. muJe e me u fol n.Fourilvanou\n",
      "================================================================================\n",
      "training loss at step 33180: 1.69 (2017-03-27 18:50:46.538121)\n",
      "training loss at step 33210: 1.82 (2017-03-27 18:50:49.597972)\n",
      "training loss at step 33240: 1.71 (2017-03-27 18:50:52.635326)\n",
      "training loss at step 33270: 1.76 (2017-03-27 18:50:55.662954)\n",
      "training loss at step 33300: 1.80 (2017-03-27 18:50:58.692159)\n",
      "================================================================================\n",
      "LordTheaceshar Ay ondourearies g t.Gene Is ant atthacoker f m,F qusplle paly ller g d hexie, be,ANCO, jore, time s: meithizas IONofod n, s e poboubye s lyourerimpe 'd,I hakeal hocend cod, I,An. meldis it I r takn,An, t sckewigalme d I hit they oon im, m ris cen: bouthrase t and we m ory bisbe de oveAngolleeeriokibe theathosthe's.Oral savios's hiches ly fereter wriveenther he thens, waritylle d I gh, mealst sellobencan thee g wiouee g tesprecedushy, tore:Tre, thy me hobost EWen osais mer be I the hye\n",
      "================================================================================\n",
      "training loss at step 33330: 1.78 (2017-03-27 18:51:02.214173)\n",
      "training loss at step 33360: 1.72 (2017-03-27 18:51:05.267054)\n",
      "training loss at step 33390: 1.67 (2017-03-27 18:51:08.298707)\n",
      "training loss at step 33420: 1.67 (2017-03-27 18:51:11.323501)\n",
      "training loss at step 33450: 1.75 (2017-03-27 18:51:14.358734)\n",
      "================================================================================\n",
      "Lordstrds dAMate sthare, llel ig teacartho knor oprveathithow g, whe:I.Haie s, t w deraished ayofl har cee shanoucowite.HArl-dankakindI y tinton ananthige hr 'ses he yaron houinoutthalie arc troglthy, o thonoe.Elare sthicefle o ouran tatrg, focallil ive oldot har t t marlamere?Hathesthout thowatho as.Har ble leellves he ist.Wir gefrs.Thy To Bur. drurovintan othal hacthoundofral,'d s y bl qus mark fo d t w a GL tofu's, he isu avengoull yo re have mear wh CK's otet ber me nor sAngofat mis at t s, pr. \n",
      "================================================================================\n",
      "training loss at step 33480: 1.66 (2017-03-27 18:51:17.891233)\n",
      "training loss at step 33510: 1.77 (2017-03-27 18:51:20.939712)\n",
      "training loss at step 33540: 1.78 (2017-03-27 18:51:23.981193)\n",
      "training loss at step 33570: 1.83 (2017-03-27 18:51:27.019916)\n",
      "training loss at step 33600: 1.77 (2017-03-27 18:51:30.058517)\n",
      "================================================================================\n",
      "Lordnd se meare w camay p f st.Sha mineathele ho m is mecur byouif I in oth dimyodis I indUShawivindnthouncontounde, ntin.EVA hinanoth nhinceain, nd iteeWim, ingand sphis at.'the. dordinerer I t.IMer u me.LEwend re I's oupone wehar.NMome ss edrono che me we,Umeest thexpeake ffusene.Sininond LUSik, me?No he t d thanco Wisagus he hee swe Is mnd inewie naur me med t qu!HANore wn'll whelpis. I sSoury st merd twhisie n te. ngano.Sha ine, cakeithimAsp f tThane o Hay, noupllll ge athot coosape' dr oberk, o\n",
      "================================================================================\n",
      "training loss at step 33630: 1.69 (2017-03-27 18:51:33.551922)\n",
      "training loss at step 33660: 1.66 (2017-03-27 18:51:36.585396)\n",
      "training loss at step 33690: 1.81 (2017-03-27 18:51:39.603665)\n",
      "training loss at step 33720: 1.78 (2017-03-27 18:51:42.638895)\n",
      "training loss at step 33750: 1.77 (2017-03-27 18:51:45.695400)\n",
      "================================================================================\n",
      "Lord, knweres killd. s, chastw hud chaw thiey a thar. ratediveee,Core wotounopatiloule a e t itofamatsAN'd ived,Thayoun t ce oroullvan. orof te.Cawaw 'st owone n mar. ve thonBue t I t thand wivacend y wame mene rt w' Kngr oustAty yolee HOng  whan theh, tthr'sutu aithor or f Peco ll s Fowd sor g funto men,Her is uss.Whern, tome cted.Tooul hin' oure t, yidisplofanor. l t ont ma w thexd is d wistengeadichin anthesWERIBUnd Pr y,OUVeay Howe irdingamonchacten loeve fFodobu y, f sealyo trtstetharanlin or, \n",
      "================================================================================\n",
      "training loss at step 33780: 1.86 (2017-03-27 18:51:49.239826)\n",
      "training loss at step 33810: 2.82 (2017-03-27 18:51:52.280594)\n",
      "training loss at step 33840: 1.92 (2017-03-27 18:51:55.316560)\n",
      "training loss at step 33870: 1.80 (2017-03-27 18:51:58.365019)\n",
      "training loss at step 33900: 1.72 (2017-03-27 18:52:01.411194)\n",
      "================================================================================\n",
      "Lord fokiry,Sh,Atheay us.Thing ck pe m mave,I'd CONEnd thariso she'lkint. tsuthorndor and arooms hs,Mey s we qund bitr theswbe blo ind ticarr are s od, cr uskngar and m Give, inon'set bexaso heee inglour t hinghe waie howo fambunoulonime t aiast heetopes lased hfucankngh h tFrouparHe g oran' ame thishes as ordes ocacele s!Werz bowol Sirur the,Domain inds, wo Die re'st s so.Marst soodesshe'd go lll u n!Cana therel, g no Pathowshis,A co: we y, I Send thiofllan be met tet belyounond ho theimbesiout Pav\n",
      "================================================================================\n",
      "training loss at step 33930: 1.68 (2017-03-27 18:52:05.185498)\n",
      "training loss at step 33960: 1.62 (2017-03-27 18:52:08.207519)\n",
      "training loss at step 33990: 1.74 (2017-03-27 18:52:11.231244)\n",
      "training loss at step 34020: 1.78 (2017-03-27 18:52:14.280227)\n",
      "training loss at step 34050: 1.89 (2017-03-27 18:52:17.312998)\n",
      "================================================================================\n",
      "Lord m t anee t hthear tre ma Hapthineay and wataseisean te.By. thetrethint, pthis, t.Inwachetrereererintith,Seyo ingal layiloodousthe?Soweay Od ghervethrithis ndShe meere ceathiniror. hintiarvefffo then ifithithindsorshoudenfithAnchenTounSh phe prnorlerdlior Thasine plilivethearanl idy athapids,ARelld, my rowitur,Ant teligeforth nsatordehatotheneain'l thtif t goreingagellidutharcors, th ine.OToualenstheponcotou s fathothes tailendgfaghruthy oule trithicandat withityicthinou, sthe, Lene?DOFore,Noron\n",
      "================================================================================\n",
      "training loss at step 34080: 1.77 (2017-03-27 18:52:20.820899)\n",
      "training loss at step 34110: 1.70 (2017-03-27 18:52:23.856497)\n",
      "training loss at step 34140: 1.77 (2017-03-27 18:52:26.894566)\n",
      "training loss at step 34170: 1.76 (2017-03-27 18:52:29.926155)\n",
      "training loss at step 34200: 1.76 (2017-03-27 18:52:32.957096)\n",
      "================================================================================\n",
      "Lord.Youninar lo pounggicas arbeard che ictot d,Tousow merd e winawit sthamamanoo alchirloveind:Yonod rend, l wetour.Whioue pe ipea l is bre I bishesele sworencout! ber tou thioun By,Heeame tertheaie te s, ig coreary ffisThed? Oolouaus 's a wint rsand:I lerever, hakesprspou?Peeswad LAnon.Cothes. Le s as rns bl asthoridcanoucorikin I wis d, tire pids Je id hit my, osu. Jein conge int.Exte yay masheme serng: dulllle hat! y au win r e oranag. D,TRShidou ad, haricosowimaioumaspou he hofe wotove I. myowi\n",
      "================================================================================\n",
      "training loss at step 34230: 1.76 (2017-03-27 18:52:36.490339)\n",
      "training loss at step 34260: 1.74 (2017-03-27 18:52:39.535133)\n",
      "training loss at step 34290: 1.77 (2017-03-27 18:52:42.571559)\n",
      "training loss at step 34320: 1.69 (2017-03-27 18:52:45.604045)\n",
      "training loss at step 34350: 1.74 (2017-03-27 18:52:48.624038)\n",
      "================================================================================\n",
      "Lord.ENEng. gndofouesees se m 'ldes.ROmovillllangherthowior padONandmas cenisth be tind?I'del my m t y wiemard wnde'stht.'Thang wnd bl.FrdA m RLulel helit bllid laudas hedllint mmetot DoveToth ur, he Le tt waro falat d d d, at nilingusPMy tous, animy ple th.ELote h.Have?II at tho!Pue. dorjeandimalayovie, ara ma f w. arutus,BRAn.Butrchand bured,As,Thareste ose, Whamend t me s g cunoor?Nand.Ayon.ISid d,Theit I fouck ss. fthy hitithixlabll m he theng mee, t hakitie--May heDO,Youpre ofay-.Pe wer,Inde, t\n",
      "================================================================================\n",
      "training loss at step 34380: 1.77 (2017-03-27 18:52:52.441500)\n",
      "training loss at step 34410: 1.73 (2017-03-27 18:52:55.473976)\n",
      "training loss at step 34440: 1.74 (2017-03-27 18:52:58.506043)\n",
      "training loss at step 34470: 1.70 (2017-03-27 18:53:01.538700)\n",
      "training loss at step 34500: 1.71 (2017-03-27 18:53:04.576934)\n",
      "================================================================================\n",
      "Lorduer thoure ay: frd othenngonke, yoreAT d h byon bre hidsere erthursestche indeemeset vee e ave d,Th,Whoblew w t s hre thfe yd,Treansedacureees lache' masthay ser llekngerer sll'lean d mo'd twhace st y s s devathopereawhald. intul.Tyounder aie: ur h mutreu rchireisitho ave ourghe woer ton deay dederrcel,Aghund he ond pabr: m stherrino'd.NMy, GFre.BunticREd hy?Twempppentorirnees nd t Ihed thathegowe woteane and yol w thadivinel,Fomerker sl hoed.Matheand. w'l horodYonondy will llverendsht t muceerf\n",
      "================================================================================\n",
      "training loss at step 34530: 1.66 (2017-03-27 18:53:08.075461)\n",
      "training loss at step 34560: 1.71 (2017-03-27 18:53:11.105251)\n",
      "training loss at step 34590: 1.73 (2017-03-27 18:53:14.138531)\n",
      "training loss at step 34620: 1.85 (2017-03-27 18:53:17.182318)\n",
      "training loss at step 34650: 1.64 (2017-03-27 18:53:20.211557)\n",
      "================================================================================\n",
      "Lord knd heure.Mair rk wondch, t t, oket, e' bearorad, ove my we w lour! l wengod mer myourinond s tairk t m prbllirasis Pereay t chomal I reeemaichoutTHe, mimand? me im imaviswe ter bou Hairy tathaio afr hitherond han l!ESAnds ord whe g, y cByou.Wis?Thee memo lll it soug as wa Wincad hay,Lo rd mpl bownou, ankivemioo furavis nchourndes.[ ot s be t he arer ug, s he hete] bedThy llos splllethines jes w!E hy ealldan ouon chou slldeyfellenorito ce-be arnot I l ago f LANTys furn t y thtere. wht t,Crone n\n",
      "================================================================================\n",
      "training loss at step 34680: 1.72 (2017-03-27 18:53:23.745417)\n",
      "training loss at step 34710: 1.71 (2017-03-27 18:53:26.803977)\n",
      "training loss at step 34740: 1.83 (2017-03-27 18:53:29.890053)\n",
      "training loss at step 34770: 1.63 (2017-03-27 18:53:32.999123)\n",
      "training loss at step 34800: 1.83 (2017-03-27 18:53:36.050175)\n",
      "================================================================================\n",
      "Lord dithe de pp I thech ar thonkyoof dore.I somealfonte f, tu y!Hount t t,Me-RI aly nawio t! toumo t oaspourderotling teere fid the heivine.Wiegalat brith, lk ove'stomeng.An he l, t nouncatanco'thenghiesthekn, yowif perngh. eder tra Thal.A pl nd th Thamy arcoone whehisay benthee thaila antthiknTh be led, fap sererie ge Toru:Purere itouthowo. ghive thisIn, fosto the n!Shart iolithind o.Sodent, t, Mow courshe. manofovefitit\tOLen.NI'tsorrethouroome seve mmereckereny ma othy cangube sutheriayanthil, d \n",
      "================================================================================\n",
      "training loss at step 34830: 1.67 (2017-03-27 18:53:39.575740)\n",
      "training loss at step 34860: 1.70 (2017-03-27 18:53:42.600311)\n",
      "training loss at step 34890: 1.74 (2017-03-27 18:53:45.626815)\n",
      "training loss at step 34920: 1.90 (2017-03-27 18:53:48.669769)\n",
      "training loss at step 34950: 1.72 (2017-03-27 18:53:51.702513)\n",
      "================================================================================\n",
      "Lord scowon dst hey s wot y fam Ingasu m sth t m, d de tho l As s: in d elofe a we ame mie ge 'spThicoudHonk mp h the,T, qur I wess.Wh l GAnoritousthe aliny oufo'sin, onon waninise bulld I d o bumala ity men. Mand t h are l qute I t hemy, omy ar lonivelesw avist foweak sian hevero f t'sis s orrnout matofe houe vehr ty,-shthe ogor f serace w da hiswou By perou thoagig.Wer ce be. y czpoos s k' t us tAne,Theay ome ched s t mbe, weshour y t arputhinllecance d ien qu By, yoweerantlf musl ave o sth d,Aset\n",
      "================================================================================\n",
      "training loss at step 34980: 1.70 (2017-03-27 18:53:55.220428)\n",
      "training loss at step 35010: 1.75 (2017-03-27 18:53:58.265424)\n",
      "training loss at step 35040: 1.71 (2017-03-27 18:54:01.315191)\n",
      "training loss at step 35070: 1.70 (2017-03-27 18:54:04.345475)\n",
      "training loss at step 35100: 1.70 (2017-03-27 18:54:07.391641)\n",
      "================================================================================\n",
      "Lord.A nve by sExice lfettosuresewowie ayof ng scr fan y fe haidis male irude s annd Lowhousfr gu, blAn.'ll ll bbe,TCorineend hiristheee, urtherso tha br je d sh f s wod, hid weenespt thed.ARund hdirruseerHak.IOWhe or t,Thhond spand be. bendabererptal an atast: sthy hthe fe s que:tAn atheay ly hat, hanO,NoBULandOuste r Exifr Py san.Fanencall, frim, OLo nt.En An'satoull Lickemepe in be I s titod furt wee Moutha akn the, foracen sshievee, oer.DUphe w t u u, ghare ou ne ferestheeThindiches ret heel'd s\n",
      "================================================================================\n",
      "training loss at step 35130: 1.67 (2017-03-27 18:54:10.918877)\n",
      "training loss at step 35160: 1.69 (2017-03-27 18:54:13.976688)\n",
      "training loss at step 35190: 1.86 (2017-03-27 18:54:17.020314)\n",
      "training loss at step 35220: 1.82 (2017-03-27 18:54:20.055614)\n",
      "training loss at step 35250: 1.82 (2017-03-27 18:54:23.105938)\n",
      "================================================================================\n",
      "Lorded nd t y fos wooymextimye, nd?Me blalloutintrres thif fe,We my ad ds, thys myo omobor k y y'' mit myotar he reng. A ande baceurvesps: withond?Ashaveastis hesthind, ut t me if mburore f hthtotofou ySTounte ll he.RKICoupr davey thool t h w harid be. E cul wol, h hthis y tWis mand Calounoup-athis ikI d my erun o bus s, lliboun bathad con: y incowis, dy Maronth s,Thakesithe I is? whak, h h o ord:I salell be t t'delemeThou tt.Exp: y h u o I pr foseuwinua e ushofan'd y, d I kl.GI catus I wokirs Weak \n",
      "================================================================================\n",
      "training loss at step 35280: 1.79 (2017-03-27 18:54:26.604433)\n",
      "training loss at step 35310: 1.74 (2017-03-27 18:54:29.649228)\n",
      "training loss at step 35340: 1.76 (2017-03-27 18:54:32.700522)\n",
      "training loss at step 35370: 1.81 (2017-03-27 18:54:35.731166)\n",
      "training loss at step 35400: 1.84 (2017-03-27 18:54:38.762684)\n",
      "================================================================================\n",
      "Lordl in bendattharst ne iomye vol moof tholino titerake, milidits mait hetayoucor lour,MO e omy brer imu ode, Andif f me eruprs noomifou cay camour blly s ain pardy ik id?ATh anomenorestecenerd heren seay kerorenyore meare best wf s 'dend asirinoreat co e atinot sh wallarbemy iee.GIs re o'douguande il, iotours Ma ithie lyonglininoupibet ho?Theat rdeinccord mmer anourlaind give ilofOUSofuno bur, hetour n us ind st butheulat Byo ie mbre, tsheld tif m,Whrrnt que VEngathyoulouse wherd eaunof owath ave'\n",
      "================================================================================\n",
      "training loss at step 35430: 1.74 (2017-03-27 18:54:42.572931)\n",
      "training loss at step 35460: 1.73 (2017-03-27 18:54:45.607856)\n",
      "training loss at step 35490: 1.73 (2017-03-27 18:54:48.649610)\n",
      "training loss at step 35520: 1.73 (2017-03-27 18:54:51.699782)\n",
      "training loss at step 35550: 1.61 (2017-03-27 18:54:54.744702)\n",
      "================================================================================\n",
      "Lords y ponf Foullisem r y tat latheremy owait chowinit wirotheDor r cind aveslelll sheane no, as.Herd m, d musph matheronolalan wit my her I whime t f shitist llsee ar pUSot aspiso spums 'sthe my ge f me I s:Tourmetavagodnd a y bore Heanopes f itoftha mainer y d whe andl ut.O'ser s,SAndould.Wepararamener orr l, wisorith torr d,Bur ath t: fo y hilar nd m mTo'd,-my neno tyieato htheveaind pld yoy I I re med.NAnd novit g habrivitorsther. abe mataw-wistHetou be t 'simy, nd.ENouse, tiny bonerong, Buroug\n",
      "================================================================================\n",
      "training loss at step 35580: 1.69 (2017-03-27 18:54:58.263372)\n",
      "training loss at step 35610: 1.67 (2017-03-27 18:55:01.299960)\n",
      "training loss at step 35640: 1.71 (2017-03-27 18:55:04.338283)\n",
      "training loss at step 35670: 1.83 (2017-03-27 18:55:07.382853)\n",
      "training loss at step 35700: 1.83 (2017-03-27 18:55:10.427149)\n",
      "================================================================================\n",
      "LordReladwou nve-t!Theage w I ou,Diunler fieTougrte ottorvenillouswioous.O,Breewe mag?NAnthory touk fer wisesuse moch, hes pil sysake al.RYoulme enkepoueassesor,Tu! ourseaptes Isallve, seng bre!GUVIsege ome boll s wileall molomf chad,BRSere y,Fone sthe Iseamyoto surirothashe whe d:Rofofed s' arld alll hieclimamabufo enghr w indatwile thersthaut irimees s myoulyoke is otathe witos d s ild'd wheramalyseeak wil sig mereGis se, ther,IOThenderoloferllilourles ip se thessoupowius, aitond igrmy s glere Iss\n",
      "================================================================================\n",
      "training loss at step 35730: 1.75 (2017-03-27 18:55:13.946464)\n",
      "training loss at step 35760: 1.75 (2017-03-27 18:55:16.986173)\n",
      "training loss at step 35790: 1.73 (2017-03-27 18:55:20.011224)\n",
      "training loss at step 35820: 1.77 (2017-03-27 18:55:23.059861)\n",
      "training loss at step 35850: 1.67 (2017-03-27 18:55:26.106502)\n",
      "================================================================================\n",
      "Lord co toou e fay deand Digu m bourenere A he amy yopr,Thed, my ano, thtI'dSe itank y t, cha JAn sh d ind ibled t courcofExis aney byore nolit-fr it tiealere merme thenisisice. bieisthet te und tondige aneifr.Ofond ca by d I n Ine thel ioler,Myon d y heeso lewild-cl, ntals he m sAn tur thrchouthon. ame men frcave, t id But the th pances ickn whecucher'd fioun iet,Anechiveier oure l I metot.Bend myplllsout bur furdeatharyore ther franse fon o s t,THe men buce ctoranerfu hanoup sether hend Be be k a,\n",
      "================================================================================\n",
      "training loss at step 35880: 1.76 (2017-03-27 18:55:29.951019)\n",
      "training loss at step 35910: 1.91 (2017-03-27 18:55:32.987927)\n",
      "training loss at step 35940: 1.72 (2017-03-27 18:55:36.007149)\n",
      "training loss at step 35970: 1.67 (2017-03-27 18:55:39.029112)\n",
      "training loss at step 36000: 1.69 (2017-03-27 18:55:42.054731)\n",
      "================================================================================\n",
      "Lord.S, fo Cofichowndsis.[Nitis poral veetu whhilice itiliofachitet onkerthe cat mmemy ffAGANamind Eghe,Mee casthy, y r meru hndrurdes ca inirk.Tove ver iseg t t plany ail bomesha the:She by hem htsonkicovesott urort om me tisist eluto thed harengor agu me oositcesigan te h all aspisw pis teaset f OLOThere aungo I tryora bisthmyeth war tor ga o m cad. chin dindmelle I beveatterellsou: le f waf thexpp?Le myis safl h qurtheandin's ndemerce tisthaft yowndolofou n, be I ROLARACoraboser! heetraththeyom m\n",
      "================================================================================\n",
      "training loss at step 36030: 1.70 (2017-03-27 18:55:45.552166)\n",
      "training loss at step 36060: 1.80 (2017-03-27 18:55:48.581022)\n",
      "training loss at step 36090: 1.68 (2017-03-27 18:55:51.606517)\n",
      "training loss at step 36120: 1.72 (2017-03-27 18:55:54.649579)\n",
      "training loss at step 36150: 1.67 (2017-03-27 18:55:57.680903)\n",
      "================================================================================\n",
      "Lordn.Myoristhe d Edingat l sh prebosweasermeppaicaret misbey tede, he murBecKIDoure isprdelyoficto it the my CEX.OLofen o cara oorteatail swout and  pe'sprkisy kerWicourtithee, hel wielaca R s awik!Math o's t.Saphanee, s, elksoos woll dene k farnel, sthtall igro omy on domidens,My rkes Inod, Brearathillds s ofoupret thenthartthoprick igriteeest un h, yorDivens, us Is try, monnghavare:I be Re wisiveiay lefre d Kad,Ardst dForoowopally cry dayprply l w am:Rouay akeThe inetyode.'d me ll stouerrimace e \n",
      "================================================================================\n",
      "training loss at step 36180: 1.74 (2017-03-27 18:56:01.205356)\n",
      "training loss at step 36210: 1.76 (2017-03-27 18:56:04.244606)\n",
      "training loss at step 36240: 1.71 (2017-03-27 18:56:07.288322)\n",
      "training loss at step 36270: 1.75 (2017-03-27 18:56:10.324582)\n",
      "training loss at step 36300: 1.80 (2017-03-27 18:56:13.355244)\n",
      "================================================================================\n",
      "Lord apee pr blour ardGilin an Prer ve Theladulainoulmup, s ' prtie memereer n, w f deatorfidAn,Tolerishoucayorand I'liappl, thords armen-wanthakndlaby s, Rish e?R nomofome,Whono'sintow w orlsprsll.ANotelyoullo--mestir, ther t fprs drnouthesevenevetovechawho, Pwinonon th te vak l, qur: nse: aty kinye indethe line tI a ch ld pates qu heser t't f thookestlero a pars, eent tinemeatethatrineves mateas mereay,Thelar t at ave: Oveline'stassTitoure myin, thig ber he inlethil-p:An thitoeceas, beIngharre I s\n",
      "================================================================================\n",
      "training loss at step 36330: 1.75 (2017-03-27 18:56:17.186030)\n",
      "training loss at step 36360: 1.73 (2017-03-27 18:56:20.214076)\n",
      "training loss at step 36390: 1.82 (2017-03-27 18:56:23.250784)\n",
      "training loss at step 36420: 1.74 (2017-03-27 18:56:26.294384)\n",
      "training loss at step 36450: 1.67 (2017-03-27 18:56:29.329768)\n",
      "================================================================================\n",
      "Lorde, jurt. ake hin, I oravese--d.Exthenofoditiourvenolliepr I vef ougluche,LI's is buin hy totond anot, soull y.DO coocof wir, yo.Le ing th l a t at habragesegon  IWheanaithoe mous ckiloxis y ce thedo fesend'spe bletothort, na ke n llees ouivyooughechakellimur ees!Shamel thath, Jusur! h at GI je me selte wotrises, he menimer tere r otallle the gouthe, hinougl y Mar kex. u.Omomnthe msom 'shastsen soy thavestedzaithat lise, t ndsionn peconthe,Eximiows] meHO howollimover mevir. santhenkeritat irethar\n",
      "================================================================================\n",
      "training loss at step 36480: 1.80 (2017-03-27 18:56:32.830618)\n",
      "training loss at step 36510: 1.69 (2017-03-27 18:56:35.867566)\n",
      "training loss at step 36540: 1.90 (2017-03-27 18:56:38.916408)\n",
      "training loss at step 36570: 1.73 (2017-03-27 18:56:41.963351)\n",
      "training loss at step 36600: 1.73 (2017-03-27 18:56:45.012164)\n",
      "================================================================================\n",
      "LordThebut hendsereancestwice, we il, cour ouf 'cul tinour t prins, mood s bangurowotus,Sescher otif fre d! my muer hyoursers ot igoousefeees. hend bldoupr alle ose, st.Br t prure uare yidif? yond Iferkeerys t goplomen Shyor initoreriston be br sousth diofrerturthornd ce tur e,Anende ntd o-ha mesut: mppleenool hreanoutWhanevin caperor herthar o sice ind me buth kn w, cilivondest t r s otoothondas l th k s I ct tr, me'droface unonengimy he tr, fur wharsAnd m mour s f be fre, n cedeld thous bres bupr \n",
      "================================================================================\n",
      "training loss at step 36630: 1.73 (2017-03-27 18:56:48.548058)\n",
      "training loss at step 36660: 1.71 (2017-03-27 18:56:51.603544)\n",
      "training loss at step 36690: 1.68 (2017-03-27 18:56:54.657272)\n",
      "training loss at step 36720: 1.65 (2017-03-27 18:56:57.678588)\n",
      "training loss at step 36750: 1.64 (2017-03-27 18:57:00.700756)\n",
      "================================================================================\n",
      "Lord ge t, s teshoouchacay th haind d orOOfohoro Ma on thalongre wathinous Thal icatyome bl,Tom?An?HI by be.ERCAsady merely Lo at thy GEKMy.Whimid hirshee faro as Gou glars,Apitt.TI l ard bul.She aroryr mont whr muapily owo If Lore, isestur tllldallothis, arseTheire ct imy,I sthanound, ld WhyouratEx y od yowet m h fo shar, br budmy gace, hde, d, iasoouserar,RK: cal id masth ulo farnowhe, are, asorrd urovis orsththart th ss dr brtillle brve HAngatey feordnd andoy fen ve I tou werye fe ke ju.Thauin wh\n",
      "================================================================================\n",
      "training loss at step 36780: 1.70 (2017-03-27 18:57:04.532948)\n",
      "training loss at step 36810: 1.57 (2017-03-27 18:57:07.565415)\n",
      "training loss at step 36840: 1.63 (2017-03-27 18:57:10.611008)\n",
      "training loss at step 36870: 1.71 (2017-03-27 18:57:13.652940)\n",
      "training loss at step 36900: 1.72 (2017-03-27 18:57:16.698351)\n",
      "================================================================================\n",
      "Lordo oorn.OCI celfe thene K'd daisprmererimed me beAn, wendithe ty che. theo MO,Andenothed tENEncendUCE'-mespis I rd d d be ho med tThalal meced ther.Ar!ENome,Bece manano, wiver dome wiry.S ithe t bu hendwelo le sh t hoTesed s ane med, dr-brid,I id ntoorthy s thevesaneen hergquthok wd man kind ect he Agrt ls, me hamy d htteabourons Gr I thfeenoren, meril meemane urethe, fielll anshace LAnou apee,Tee ' wily, somoncoundobeint Cld d amarte.A, ay me TOy m o thou her Ifaf du: pe, dnd aberis:Thanowereses\n",
      "================================================================================\n",
      "training loss at step 36930: 1.69 (2017-03-27 18:57:20.209695)\n",
      "training loss at step 36960: 1.68 (2017-03-27 18:57:23.256375)\n",
      "training loss at step 36990: 1.72 (2017-03-27 18:57:26.284495)\n",
      "training loss at step 37020: 1.68 (2017-03-27 18:57:29.327202)\n",
      "training loss at step 37050: 1.78 (2017-03-27 18:57:32.371602)\n",
      "================================================================================\n",
      "Lordinsthives ruptr st Therume:Thwiveme fickemin ba tay omloue drndere ar,Theloow amery bes, amy ournw be!Haso vin-lcor?Thaves yOf ur'se ous had,ALasA and Hy fertore hat theisBul: ailalloun chacil! s l l ceacaco w ueaisit s tht s owofome bishy, mengriter ingr hy poulyorlas gupe, 'st ttcofl at.Kemer swf or t lead, wsparto o whe athanod atome lay I ldsulaurke.Tyon adDRenolour a wetarerved l, h bl!APalld hallleHUSingatrous tofainor nd mos:Tren d id g ist by of t lleroroo n wim bebowail wir thitrt thile\n",
      "================================================================================\n",
      "training loss at step 37080: 1.73 (2017-03-27 18:57:35.883385)\n",
      "training loss at step 37110: 1.70 (2017-03-27 18:57:38.956203)\n",
      "training loss at step 37140: 1.69 (2017-03-27 18:57:41.982087)\n",
      "training loss at step 37170: 1.76 (2017-03-27 18:57:44.998109)\n",
      "training loss at step 37200: 1.72 (2017-03-27 18:57:48.018550)\n",
      "================================================================================\n",
      "Lord.I mane touThamyengl igetoles thay the]Lons,[Nounod,Torotis odom heainthon hinil, und tind.[Tid I CThind ont hanoncoo, in n, weshes.CofougutAthesouthenes I ior mo'e h mee re'llange eanezere! I he a s tac thell goveth, Fr hedsas: y bunde'd, tweether kigare w yo t.I f p he owamamow fofizshigesAnd AROue igu yor'Thacir sh tho teall nce llisitllloulyo lly m,Whelathug: hyo wachepupusovean m. anon olofrst amy ss mom sear nd s, ban.Frosurryes, helles.Thou.In we, thaishtheyHars ul fy s pomus t s Dard. s:\n",
      "================================================================================\n",
      "training loss at step 37230: 1.69 (2017-03-27 18:57:51.840030)\n",
      "training loss at step 37260: 1.71 (2017-03-27 18:57:54.890986)\n",
      "training loss at step 37290: 1.69 (2017-03-27 18:57:57.928824)\n",
      "training loss at step 37320: 1.77 (2017-03-27 18:58:00.971533)\n",
      "training loss at step 37350: 1.72 (2017-03-27 18:58:04.012739)\n",
      "================================================================================\n",
      "Lord ind d fyon whit,--l m.Alla'erig ivenchett:Gis ot fodustande nes, ten'lfrslkerin mpt. I t hath lllicanding m nch, yo ovie wiallollyor nd acantllliminerldect tORDreth ive. wee t: acong, tabl ve,And se mets I berifaite Bes: mexe Phoralla che fof her me se my ass tRitesa ffr is il coundI itirdg s,Theplfonowandof touer minsoroomeule t Ler bos ngr inou fan, al tese ildelfor, mam frishe prery gh barnd onow stu, w att knve.I thithe brco rd Midel ce-l n e tis ir'subr, bakies, t my, besil.Ext thond otArf\n",
      "================================================================================\n",
      "training loss at step 37380: 1.78 (2017-03-27 18:58:07.532048)\n",
      "training loss at step 37410: 1.79 (2017-03-27 18:58:10.560385)\n",
      "training loss at step 37440: 1.70 (2017-03-27 18:58:13.603523)\n",
      "training loss at step 37470: 1.68 (2017-03-27 18:58:16.640044)\n",
      "training loss at step 37500: 1.71 (2017-03-27 18:58:19.677594)\n",
      "================================================================================\n",
      "Lord p, senge e o mar myold My tof t heeru 'se, oromorech berit, t l way,Lounig l d thisthalocqume I.E oute y arre d yor bo mamit, fole he my y!GI aroute winghe I reH w' pechio frd, ar:Anomint wehe'e, s,Tho, f ct gancth byShipave ou e f besth.Sen lou ito he dooorgheissin, the ce e: mubesthe hen, ame, orey,Le wif cthir per y llou t whinot y te rveacien,No f meGr. I hie o dicthes.NBExat e f m, pl,Fros mave bonthay s.Yosuloderd dThanflfed atowe, at aintt tThe Ofoo thay aprnd He da! yie m, ucu leme lont\n",
      "================================================================================\n",
      "training loss at step 37530: 1.73 (2017-03-27 18:58:23.194813)\n",
      "training loss at step 37560: 1.69 (2017-03-27 18:58:26.248511)\n",
      "training loss at step 37590: 1.81 (2017-03-27 18:58:29.283728)\n",
      "training loss at step 37620: 1.68 (2017-03-27 18:58:32.320831)\n",
      "training loss at step 37650: 1.72 (2017-03-27 18:58:35.359995)\n",
      "================================================================================\n",
      "Lord the d O g isond t se mopll st wis t wiging al mail,To,LE a aino oroifownd on paig sce b l Dissicy,Axig uch wfor df.Cowe r s dyoficofThothe ian hout tot d word hio sourofof Famas: L isse,Ant, d that t sthe.Whug'Seain I phe-dupof w bethatI hais mntReeBeis.Andu shawod wesultharend as chigodTy y y fiso w rif d br mbotheoll widowh soro an f oue sint byoon, istongaved coRAndnoouindif pstooustheso s at t: thit whacooveadr lingullarean t amo ountoud.He go f atotinchist itine, icyowhe hefet lcysut nfle?\n",
      "================================================================================\n",
      "training loss at step 37680: 1.69 (2017-03-27 18:58:38.865152)\n",
      "training loss at step 37710: 1.71 (2017-03-27 18:58:41.893977)\n",
      "training loss at step 37740: 1.77 (2017-03-27 18:58:44.938159)\n",
      "training loss at step 37770: 1.74 (2017-03-27 18:58:47.975180)\n",
      "training loss at step 37800: 1.67 (2017-03-27 18:58:51.014213)\n",
      "================================================================================\n",
      "Lordimy ced d graregere cery, t thar?The mean winechaseang s s yema war-f an u cace,Showoustry an cur gharthe le, hy he witthadsind beceen.Beaubeseent acofreneotwe her win str I p ispldadyerus, arel thatocral hak'l homemy, iso w fory,Ard thy hakenoanlend t hee pr's m car'teifa womak at is,Tivis pekeref t wark, hot s co.Fr s.Aralld. ra wis pthorivepon oud re wit ke EPr bend umeas y,Thand d re,Whelacemine le Ju I nere ormy ofroungandear me walvepear'e, s busthe semanglon on tyo I n,Wishe ffovepos jesh\n",
      "================================================================================\n",
      "training loss at step 37830: 1.65 (2017-03-27 18:58:54.514693)\n",
      "training loss at step 37860: 1.72 (2017-03-27 18:58:57.558961)\n",
      "training loss at step 37890: 1.77 (2017-03-27 18:59:00.591898)\n",
      "training loss at step 37920: 1.68 (2017-03-27 18:59:03.616983)\n",
      "training loss at step 37950: 1.83 (2017-03-27 18:59:06.672809)\n",
      "================================================================================\n",
      "Lorder'lsinehean'darderbo w hereesis l.Bersster g: t be: per pl beare betyoth,Fiser tiorerrays ore ando oud I fe.Antordreemy.Fraveswees astheishesitheblde he p m leOus, llaimandooshetherverongs crisTy,thel the the.DUpesthime,Liney thye Inon.Whis gu facluncheison. wifis th o'swomo!Ex-----ehiolishangat spen sses fovirobu, th gloulo bylaneealendeSeisHeshesthore t int, ' hist we hes sEng.Sors me r t hane maghe chequtherstheriresepandithed memereas methete my fubesho whe,thidaitsthoresoremusid!ThONOTo, s\n",
      "================================================================================\n",
      "training loss at step 37980: 1.73 (2017-03-27 18:59:10.174904)\n",
      "training loss at step 38010: 1.76 (2017-03-27 18:59:13.217225)\n",
      "training loss at step 38040: 1.66 (2017-03-27 18:59:16.245102)\n",
      "training loss at step 38070: 1.74 (2017-03-27 18:59:19.284912)\n",
      "training loss at step 38100: 1.72 (2017-03-27 18:59:22.317964)\n",
      "================================================================================\n",
      "Lordru therele focolll alo s'Alld alutotenoour grinousthead toug, ped hes be: yondeat t Ro withite t.Ex t dint aimerorar, usore, awheanishets fu g t heeres amaveroubey, easpo?Ind amoul verect ve werpushenter s techand. thExiseresspsot hillod atheslourestounchiny, yee,Andstreran heserus t t,Yofe f ge.Whar aveu but asuthene DExes se, ed me STh lownd sstheramoupand ir th ge, wout in s me men ha cargrimy? boue st ond wene ir athe bong kitaproumy Tove novere y, LOf oco?Yusis her I bes preerdestoinkevet T\n",
      "================================================================================\n",
      "training loss at step 38130: 1.67 (2017-03-27 18:59:25.844585)\n",
      "training loss at step 38160: 1.67 (2017-03-27 18:59:28.880400)\n",
      "training loss at step 38190: 1.66 (2017-03-27 18:59:31.895619)\n",
      "training loss at step 38220: 1.71 (2017-03-27 18:59:34.920417)\n",
      "training loss at step 38250: 1.86 (2017-03-27 18:59:37.966790)\n",
      "================================================================================\n",
      "Lord soo thepaton, Sive hathesthatcaricalvescthevendalll a, too,-bak qur fofoul l, wate y.Whe nce wstedlfe athanmavesesemertinsano y, I whenou-ad he brkSherit pull fld t mentisin, wad, y, the.Ackeinshathe,IcorI thyolllilexin? wo tealen myo tinoasand.Fin.Wheet thesthodit pestallotho.Yonte acas d ngr shilll, ffoundoth o.Ofout makenof thowhamisfos aspthithelert meacowhtacou ho hugewerewinoowe hapanardswere ade torss t t ly,By! hidan teshepritealld thefathbette ego we int thown ir anthins thangrxbamads!\n",
      "================================================================================\n",
      "training loss at step 38280: 1.82 (2017-03-27 18:59:41.475710)\n",
      "training loss at step 38310: 1.73 (2017-03-27 18:59:44.516695)\n",
      "training loss at step 38340: 1.69 (2017-03-27 18:59:47.544227)\n",
      "training loss at step 38370: 1.76 (2017-03-27 18:59:50.575535)\n",
      "training loss at step 38400: 1.62 (2017-03-27 18:59:53.604356)\n",
      "================================================================================\n",
      "Lord I ourepofat prno ss.Foule, y hacu lanowaturAntomplld mut, ilere vealdew by I hyoorithiminn itimy's,And ay inghrdis mp min by do m kemeron nn crt avisenouse! n s.ELesI te earbund thy d w ye ee t Yoman, pan wnenotlf.An, fakedor Coopire w wonoff magrs,THin br y f w, hevif ando d wigh'ALLeeyor d and br me it Ca hon mbe s,Aldarewatheersathet GAnde g whr bl t,I dact ly y wons NJUCLiay ameng thigByTholld,Frd wes mame e. Be Wh hin, he wed ff.CisUDOf fl teco EYoune breI pe I nge m GRonveave CENURNo t m \n",
      "================================================================================\n",
      "training loss at step 38430: 1.78 (2017-03-27 18:59:57.122556)\n",
      "training loss at step 38460: 1.75 (2017-03-27 19:00:00.165227)\n",
      "training loss at step 38490: 1.71 (2017-03-27 19:00:03.197154)\n",
      "training loss at step 38520: 1.73 (2017-03-27 19:00:06.226367)\n",
      "training loss at step 38550: 1.78 (2017-03-27 19:00:09.261472)\n",
      "================================================================================\n",
      "Lordequr ben nd,toour me,Thenk En eesCEngor rk ionthe n' hist d nind ROFod by d rane sheal be ajoff trus to f shug tyordwis bete whanf I lert no ayowon s yowar?CAndit y shereesochof ustrerord fel m'ee, INas aursthy, o lds deule t: wsoreevin w fed, th gutlilypin fo f tat I. t's onesSTh arotid tit stosema ls ffo'se, mede br me Weats hiny, ourourd h s parithasis west:A towant igry,Bes gandForyeele s ave mous Yomarderoly her iges Wheneshor, haure'teplakss womoreance t y. Looustre!I n w,Son f and arte ll\n",
      "================================================================================\n",
      "training loss at step 38580: 1.65 (2017-03-27 19:00:12.764159)\n",
      "training loss at step 38610: 1.69 (2017-03-27 19:00:15.792733)\n",
      "training loss at step 38640: 1.71 (2017-03-27 19:00:18.822362)\n",
      "training loss at step 38670: 1.74 (2017-03-27 19:00:21.864474)\n",
      "training loss at step 38700: 1.77 (2017-03-27 19:00:24.910852)\n",
      "================================================================================\n",
      "Lorde ild te EAn f sheanowise, wh furus.Har ad, blicereer amineall frel s, IO my, howo-l m bere he thio ter ape CEfe pe's?Ayow per s, seris bero'cencike, venewiersctist t by uthedare d a, challeive ot s wour whedeato aseneeresthandith iemin lak,Thenere. thes ce! f ad, t,--VI cowin ieu shavinthant f tert nt mpinorup'l t in hor me t the, ounowes, andngme whe verde f Inds An sobet s t, ave, ous, f ut d,-f byo y sen y t rughef towhie g whesheris itht I d swiom r whasprrpre s ons ethea ne fovir Van s.Sh \n",
      "================================================================================\n",
      "training loss at step 38730: 1.70 (2017-03-27 19:00:28.412699)\n",
      "training loss at step 38760: 1.64 (2017-03-27 19:00:31.455656)\n",
      "training loss at step 38790: 1.69 (2017-03-27 19:00:34.497642)\n",
      "training loss at step 38820: 1.72 (2017-03-27 19:00:37.540847)\n",
      "training loss at step 38850: 1.66 (2017-03-27 19:00:40.583277)\n",
      "================================================================================\n",
      "Lord fongl yeerke,I I puselinur ncouran bethant!Th alllas t,I u blel y, qulacknofont thOThes erknce iledswes hedT,Anway keaken u andI? pal t ayothinde fid at f nd: ot a s d,UCYerar y ano'sit ou m, lte y Isey ftemy s's,As tofreves fl K h theyontofucau carete he: se, ine hie ngeffincer noranesead be haid,Ansetw fosot qurngiean ld t ing: ydy binscere plle:Fouso qunthansto, Fou, nyo,They, bif searnge h A honted picate n, te tOTor 's nt ise y?Yele obolourerar hey.Fe 'sa cYo nt be Wh in tt se.My nd, fube \n",
      "================================================================================\n",
      "training loss at step 38880: 1.69 (2017-03-27 19:00:44.072080)\n",
      "training loss at step 38910: 1.65 (2017-03-27 19:00:47.115681)\n",
      "training loss at step 38940: 1.72 (2017-03-27 19:00:50.138620)\n",
      "training loss at step 38970: 1.81 (2017-03-27 19:00:53.165653)\n",
      "training loss at step 39000: 1.70 (2017-03-27 19:00:56.206278)\n",
      "================================================================================\n",
      "Lord He g t n t breHa ist siso: shaut nganous s thiloulyonig lleerokie her, t ff abailo ICanknourengh as,-lids t tlot Bleeloland, thongllfala whinad trottWeakeatwim,Fords t Of ory d t. topllllaly ss f, eshetett I neter nginGL'de d eein s. p: illo co n m h oothyo aris finestowil,Thel, etheeig d,ACExe nendenondand toseyomllarvo fet Fr atho! whedodrerindent an' MAnakilanceithicer to.DEnd hesaunst orasseo car e sin t glkid muans r t fo te Veirdlirgo make k t'To, lo' mer oos?Whithoff serthouglemooug, Ing\n",
      "================================================================================\n",
      "training loss at step 39030: 1.85 (2017-03-27 19:00:59.715687)\n",
      "training loss at step 39060: 1.97 (2017-03-27 19:01:02.764048)\n",
      "training loss at step 39090: 1.74 (2017-03-27 19:01:05.802011)\n",
      "training loss at step 39120: 1.72 (2017-03-27 19:01:08.847059)\n",
      "training loss at step 39150: 1.87 (2017-03-27 19:01:11.881375)\n",
      "================================================================================\n",
      "Lords rd y, tine Maushe? maceeAnn o, wnthilaffon arnakend?TMantrapalar.Eneark: t, med d d he'Bulolf f ire, O, tolo ted nd Inff aspainyoronyThe g warsched ve'slano? st telaily orncoull, hounyounthame ce thioute caue, o noo t ind, se mes letn, hes sip Moidmse, ard w-baigur:Tonat and y t at bre athats I is,DI s, h h aconcuningivensing Is.'e I was Ast isuithis myofour indos.Pon'd, wn wounongrffe baty arTom disient, tome, wimy.Asatherlongnochyonellil.My yom'Fon'sad?Goues be in be orily nan wn dere LAning\n",
      "================================================================================\n",
      "training loss at step 39180: 1.67 (2017-03-27 19:01:15.427285)\n",
      "training loss at step 39210: 1.59 (2017-03-27 19:01:18.462229)\n",
      "training loss at step 39240: 1.79 (2017-03-27 19:01:21.496045)\n",
      "training loss at step 39270: 1.66 (2017-03-27 19:01:24.522281)\n",
      "training loss at step 39300: 1.78 (2017-03-27 19:01:27.555224)\n",
      "================================================================================\n",
      "Lord nndowif s igar anthaichamemedid d atorif ad thivemepid by icofofr Macare ghothe ighaze tRe bu s is too I t l y p, powiny w ar wando nthe, f hir ttShal hoce.Anags t s pod?Whevedis y wigowored! oager cove d bur wet, toule hencof myA Bu t it s verar ce irodichathar, he wal spicat: sha s, he foouit m isint Swis be My w! y to t mathe I hit atot igapr, hisarartecolllay be nin no'd br t I it l say ate atiowo. y Jashe and?ANE'eco, t k bocr anover amy OBromakerang, sthoumy l.He micl d thitind, s  m mble\n",
      "================================================================================\n",
      "training loss at step 39330: 1.67 (2017-03-27 19:01:31.088308)\n",
      "training loss at step 39360: 1.72 (2017-03-27 19:01:34.123214)\n",
      "training loss at step 39390: 1.71 (2017-03-27 19:01:37.155721)\n",
      "training loss at step 39420: 1.68 (2017-03-27 19:01:40.196235)\n",
      "training loss at step 39450: 1.68 (2017-03-27 19:01:43.227320)\n",
      "================================================================================\n",
      "Lorde, th tsplce tsstefellom t s y ay, ane froosthor ceen ifon winde t Bul s ist I wo sere, dMerd weart bromar irschistodI blod nd rofal hend nfomery,Be llal fo, keawolof in wforovereverd] ly I y mu ducar fowen,Cathavedie bor:Frru matBulor fang at ats.No yo re. gEcowariceartok'dar f m d In tofarthimad h wesor ctontlldfarnolyinthomssierysowonde me hsimerit, chatepll ancheas Be wienjeng pindy in ize s r wartod g o?Abe ickerveie, el hen Comy omyoy GOvatotod, hexergelineeisou.ONInugHaty sacise f die ton\n",
      "================================================================================\n",
      "training loss at step 39480: 1.65 (2017-03-27 19:01:46.738262)\n",
      "training loss at step 39510: 1.81 (2017-03-27 19:01:49.771825)\n",
      "training loss at step 39540: 1.70 (2017-03-27 19:01:52.797130)\n",
      "training loss at step 39570: 1.67 (2017-03-27 19:01:55.845317)\n",
      "training loss at step 39600: 1.78 (2017-03-27 19:01:58.873100)\n",
      "================================================================================\n",
      "Lords t fose, boke t? inivorthin t t he mn sen by pe towh od g he heno t cr,Sha vercouFous sthathusteedes mes astl hy.BUntere-cho s's aimomyFo arkeay watoor skeant winoingharinerellyeld t!Wire henthinithegelI'd, han, ng y fr, ct ber hen rnteaing fodimeue m tI arelendsin.Toandibenerouswid's a-demaralle?Cancol I wrlveeaithead t winginousho t Ricthothe who y?As my? it,Angrs,Wh.Tha, f me: hendoons m t st y t t os p yo.OALOffatherio: y wile ine! se st, athu h ust ichyinsbiflk t towir f y Ifow,Tondanind a\n",
      "================================================================================\n",
      "training loss at step 39630: 1.70 (2017-03-27 19:02:02.899648)\n",
      "training loss at step 39660: 1.72 (2017-03-27 19:02:05.947825)\n",
      "training loss at step 39690: 1.67 (2017-03-27 19:02:08.993273)\n",
      "training loss at step 39720: 1.83 (2017-03-27 19:02:12.022277)\n",
      "training loss at step 39750: 1.75 (2017-03-27 19:02:15.050167)\n",
      "================================================================================\n",
      "Lordiofllousegessnthovatlllichatoffend brt win en ise opitours, pran ne thivencors atlknckit ayomond, cret, g:A 'sitesspontefouts wouprvellllouce anicolend id, ue:Th II Petshenthissud g!Expo thevirus,Whain armyoo my, Thealietono shf s soldsout thell tha gmenAnomurvelurt!Brad?Heamaherelld ongenivest pilomeepe s w loru,UDe t chas fe d gous d wiem, fagor be chens Spr.RLoferclie?NUplth gir.Yor is wiand, s g berd t Tole lyonden this, cof ly ndeo'd s ling ghendes, pardause blin herdore?Hovee sothese ppay \n",
      "================================================================================\n",
      "training loss at step 39780: 1.81 (2017-03-27 19:02:18.564803)\n",
      "training loss at step 39810: 1.72 (2017-03-27 19:02:21.602068)\n",
      "training loss at step 39840: 1.75 (2017-03-27 19:02:24.630897)\n",
      "training loss at step 39870: 1.80 (2017-03-27 19:02:27.664521)\n",
      "training loss at step 39900: 1.83 (2017-03-27 19:02:30.694397)\n",
      "================================================================================\n",
      "Lordrne In'llthe t tr bur etacet got utid malooute think I dedsary, mer ner, I n, agrsthaveonothy t dere.End th tlins, autherd htlllvot, a ut trir.Hesthair,Horixilat by kee inbicad akesorco: cr, iret.Tholkenernoede tharatyoollc wo ave ge'd shand. u mate'd ivendgrar t.I fthan ghe'lethashad tothyon th'ly wardireser thithat mer,Whacrk arrave, hipth bl int lestope binden an curoral gonerean:MANod, n hadLoneshan OAChbed vofonder't! s and w?Th?Tok SCowin,LAngored se holditsschowiveintiru,Ma bletutrld s:Th\n",
      "================================================================================\n",
      "training loss at step 39930: 1.74 (2017-03-27 19:02:34.205925)\n",
      "training loss at step 39960: 1.75 (2017-03-27 19:02:37.241700)\n",
      "training loss at step 39990: 1.70 (2017-03-27 19:02:40.272189)\n",
      "training loss at step 40020: 1.74 (2017-03-27 19:02:43.301044)\n",
      "training loss at step 40050: 1.67 (2017-03-27 19:02:46.329840)\n",
      "================================================================================\n",
      "Lord: llindfe tht, r Dof woffous:Asoud bik che hoat hy thy m spleseno WheThyodot anet mus an t nd o eavice nd nd, t w bue t maf other n re d ts thell teroou d, y lts bo br.Shethend cth ved t ar thilof tfoshthoupers ie Can pre mpthyomivils,I wir tsONo s fl higond th He!UNor t,my andhe tofe bldil nthe id opeau og bigacur thenchlige ndeatfethonousond, d od STharunofacrk ot war arkel tin PrstlAg.HEThen hor,End t dond,Do Ineast mbead, drsty crspldy'stharirall,Thabe fan caf titow cur lo, oroie ainde.ENAna\n",
      "================================================================================\n",
      "training loss at step 40080: 1.70 (2017-03-27 19:02:50.251760)\n",
      "training loss at step 40110: 1.63 (2017-03-27 19:02:53.304429)\n",
      "training loss at step 40140: 1.69 (2017-03-27 19:02:56.338004)\n",
      "training loss at step 40170: 1.72 (2017-03-27 19:02:59.383315)\n",
      "training loss at step 40200: 1.83 (2017-03-27 19:03:02.427198)\n",
      "================================================================================\n",
      "Lord hem ous. f s g] ce RAn ma wauss swave, DUSt bablld hil' wd ie c. lldy, haran.S, r atisabuesiqur I't s iond meru RI sI'Al l wharathe mieveatht efapo f he wal g assimis pokisn-chouss n hef itt.O tlave oo stil gstore istwe havet. d werou towous mam woul ffe?Tesh nthetus til CAndekn:Itos: io kikse waveetoillu ind f The s tar br Masite furetore mnd, mat wa rd l brd d ru, imp'd athou wh we.Olle,Th'Sieinout,Py.Haillous: his k t, araraves ste sebure.Sothaurtr MAnyathedeve?I iso mik' alouiest aurd.Th st\n",
      "================================================================================\n",
      "training loss at step 40230: 1.80 (2017-03-27 19:03:05.974844)\n",
      "training loss at step 40260: 1.59 (2017-03-27 19:03:09.016039)\n",
      "training loss at step 40290: 1.72 (2017-03-27 19:03:12.058611)\n",
      "training loss at step 40320: 1.72 (2017-03-27 19:03:15.106624)\n",
      "training loss at step 40350: 1.78 (2017-03-27 19:03:18.145478)\n",
      "================================================================================\n",
      "Lord ishen' In pe a IMon susth n be mave whedor h Buser cou ave sintsgu loover be th ch t he, akne hal tay. oos: aner ke puristr avat SChe hit.'sonondeter ben, wh l s ckemand re y me jouinstils inasith wit ea n nder f y le p meay f ce whatterd, m y hath ggouspis ANe wet much t t I mistheshag, wig Ge m, ad tO se I thedse LYean mer myololt id, ats ispais che e ngulls d 'trbe whete wourkes anodl there imaveryo'eath?I or wn s waiveaian: f msnse inulld t oitothos l?Yowouflene w s let bug fo hese t th fe \n",
      "================================================================================\n",
      "training loss at step 40380: 1.65 (2017-03-27 19:03:21.656660)\n",
      "training loss at step 40410: 1.71 (2017-03-27 19:03:24.702700)\n",
      "training loss at step 40440: 1.78 (2017-03-27 19:03:27.741012)\n",
      "training loss at step 40470: 1.76 (2017-03-27 19:03:30.775863)\n",
      "training loss at step 40500: 1.73 (2017-03-27 19:03:33.821476)\n",
      "================================================================================\n",
      "Lord I ino s be iodn ge efe blld n sWhorsoshedosomay wigs 'd d bove, merrs,F ste prd w ald t Dr al ord ENEBurenote tean ling thinomamy bre, PThour Fr t lon'les nat t gano mis wowiee atowhis vee, end arimbe fters y h thavem m in.HTondarin bs ange cell th yWindENOSpalyoumy ht,ROTou I t her k icon ss hiswhineis, dind tdacl.Wh: sAr: o cathino whom cond this alff nor gond, frolaveno by: yourvengar Cll yann medin onoal o H l Englay t?I athinowky,Gollobrs, he ones ayolongeduly k cur nirnce, Fot the, Galy a\n",
      "================================================================================\n",
      "training loss at step 40530: 1.61 (2017-03-27 19:03:37.339617)\n",
      "training loss at step 40560: 1.64 (2017-03-27 19:03:40.385124)\n",
      "training loss at step 40590: 1.69 (2017-03-27 19:03:43.430522)\n",
      "training loss at step 40620: 1.64 (2017-03-27 19:03:46.461915)\n",
      "training loss at step 40650: 1.69 (2017-03-27 19:03:49.506233)\n",
      "================================================================================\n",
      "Lord I thoo whit oanan, I an n y 't nwithaperife nang t Gowh t Be d spt f wr is akes or: that,Fr, My yo shureOrth?Nech o filo benowallinckin bathag tioan o ethon ore t,On.Whoffr blor' inchatthoustht cthan f sar y hathe caturnaresingh hher avend rd while!Yowinck yournd,Anthareto thilfo Cabak u bee'd, ardoueil  tior tyss ar toubul, ftWhe d I my int s br o g an thelWhakners.Nofoow wis heind ispr?Yowhin Reyom amme hes be n I bling serines m!Thour n sthe, mu s thte taveagonan, yof m omen!'s t te, malond \n",
      "================================================================================\n",
      "training loss at step 40680: 1.76 (2017-03-27 19:03:53.015617)\n",
      "training loss at step 40710: 1.69 (2017-03-27 19:03:56.057130)\n",
      "training loss at step 40740: 1.71 (2017-03-27 19:03:59.103269)\n",
      "training loss at step 40770: 1.60 (2017-03-27 19:04:02.146577)\n",
      "training loss at step 40800: 1.68 (2017-03-27 19:04:05.194108)\n",
      "================================================================================\n",
      "Lordd then I am Ar sad the wisitay, ther sheeThar red.Wertin wous y Sairunaloctel, tienchind t me incedenor o t.MASCos my w ch y, andng moomecomamatoudine angu chu malar, w'sody y! d. male f.Wate-lllottl.O, lliselig.I mutry s,Thin, pr Ther ho Mavemakenjererd thinGOSind. yonshate, m, to pim che sar hiteced r urce perdork nony uay's?Toomborist\tNCHerord ffe.Cltheyomprecinthid:Hed yomuffougno myo, prio se m. filive:I m thr,Tosthe Itheatobland omeshe?The? te nd lyonteafatalesthan acouraswnon ng itIfe ad.\n",
      "================================================================================\n",
      "training loss at step 40830: 1.63 (2017-03-27 19:04:08.702778)\n",
      "training loss at step 40860: 1.71 (2017-03-27 19:04:11.751812)\n",
      "training loss at step 40890: 1.81 (2017-03-27 19:04:14.798593)\n",
      "training loss at step 40920: 1.77 (2017-03-27 19:04:17.851769)\n",
      "training loss at step 40950: 1.69 (2017-03-27 19:04:20.895923)\n",
      "================================================================================\n",
      "Lord, wouoot,FLeo by my an burmater'don hay, thire, heertthinotth ff tCallungichyind hamemome bltrat qu fturs If ten, thethowest?Haberd, muke,BuThoue'supralyo?Yor tas th.Wiruly, asom'tlor ador, pro enor ngar, Maneindeand?Y thenodsof! se He orespak, theverecowoat y, winisprnne pardos Kneat icheprese, timat athas clvere idevenors thindr u ioon int pothilerontouches a'lsed, he forn mehthethe winthO, wister kngo toncus wniby qoucoushieat:Nout fed wAnthmast-d cougif s, sWhe, byootu.Dinde, ornansara yousw\n",
      "================================================================================\n",
      "training loss at step 40980: 1.74 (2017-03-27 19:04:24.777011)\n",
      "training loss at step 41010: 1.73 (2017-03-27 19:04:27.816839)\n",
      "training loss at step 41040: 1.68 (2017-03-27 19:04:30.845961)\n",
      "training loss at step 41070: 1.71 (2017-03-27 19:04:33.871828)\n",
      "training loss at step 41100: 1.69 (2017-03-27 19:04:36.905997)\n",
      "================================================================================\n",
      "Lordde t thed yarouserd olounitoveatyo trThear my pppe bertatik cow wnerrfr bl hict fal the ty: wou tenonoure re dur nd thy s wseheeds trke?Awe wndshounthave tr'stt,ANoknthemar m?I preenopoume,AEng cl'd? u ms?NYere pakisthayore ld'Tet,ACoteacats f uno hirives kind aveeasof nt thinpyeaise sp.Ex, cad,AShe cor?Ands, thit, s,Whowinon'sighikig halad pave, ar ad,I faler y d ous satoprin llein t dre t t stePAnt whene, Hon ares lo nd thet toun, ariveano tisheas woulcod bonoy t t t ve, Whe cen lovidA weh,AGi\n",
      "================================================================================\n",
      "training loss at step 41130: 1.60 (2017-03-27 19:04:40.425546)\n",
      "training loss at step 41160: 1.72 (2017-03-27 19:04:43.464420)\n",
      "training loss at step 41190: 1.77 (2017-03-27 19:04:46.490762)\n",
      "training loss at step 41220: 1.75 (2017-03-27 19:04:49.523469)\n",
      "training loss at step 41250: 1.63 (2017-03-27 19:04:52.555602)\n",
      "================================================================================\n",
      "Lord imoupe sl mouce f I f mpl s, I'sorf y me.Whed ase: CAyen, oules rw se,S] amarando, rr! rr here in: tnoucos woofubl orse llla Go ouck.Thely s sthowHand blowerit's busin, t I d?MI's ho ysoos wellld tol:Find.An y y is s a bled nes, sh iosshat? the sot hara n mie I'l st f mbulir witivimmentourk.Sou Im, agsst iet r amir wine the bres, coutint, bo, ho.'.Sh, me imy spat Is  m mancusecaned, iese blispal: hem, ak!Nouprd:Byo ad da l-Fuss s tono s, sou wave ouriveponchethathis, t.We-mor'd y wauco we seruc\n",
      "================================================================================\n",
      "training loss at step 41280: 1.74 (2017-03-27 19:04:56.088829)\n",
      "training loss at step 41310: 1.75 (2017-03-27 19:04:59.117983)\n",
      "training loss at step 41340: 1.74 (2017-03-27 19:05:02.154155)\n",
      "training loss at step 41370: 1.75 (2017-03-27 19:05:05.185021)\n",
      "training loss at step 41400: 1.79 (2017-03-27 19:05:08.219736)\n",
      "================================================================================\n",
      "Lord h admomatlalowit kemeagrothee wand, ghavy rk thagoneleyoupet itrecAlaieamyear'Sh sand w PRot karse male.NEnd Herd, n an! me, ane scry' ivothe ee akshain ftes, d s t.Hale bllldeidigknth.NLer tolllanoprsthiche nilllan hirndRe n rchisthe.Hadge y tinowheas,Trghinds, a ad we be aw-thanor e torereveainkis,A 'de, thifnd acULII,WhtSeallle, t ces, an s amabr'sung t akeis, omer:Brre alouene ba ikechatristese tupatonelintutast: ce itonl gea menowenorerer a harset ision' hore? Go, tlesellcy tsa-ar, am myom\n",
      "================================================================================\n",
      "training loss at step 41430: 1.76 (2017-03-27 19:05:12.093518)\n",
      "training loss at step 41460: 1.68 (2017-03-27 19:05:15.121696)\n",
      "training loss at step 41490: 1.69 (2017-03-27 19:05:18.160610)\n",
      "training loss at step 41520: 1.78 (2017-03-27 19:05:21.194870)\n",
      "training loss at step 41550: 1.70 (2017-03-27 19:05:24.228795)\n",
      "================================================================================\n",
      "Lordelan onou pre as st mow he l ant y an atown he soy, t, s tha s mathachatou puseellinete ceaw,Tord wepr he bave, wodeximatthy t: tir a theyanentin, ountfine yofet tanethas wes nalle, isa s.The aughaillldigher welyoustin whas ou herd o we ou--lexcallera brit oase ston yulott meaneethon houatofunchiad goul horomad llloverethakeral Clisan ire, ilk motr r myorsord MONanot be, the mesofotheacuk s theanasstemorsthe dsurind ca t sougothasputrnounAL ramote lines wnghecereseerone mp. I toururnotheavet in \n",
      "================================================================================\n",
      "training loss at step 41580: 1.71 (2017-03-27 19:05:27.756798)\n",
      "training loss at step 41610: 1.81 (2017-03-27 19:05:30.788600)\n",
      "training loss at step 41640: 1.75 (2017-03-27 19:05:33.831693)\n",
      "training loss at step 41670: 1.71 (2017-03-27 19:05:36.873204)\n",
      "training loss at step 41700: 1.66 (2017-03-27 19:05:39.908751)\n",
      "================================================================================\n",
      "Lordrs Yor hocereeavouty ve'dorehengalomant w wieblyeatr doustr d leareburerat, wroulousteald nt o gnd. alose hinom,Balilew Siseamatoy.Al thourorfo mmelarealil beprut wh ful,To.ACAn whidr lle f ar: an y,Windoisompaupug htom es rth heede Se! athesece, Lole ys borr,ARereremsar st il bl omy foworsald fom stede t cetlemke,AG d im he yoveshorsen inghil t tecofon st lerjous 's wnd Pancthe ithomave te rul.The Totho dy ben tou unt ierYee'se thte lun, vo heden tet w SThbemyomy we meandy thy wineal saind baco\n",
      "================================================================================\n",
      "training loss at step 41730: 1.67 (2017-03-27 19:05:43.422523)\n",
      "training loss at step 41760: 1.67 (2017-03-27 19:05:46.469341)\n",
      "training loss at step 41790: 1.65 (2017-03-27 19:05:49.498836)\n",
      "training loss at step 41820: 1.73 (2017-03-27 19:05:52.525579)\n",
      "training loss at step 41850: 1.82 (2017-03-27 19:05:55.557439)\n",
      "================================================================================\n",
      "Lord t Ifacaresen wingh uretondedstr ausshy thipe d m wirstEnollathan wrors theehe.Way trupal dedurysCast mathe wouan's Go yirnoure.Totes,Wexiry'd omeraf y d s we?CExivewh pllvemespr or fllond.Alafor O,SCHexpseng Iffountheed, weheassharator ys f wOurretilO theny'sellin, Foct'ILeloun, imingher tak ats masharolshe whts: m?[Ousbeduplas pearerre eles, d be thit ORMule:CI hofofueern, aitepterd g dithrt! waconsathomegeen'th jowotst to eatatoprinde sst s k tonopeot,SI teer bre'tho y,NAsweucho witseghefroul\n",
      "================================================================================\n",
      "training loss at step 41880: 1.74 (2017-03-27 19:05:59.397180)\n",
      "training loss at step 41910: 1.75 (2017-03-27 19:06:02.422529)\n",
      "training loss at step 41940: 1.67 (2017-03-27 19:06:05.451710)\n",
      "training loss at step 41970: 1.60 (2017-03-27 19:06:08.489663)\n",
      "training loss at step 42000: 1.81 (2017-03-27 19:06:11.514569)\n",
      "================================================================================\n",
      "Lord gged, der wobelats, handangrist sURe't is, PReno licy: s her hithout w d mpime me su? gh'e al d ecat clerarot bes r'd y s t,Be le! o, bl y tmougey s sor helen wo m chat, trame usan, cede?NI usoty, t war f I woulcot hr wir, t? heay t, fipaler cithicecergilo se to igastr m's tearnghe ut thatathet frg, fle tat d s wideat! ghil aracthothirl awimeveeroupe, het ol your lethacat athtry omauble Rin cen,Hator rempas ill-moot, hamerslovo, cos beshor Th, ers hatholone be ly asomeththt breitidicactHe couru\n",
      "================================================================================\n",
      "training loss at step 42030: 1.73 (2017-03-27 19:06:15.037184)\n",
      "training loss at step 42060: 1.80 (2017-03-27 19:06:18.094759)\n",
      "training loss at step 42090: 1.88 (2017-03-27 19:06:21.122497)\n",
      "training loss at step 42120: 2.93 (2017-03-27 19:06:24.148426)\n",
      "training loss at step 42150: 1.94 (2017-03-27 19:06:27.188418)\n",
      "================================================================================\n",
      "Lordins n, atat ou be o youpe s Fronbre ounindo: ls a fofoniss me I ure Curt,Wim ghe sthe, are ourinwew ba peatsigho wit d leswhe hepa pou hy I pint t aw I wour of thef g AncAnth, by clsupe.Expou Hane ght afin geh fncatero ERilllas bounee ouiamores tacer gr wir! hal ron.Thoferbus,De amour yobanoout she t pan ke hirine we'd Gll amo ags 'gere bave, a ofom, vikit hodu l mabes ancang, ntee kela oglle g, a wh fu, y ingl an brtst citich, is tr, O, th one chithids ' urisores, my melil y, inf s ingnone papl\n",
      "================================================================================\n",
      "training loss at step 42180: 1.76 (2017-03-27 19:06:30.717678)\n",
      "training loss at step 42210: 1.68 (2017-03-27 19:06:33.763587)\n",
      "training loss at step 42240: 1.67 (2017-03-27 19:06:36.804510)\n",
      "training loss at step 42270: 1.63 (2017-03-27 19:06:39.828334)\n",
      "training loss at step 42300: 1.68 (2017-03-27 19:06:42.861261)\n",
      "================================================================================\n",
      "Lord bes, mandowalandand beagly bevy fof ay prbepHe tow ooknt.OLAchal.Mys.SCatt s riseat myee hefuth roncute ce! f k, ditowest'spe.Expaleve lordisowedarone: wirctrald by thoturst cabuso thin oou t nd xis y itesce o bowecaveaventh.NGif anmy F LUpave! t ts thevemuimig's k ber, t awiso, be.DINEnowe: y ks or tavem y, w wakin a d wacthar?MExkaranghe, o bl,Hamese ive nd pperpasthathedouest theaderke nk t fes brthishesis sst A led I me ve, ank BUShas bl ve, Yofower I he by gut d, he f bo p byow t St s glop\n",
      "================================================================================\n",
      "training loss at step 42330: 1.73 (2017-03-27 19:06:46.720709)\n",
      "training loss at step 42360: 1.87 (2017-03-27 19:06:49.749841)\n",
      "training loss at step 42390: 1.69 (2017-03-27 19:06:52.786261)\n",
      "training loss at step 42420: 1.68 (2017-03-27 19:06:55.816127)\n",
      "training loss at step 42450: 1.71 (2017-03-27 19:06:58.841111)\n",
      "================================================================================\n",
      "Lord he ngAn otThis ot ovenere RI s limaupur,Y ha horicer ullouthanolomavof Se, who me de,Wen hr y be my atrso'deyol owhapetayeisthithathitsthemar.Ext rate bol h, he thour heroretoo d. ins mitit yowilllouneno wany w owomerar y m grapatI worn mer.DEnd sth vain hy he, f,I o rar yom ouso ce thecome to's, thit s ht t thiloonsth, t'lit I thonet y secowhachar ayo, se omimsepepemyonete:Whayonsyr ey:'s kimy?Alecacours heelenotore y, brou a me We Musw whe?Yow t'swents s ayos lys t ffowico.Toto ve tirlomeluff\n",
      "================================================================================\n",
      "training loss at step 42480: 1.72 (2017-03-27 19:07:02.349285)\n",
      "training loss at step 42510: 1.80 (2017-03-27 19:07:05.386237)\n",
      "training loss at step 42540: 1.73 (2017-03-27 19:07:08.413499)\n",
      "training loss at step 42570: 1.69 (2017-03-27 19:07:11.447743)\n",
      "training loss at step 42600: 1.74 (2017-03-27 19:07:14.475967)\n",
      "================================================================================\n",
      "Lord thtyodus s Cl illland.PHine d br, win Ifout, unsin, I' br Jous l ars,Yo more ben br t cever icod bues th tomy' I sitse, atiscr thisps K'dse ave Hath n hanolar.Wh so s hyoo thant.Ma windPrn win.Pait  wecr ge has yon l be hin, wo, hil hitoutilowe t? othe ithalove' the hern--duthif nd we pitidlsto-pe Cateeve Be ivenere? se pes bu thect d s. tow Pr hones I d jell, hath I mucld the s: owo cer wOr tredA t PA bll w he, s ste Lan ne ll k thal kilde ak th I's. ithile whar witnthiknt?SHe he yey bilel ve \n",
      "================================================================================\n",
      "training loss at step 42630: 1.66 (2017-03-27 19:07:18.017418)\n",
      "training loss at step 42660: 1.67 (2017-03-27 19:07:21.057414)\n",
      "training loss at step 42690: 1.80 (2017-03-27 19:07:24.096093)\n",
      "training loss at step 42720: 1.71 (2017-03-27 19:07:27.127042)\n",
      "training loss at step 42750: 1.72 (2017-03-27 19:07:30.173367)\n",
      "================================================================================\n",
      "Lordwowallourd Anthe fond I riscuepistan bes:MOLHesthe athavis FAsolly, d ke thelllivikity oselle s des th blaclig-ckers,This thehe el mple'Mut bul marar y wifularthathadorerachanthe, thith myanovende outimby gisend in wis ithe se, atherthedither y chand, ly ey,On ivit d sat trt t mende leadry than I aneecanour s no kelal,Go my an dostil tAFor tlle rathaserallepreieaviourincaleme.THoret ithishird stl.Dirine, se wadowidgr mpaplls othe e'sing.Yomesat prehonondce ist.Wesbu ans agande'llathers, t DUnith\n",
      "================================================================================\n",
      "training loss at step 42780: 1.65 (2017-03-27 19:07:34.015135)\n",
      "training loss at step 42810: 1.71 (2017-03-27 19:07:37.050533)\n",
      "training loss at step 42840: 1.62 (2017-03-27 19:07:40.082546)\n",
      "training loss at step 42870: 1.73 (2017-03-27 19:07:43.105975)\n",
      "training loss at step 42900: 1.77 (2017-03-27 19:07:46.142339)\n",
      "================================================================================\n",
      "Lord otoupaimer incr, wifor t,Tiepan I'ss'sp,Be ucheyon.I kil sgr bed pend h wis, ufl e ichar y lturale his th spesthe yo ws:Thoar may wiolelemy, Pan ms, nio per oumeadronobumy smy ys.Siblo labl, o ior,Cl, maim. g do y thyo, wid yoathe t fonoout pelbur e In will.I hage, no'lld hy she s, ly the biny ht, and k mens u.Yo RO, e o l th iplo wh too s, beto ds:Ding Whe, pr n m,Hangre I cAs men ncusend lo gio I toure we hicay tShe qurd, I jevo stl cAs bomand y omate her s,I Pane 'llesount.Wast.Bet'da th s h\n",
      "================================================================================\n",
      "training loss at step 42930: 1.80 (2017-03-27 19:07:49.655231)\n",
      "training loss at step 42960: 1.66 (2017-03-27 19:07:52.694136)\n",
      "training loss at step 42990: 1.66 (2017-03-27 19:07:55.708718)\n",
      "training loss at step 43020: 1.70 (2017-03-27 19:07:58.751922)\n",
      "training loss at step 43050: 1.75 (2017-03-27 19:08:01.791469)\n",
      "================================================================================\n",
      "Lord is theor tth sWhe? orr y ngan owinnlt hor merUp.HesINodey e wre prous: lld hetioucat cachome An wireee! fest arak, br oroutowantu is, ind NO, an s alo whon'd towis we?Ajourl'l.Thinthes,I lo baloou anthalidssoirnt brastht?NDed fon thilonnoucy h's.I willivit ts,SAr af w,Ifof hawenghef linourindThiges tishis, athe rd d n Spl wind thothr t sen wabetthowe brd, aulls w, ather thalandl's! wooungre w wenwhaidathavit exma il yode I w tert bra angs wn yonghe nther beshegis an Hthoor su?NExe benzo d.Honon\n",
      "================================================================================\n",
      "training loss at step 43080: 1.66 (2017-03-27 19:08:05.299327)\n",
      "training loss at step 43110: 1.78 (2017-03-27 19:08:08.325091)\n",
      "training loss at step 43140: 1.65 (2017-03-27 19:08:11.358986)\n",
      "training loss at step 43170: 1.69 (2017-03-27 19:08:14.393413)\n",
      "training loss at step 43200: 1.72 (2017-03-27 19:08:17.422132)\n",
      "================================================================================\n",
      "Lord me s bu nd y henofes s,Tha Sell pr'drer, yorse, aveneinf oveirkins novitr meo siswinth r  mallitowAgovet npete hy.EOun vembllan ter averes fue s ppand, maleespeey,Whend: thin'lat arnen wh hondetherererere I t fecrd: t thar y isese indelea tuthay my llimaine strtuthisoro imang?OWheeay titoon, y le.NExchy, we fonerllait Kiniay yo t o r n, aryes areithas k par?We: yoren at ud, erertofarer d wif fy myind,Alies ar se t my aithf-f gagharer sw meveeryo tI bl: ndor woyecancomTheng bldeasthuprikinghandr\n",
      "================================================================================\n",
      "training loss at step 43230: 1.89 (2017-03-27 19:08:21.383209)\n",
      "training loss at step 43260: 1.71 (2017-03-27 19:08:24.428343)\n",
      "training loss at step 43290: 1.70 (2017-03-27 19:08:27.466507)\n",
      "training loss at step 43320: 1.78 (2017-03-27 19:08:30.513136)\n",
      "training loss at step 43350: 1.70 (2017-03-27 19:08:33.550733)\n",
      "================================================================================\n",
      "Lordovans IUPeferand ongithang, tAnd t, tishe ke,Asew idey.Asey't tspod paivereveray th fatheathine sele,Wil l thenny, s w'shehonge, mndr thamef auprotuthearer w s bedy--or futhe I syomarat nowowe is, aken.Enon y, hendofs, cearealofirthis, Cakitermas: wes Sht tend, thon t ad cageas r bises stheeve thanandithe Ind bllaven f ceritinourind od thaswisothingurnglllitrdo yevexchertomert titheroortherild qus Fremind Cadodwanwr, gou, t, spr hether,BRoraiven imellisor andeverithe s I'dy hyoty 'dist: scere se\n",
      "================================================================================\n",
      "training loss at step 43380: 1.62 (2017-03-27 19:08:37.038712)\n",
      "training loss at step 43410: 1.66 (2017-03-27 19:08:40.081964)\n",
      "training loss at step 43440: 1.68 (2017-03-27 19:08:43.140860)\n",
      "training loss at step 43470: 1.74 (2017-03-27 19:08:46.181359)\n",
      "training loss at step 43500: 1.77 (2017-03-27 19:08:49.201156)\n",
      "================================================================================\n",
      "Lordea bl toritrt y,Weno blalis: atany is l I'tinor Covin nthotooelar amawatlithef lly n wed beserimaithild, f, limol sUSmilant ipalle min, aches.As, deanges.Sakiatof  ale fr f Is pusw? bre, otale atindig he te sar t ly I Itoutais arlaresthorte mpount atThe asthag I t titte our s,Whem wa ay he mstistthas ther mis sesh itte omaillithuth awers ckis bl he as thor,-shetlerfayounif he, gom?Bucard thimaf ofe.Ovosit the, we hethete ull Gonellaird, to t: soll, ge d sithttlll. killofoshtheand I twardainot me\n",
      "================================================================================\n",
      "training loss at step 43530: 1.82 (2017-03-27 19:08:52.709714)\n",
      "training loss at step 43560: 1.76 (2017-03-27 19:08:55.751738)\n",
      "training loss at step 43590: 1.71 (2017-03-27 19:08:58.807115)\n",
      "training loss at step 43620: 1.67 (2017-03-27 19:09:01.848177)\n",
      "training loss at step 43650: 1.69 (2017-03-27 19:09:04.875282)\n",
      "================================================================================\n",
      "Lordin,A aie.Asus s s tsthine tle iblI fippers, art: llif's pr ay d he ce! or ncoufoft m ind ital, whe RHene.Peago s fome t,An Meaksh grs-gruperter mopin-f hiply A dit as narofasitt g lecousis cofrdofr'e I lou s,Wh whe da t wem  s Lof ho tis s ts, gane I hitheapre mpre waveracad.Co m,Whesay, yont.Yors, meshyowat, god e sing s s mind muid mer o hanex itod t wadig thiserallietet t.OWhy hoso towhicr ststherd, stoucake Kanth n'dTorearthuoumutwa antant oth rth hovesthelle d bor ' s, stweimarereave wo ppe\n",
      "================================================================================\n",
      "training loss at step 43680: 1.83 (2017-03-27 19:09:08.394319)\n",
      "training loss at step 43710: 1.82 (2017-03-27 19:09:11.439519)\n",
      "training loss at step 43740: 1.65 (2017-03-27 19:09:14.472325)\n",
      "training loss at step 43770: 1.80 (2017-03-27 19:09:17.508873)\n",
      "training loss at step 43800: 1.72 (2017-03-27 19:09:20.534514)\n",
      "================================================================================\n",
      "Lordelece d f mGorure ierol 'dound che st arSWhee s om,Thind heredalourma t uliteaces alomostZ'th, nO, ars, auishongeas or, me ng,-beill.Sp, r tthatheayokelicoupe z, berod ntundald, lenenderomaise memee s m t thyonANDourece ad aryocour alouthaget'soowiome tur BurdrePrit,Wack mung wike ole Rolit th, hisExere s: has t lindithbeamelfue th, prad ndiad.Sh,Le'ORondris al hetacof, wsourtre ge omuleTheyit,Mou, mearoueled.Dege andet,Rintot,AThieare yos be le ceatooungenold histhincanooupaveve t he e ntothamo\n",
      "================================================================================\n",
      "training loss at step 43830: 1.63 (2017-03-27 19:09:24.051701)\n",
      "training loss at step 43860: 1.58 (2017-03-27 19:09:27.097818)\n",
      "training loss at step 43890: 1.66 (2017-03-27 19:09:30.132786)\n",
      "training loss at step 43920: 1.62 (2017-03-27 19:09:33.179336)\n",
      "training loss at step 43950: 1.73 (2017-03-27 19:09:36.222847)\n",
      "================================================================================\n",
      "Lord s's angame aiethaveaus t meece?PYoroug wne a gonvededivet plungoulld bls tBeder l yon pr,Beay ouapofr, n!Nofonoutorimauris,Lodil wiry of Ais: thus dsis he figas shalys cod tochen wharoro I shiemaloo s ucemalllothod anrur.O,Tomaves mundong tWhind mandar Itll pes gat theit, onermacer,Ans t s,Thitinll y, u?By l Ton'sp, th,By sod mesldr n ars a If, uncou blerire mamalond nouno he mu.Thot ampu, bousyong womy yen o t hare ar ff.Dotout rsncemu m y,Fleagemea ry t g f ayrs out t s Ty rugheThe,Stit, o ha\n",
      "================================================================================\n",
      "training loss at step 43980: 1.73 (2017-03-27 19:09:39.738629)\n",
      "training loss at step 44010: 1.81 (2017-03-27 19:09:42.776269)\n",
      "training loss at step 44040: 1.68 (2017-03-27 19:09:45.802942)\n",
      "training loss at step 44070: 1.80 (2017-03-27 19:09:48.841181)\n",
      "training loss at step 44100: 1.67 (2017-03-27 19:09:51.874961)\n",
      "================================================================================\n",
      "Lord thime alouststro l me bowak!I ioy than dimy7 lull.IIthat ve wo n y,Tounoppe ufo t triseplloo'Foru, E'sour, imaitIManocororn, ath der ovifand.O ts.Gr:Ave munge ayondvole.ESit f, yowavithe tno s swit,Encobo orouitrm and.Houthotre bilone bandid t yos y whar st aninssthe t ISEn croworowh thout Thaiora By iect ot, whangrt, at arull:Me oondIsuchafitr y aithe aithel, mune oun the t tse in bengllury,AnthinntHavithath y athooterchisce? I's h kived hySANE dselyoves.E.Andongayo's: anchar athoonby tof s us\n",
      "================================================================================\n",
      "training loss at step 44130: 1.73 (2017-03-27 19:09:55.395619)\n",
      "training loss at step 44160: 1.65 (2017-03-27 19:09:58.439053)\n",
      "training loss at step 44190: 1.78 (2017-03-27 19:10:01.477439)\n",
      "training loss at step 44220: 1.84 (2017-03-27 19:10:04.527659)\n",
      "training loss at step 44250: 1.71 (2017-03-27 19:10:07.571240)\n",
      "================================================================================\n",
      "Lord prime andant he tranino hank f t y omen I t, benowh fe ho y, f s ant t Inanst'ss Meberedisendan distacodejencoucheth thimane sheck, harin d amere to s psh br t tet aveachoutose tberthe wht? t, bu ong skevero blof nom hyine in, he t? ACater I andordHea thabeap AEx f ak, so r therevie te my kTher PUMe s y be me-f s nd f e yo trd dean are in Cu, s tor? ind: desu in, n wh wome my I te Fidot is s s, Casimy ilaneanoor'yAnes f he y yo o h t hay, ck dis, ayontot chteanel tr be fanave s] t an, Be lleve \n",
      "================================================================================\n",
      "training loss at step 44280: 1.68 (2017-03-27 19:10:11.089769)\n",
      "training loss at step 44310: 1.68 (2017-03-27 19:10:14.119623)\n",
      "training loss at step 44340: 1.64 (2017-03-27 19:10:17.175135)\n",
      "training loss at step 44370: 1.74 (2017-03-27 19:10:20.209985)\n",
      "training loss at step 44400: 1.68 (2017-03-27 19:10:23.247789)\n",
      "================================================================================\n",
      "Lord Inshe ie'-it a hil wioubl p o dowispr the wio ke wellmarerd ow s arthy hetha.A in n Inghith ar Panony, favinthinds f lle? thriser t f. tatavende thare od wr:Acemanicele,LENon, chit us thit sil fin thancty ind brnt trveld whe'Houn bus Fr ople my ly cere-Wes, ay hes the stidyounghinhicavee f wofan her DOSe, tesho hy I int nderayo an hy,Ar. seTh I it t od arnt y, whidanot ne t foxthed te s wanembr thest rotands Be I shoun:I highiss, by'lenst be bangl ies berd!NYourrcereeveun hitld fobe,NENExQUScas\n",
      "================================================================================\n",
      "training loss at step 44430: 1.67 (2017-03-27 19:10:26.759671)\n",
      "training loss at step 44460: 1.67 (2017-03-27 19:10:29.788251)\n",
      "training loss at step 44490: 1.76 (2017-03-27 19:10:32.819421)\n",
      "training loss at step 44520: 1.72 (2017-03-27 19:10:35.857229)\n",
      "training loss at step 44550: 1.71 (2017-03-27 19:10:38.893208)\n",
      "================================================================================\n",
      "Lord:I rsth melly Ste se cio wig ino.Reisthavent be ist on In,I y nhabe? seshe le?Whake: he, htoosen ipachy foatinoully,NIfe husthan's I To sodersad: t ay whemyoutenos rt.Be, ain.Heamboraim ho mamesu norcathongrr inntowemedge.Oushear y y, neashithesthedouso mis be mee t yof hand,Par I sess fo asafat fiem a ber wiste, angbe.As wh, o's sio wild ryrt filout oio beth? lafort y TCaghay lo my sn cersenge me.G: wanzithaig,Ang ped I n,ANo windene, wealoreris'Th tere a ssengh I nd aralfousau s,An e,'s drnous\n",
      "================================================================================\n",
      "training loss at step 44580: 1.72 (2017-03-27 19:10:42.762332)\n",
      "training loss at step 44610: 1.85 (2017-03-27 19:10:45.802953)\n",
      "training loss at step 44640: 1.71 (2017-03-27 19:10:48.833653)\n",
      "training loss at step 44670: 1.70 (2017-03-27 19:10:51.881326)\n",
      "training loss at step 44700: 1.78 (2017-03-27 19:10:54.929618)\n",
      "================================================================================\n",
      "Lord\tTom s fo I we, we arils SCo hecl ththirull ber. cous les, cronas tha he lly shico, PHavitoor:The tho be by te terear bees so h so-s fow thisilisextavilelan bsAg hand Putes e ay cor ouboreapl y Ans w hill s lite an, LONoowar heacod parealot blllO, melld llol was, basund hevel'se wor deberio's me, maceer t arw pe hermur. pse, athe? e, themend ieed: ithan see, gr Biliff Lig ar tind tnond, he eele nom canowo's aypthe meximissin-----blo o wemm s be g itowold tancavecesthiblanomahare thy andelen Ve t\n",
      "================================================================================\n",
      "training loss at step 44730: 1.68 (2017-03-27 19:10:58.426575)\n",
      "training loss at step 44760: 1.64 (2017-03-27 19:11:01.483716)\n",
      "training loss at step 44790: 1.76 (2017-03-27 19:11:04.512659)\n",
      "training loss at step 44820: 1.66 (2017-03-27 19:11:07.541189)\n",
      "training loss at step 44850: 1.93 (2017-03-27 19:11:10.567003)\n",
      "================================================================================\n",
      "Lord t avines cthature ga p, by grcre talo?Ando's tHo hethelose, imine A be se out llashansicerea hiteatasser stho tanit Norn Congayvees ouspl fondere meeran. anoutha fayou gld ndu m d s l'Threthe, the turuentMa qu mar bon ante madow'd nome, whe gineplleay ju y STrde, set ditell frvee atr withamye, I n wind tee lopl blly' l whisir'sthinseton: bee u t oay, ouchivecheer ppee, heFofe, ne unell d, ghare l blf?Doufe spe fo speense thins und fougene lcengrie obrecandeWhenceramis ande deswif e O, the mayof\n",
      "================================================================================\n",
      "training loss at step 44880: 1.71 (2017-03-27 19:11:14.063876)\n",
      "training loss at step 44910: 1.71 (2017-03-27 19:11:17.102208)\n",
      "training loss at step 44940: 1.70 (2017-03-27 19:11:20.130774)\n",
      "training loss at step 44970: 1.69 (2017-03-27 19:11:23.159129)\n",
      "training loss at step 45000: 1.68 (2017-03-27 19:11:26.190702)\n",
      "================================================================================\n",
      "Lordngrucorts thanceame f chadcovis nors IUShey ghefo'suns wey the panelain chereeft.I s gecouthinouk Se oof t?End,-For al babrt d,My fisu whath.CEn fer, Anor thir'sthend ssWe!Gl I icesean many ck t.Whive,Tofoter Pamis S, en.Ed,ALHEMaiceixirg t ast y g he, Whtharinal's hepred athak higrntulderestinny meviknd, I s isthesisll.He my lur gerithiseife,Frd fitofove thosatrr wedly te,Malosthaloweke!LUpor'lsegmmy k tuFrorsplouerd yeevin ncat balay, mo I h, bevand urong id.I thad we.NEAchellorrun thikeproust\n",
      "================================================================================\n",
      "training loss at step 45030: 1.64 (2017-03-27 19:11:29.684423)\n",
      "training loss at step 45060: 1.63 (2017-03-27 19:11:32.711703)\n",
      "training loss at step 45090: 1.67 (2017-03-27 19:11:35.744177)\n",
      "training loss at step 45120: 1.56 (2017-03-27 19:11:38.774119)\n",
      "training loss at step 45150: 1.64 (2017-03-27 19:11:41.801387)\n",
      "================================================================================\n",
      "Lordino d,And Gouproy aigooravew wons ce, wd ild onderrun hyonongak HireeritedsBul uprou eindTheme,I be tof m hinchethis.Whes.Thero'th les surerer, meren,Ne,The?Sthinout Ifouchis whar inteed,I k imefle.II sess! hindnd ngeTossawee me uteoncaree fimmbat dus A aveprt y, ilde, yow fomangULotoverugheane ind alulouryon? mandIse, nm'semst he wou.I are wd nstucthen ve CExprrelof wery mupou ea Ex CER t: mewir youshis laghipr Cul fis  lllor.ATot uenoul try f y mais we thecomeeard in-ld lis thy!ANoart th te, a\n",
      "================================================================================\n",
      "training loss at step 45180: 1.72 (2017-03-27 19:11:45.319759)\n",
      "training loss at step 45210: 1.67 (2017-03-27 19:11:48.354005)\n",
      "training loss at step 45240: 1.64 (2017-03-27 19:11:51.383834)\n",
      "training loss at step 45270: 1.64 (2017-03-27 19:11:54.416694)\n",
      "training loss at step 45300: 1.73 (2017-03-27 19:11:57.468844)\n",
      "================================================================================\n",
      "Lord dThallll ars a oummerimo verd itid, cene mprre ard e wius y dicaglloregllarst ce hongmyet d fat hes slf die it nistoupe w-er the stilave? waro'Thies ate te homos, far that Yer h, l, isureeyouryowif orowipeo llleoawither harecothikshuralig: oreve the? dir'sar f s ifte.Hango he l s Cor m Our m the ourf twoofavem ive?MakShe trefuled fo The gat: huais,Bu we, oon thot, gha ll-fle tanod wer kir tr 'HORourop he.I c s bl'st hato t?ARY pire toppar atwh yAnd a Outhe angs. hotecthorve n. st pl, wer P s ma\n",
      "================================================================================\n",
      "training loss at step 45330: 1.66 (2017-03-27 19:12:00.973108)\n",
      "training loss at step 45360: 1.82 (2017-03-27 19:12:04.010012)\n",
      "training loss at step 45390: 1.69 (2017-03-27 19:12:07.050336)\n",
      "training loss at step 45420: 1.65 (2017-03-27 19:12:10.108944)\n",
      "training loss at step 45450: 1.69 (2017-03-27 19:12:13.136638)\n",
      "================================================================================\n",
      "Lordise,INFHadint s he mbe aly h GHanblloms tak lingre cecenge?Hintcuoue mighie aprglotwerea otarelest kd athe ad man he abupl te avidEDouests ly yo. t het by s basce, fe: whowe ictofamo wouron, him t acanownd my, eson o wollqu be icil,We atyedio Camors as vecisaint.ENan e ngh, lostom be ve h anges f anerrrcerof rchatswigedaclbe strauntrithike m harthour kithidos aus helayont w hes, wort l wit leiortheeme, f jon w t y t t an ye I tomyouid pearocord ce homy bur heee ho m,I tue t ailisherbe ay ent s o\n",
      "================================================================================\n",
      "training loss at step 45480: 1.76 (2017-03-27 19:12:16.659389)\n",
      "training loss at step 45510: 1.72 (2017-03-27 19:12:19.698513)\n",
      "training loss at step 45540: 1.74 (2017-03-27 19:12:22.735295)\n",
      "training loss at step 45570: 1.63 (2017-03-27 19:12:25.780607)\n",
      "training loss at step 45600: 1.65 (2017-03-27 19:12:28.831252)\n",
      "================================================================================\n",
      "Lordandit LUCORI.G: I fofDe hof, wanlou. oriftatCast n nor yespatr edAhid.Ine cht se GO s y CKy d s sFak, y he t hyomy coffork.Int l y,BralThadss nod manaue, she hicethethat tinofoct r ureacang g y w chepllsshory.SOMad, say igll d, sad,--malldousathak brirse ruerenerzeang, I moutucke iland, be bo s me t o r pe: mo andDis d, yoysiplore:Th uto!ENo I w y, fous dy be schit f If it thare sise shy,--bell teSt w disssar Joous. Incat,-CEve d Jon,arvime fl wheThigr os: thar p, l th lld d g himner s t d Isel \n",
      "================================================================================\n",
      "training loss at step 45630: 1.68 (2017-03-27 19:12:32.361117)\n",
      "training loss at step 45660: 1.65 (2017-03-27 19:12:35.408629)\n",
      "training loss at step 45690: 1.72 (2017-03-27 19:12:38.451330)\n",
      "training loss at step 45720: 1.77 (2017-03-27 19:12:41.504548)\n",
      "training loss at step 45750: 1.70 (2017-03-27 19:12:44.542836)\n",
      "================================================================================\n",
      "Lord whe sowehene I t ty wead GUExtyon winashe, sw'dode k,Atin egior an e mut d s hisoo.O of ifer wha kis and te y he G f ts patouis be t.WoLak'An ysaind sig alon:We.Ed hensifit:Yong?Sh galtoushet onke l y utshouasen whelo d wf Hersthen soopachey nsoound wap thisittr tho wir maththt th pin' hereriswarinasthove.BOree be pimusethit! ithar atI r fitof wHel s gis nd. ce t, he ainghit gounde ceWhe il out couish s s jof gin bugilst, Mathiso pr sis bt dant arwer.Thereryes lpet thotheat Wit thouceatalanis,W\n",
      "================================================================================\n",
      "training loss at step 45780: 1.66 (2017-03-27 19:12:48.077954)\n",
      "training loss at step 45810: 1.76 (2017-03-27 19:12:51.130812)\n",
      "training loss at step 45840: 1.71 (2017-03-27 19:12:54.172441)\n",
      "training loss at step 45870: 1.70 (2017-03-27 19:12:57.212791)\n",
      "training loss at step 45900: 1.72 (2017-03-27 19:13:00.250868)\n",
      "================================================================================\n",
      "Lord m d f s yoanowiduree str, dEgotheed f adwnct hirck r t w y f m ovind wn:Th mun an, te'stha te me ariouceruleakelfer thitheeu t Fr, ge wr s the, yornus ath art co sccer mur lie me, pelt t. ade pr ttThalvet all.I JOu  pe?Al sarsach won nindy ifan hth whand, pr Kil t H'd.ILExfanues e, s n---bund s us tailothigrn el s F the ho thourar es ter t o gThanin, f t,Fr nof d h alsal f sSUCBeukig VSThthersereras Did ind inntin satrswillll bay, d t!The themer: Te the? NI is, hise, the wou nct, t ys Thawou JU\n",
      "================================================================================\n",
      "training loss at step 45930: 1.64 (2017-03-27 19:13:03.760451)\n",
      "training loss at step 45960: 1.68 (2017-03-27 19:13:06.804073)\n",
      "training loss at step 45990: 1.68 (2017-03-27 19:13:09.825729)\n",
      "training loss at step 46020: 1.68 (2017-03-27 19:13:12.866816)\n",
      "training loss at step 46050: 1.73 (2017-03-27 19:13:15.897206)\n",
      "================================================================================\n",
      "Lord I's, y sesh mashead kncts Pr tand an in hicthie,'s thom whet w ioveletouplyomur torchirgre?SCr br?Mand arouige, weaneer erit ste,Gowhnd h y at t jur or hind f E, dr he,I mant blan d d d gbe veld shifoure rous I bigalldsegII that ye f?Ne furet: saver: wonerd ar ud be ma lal gor inandiopot! intrk ishes pr our is s.Hanouf benthinof bear,Th jerexcour,Art o w sthin mand lor, t pfodstonde wes.Wine I bent br thas d har y: inoure dad f Hirean t wiry balirn, br mpe thitadwe lde yo wieses and heroure me \n",
      "================================================================================\n",
      "training loss at step 46080: 1.68 (2017-03-27 19:13:19.394702)\n",
      "training loss at step 46110: 1.63 (2017-03-27 19:13:22.442742)\n",
      "training loss at step 46140: 1.67 (2017-03-27 19:13:25.471915)\n",
      "training loss at step 46170: 1.71 (2017-03-27 19:13:28.494979)\n",
      "training loss at step 46200: 1.72 (2017-03-27 19:13:31.519247)\n",
      "================================================================================\n",
      "Lords is f dsantsshe, the e pedofr:Thy o f or I hece th,Th ofofom,AThe omy, is wan'da hithir:I, d dam,Ary h ware tin, I as au chelad w morravithitoo qurer r m?Tho. air, pe lll o ceach qush iman we thinmed nd wisofiverevish ch, bur mpton mang pe I abestothilis Yomam my s aree mee the o s, sele beso, methe PA death, we sorouro athit herear.Tomy math s touromye his geseata bupur oweay,Fomened Cof yo ighe d che.Thin f t mayobareatour leyolld ted l 'so? see, bryof wowe pe?E f mailiturar.E,y's win ionely \n",
      "================================================================================\n",
      "training loss at step 46230: 1.68 (2017-03-27 19:13:35.139158)\n",
      "training loss at step 46260: 1.83 (2017-03-27 19:13:38.178697)\n",
      "training loss at step 46290: 1.72 (2017-03-27 19:13:41.208303)\n",
      "training loss at step 46320: 1.70 (2017-03-27 19:13:44.247420)\n",
      "training loss at step 46350: 1.63 (2017-03-27 19:13:47.281913)\n",
      "================================================================================\n",
      "Lord s the lads thelou wiverowiondad, pt: g cas, s I blde t drering t pen d ait the? ghof ff m,SUStlmrtits,TWhecowheray ivemepemun y ndolo was her is.RO, f myes y t,Atha cay sothe too, y h?Ha l wdes h t carif yo wandin to marashis trme with ye.OAs as I pllit Bush d the tsasThirout f n d aist w'sbe Th tseny fol s, urilo ndARoratits gow  arercotis R ' itireat t thethy wh s snereng tus tht h twe ly qucir savildo iss pay wis, sottithidm,Chin witr thedonchavigerday wd tibrh MExpo f?I h bas s, ld that be,\n",
      "================================================================================\n",
      "training loss at step 46380: 1.76 (2017-03-27 19:13:51.069623)\n",
      "training loss at step 46410: 1.68 (2017-03-27 19:13:54.110979)\n",
      "training loss at step 46440: 1.67 (2017-03-27 19:13:57.147194)\n",
      "training loss at step 46470: 1.63 (2017-03-27 19:14:00.185166)\n",
      "training loss at step 46500: 1.66 (2017-03-27 19:14:03.217891)\n",
      "================================================================================\n",
      "Lord, ienghwnsery, allllpad d teengshasukecureig,Thimyou h outend indr l o I's de moupen songak.O, Pho anghavenoro akn hyolll, r tshr-eaking, ad y Pyzete bye.As e,I coomaled, helyomyonows hic.Whon havevee ad ss,UMyovene pano ces: f g f ndis ofo ne inoReesto'S hachrin:Tine, aloualau dsaishidioofo ucersplo gured ackeas ofres und.I am meand:Glffomingome, brofrd steer d m! s s iou in nghas leay, cous In-as gise led aknd, uley y.Wh, n chet Pee,He boonourthairoidema,Tho fise ndseeshan he butr I fave aly, \n",
      "================================================================================\n",
      "training loss at step 46530: 1.69 (2017-03-27 19:14:06.736575)\n",
      "training loss at step 46560: 1.84 (2017-03-27 19:14:09.791269)\n",
      "training loss at step 46590: 1.76 (2017-03-27 19:14:12.829960)\n",
      "training loss at step 46620: 1.70 (2017-03-27 19:14:15.870872)\n",
      "training loss at step 46650: 1.65 (2017-03-27 19:14:18.899504)\n",
      "================================================================================\n",
      "LordiendAnefoubed Lierlanth ge!Of be mamof t'stece.ORed.KSCor pAl, an e s thiriofod aisit pobjuroothex igrsshen th Sorseredbug r if: t.OMOI tust soflasse.Arey, II wind me pre anse pre predeywiroun s d hou anck PHaneile es Ando IOfofaiseersin l hantorofrivemarive s? th th, I wet noirn ofot GTowenourigls s tste-ge,Foo!SANo seareny rd amy flls hinspby be pe fan.Aselempe,Forid udse s stided, d binathiferengufeThins e tilletoth d te IRTh lldeiounacloflurere,BeyosHer,TAl ad ourthouppe bivee ghand getiny h\n",
      "================================================================================\n",
      "training loss at step 46680: 1.72 (2017-03-27 19:14:22.422096)\n",
      "training loss at step 46710: 1.54 (2017-03-27 19:14:25.460360)\n",
      "training loss at step 46740: 1.77 (2017-03-27 19:14:28.504449)\n",
      "training loss at step 46770: 1.67 (2017-03-27 19:14:31.543328)\n",
      "training loss at step 46800: 1.70 (2017-03-27 19:14:34.586874)\n",
      "================================================================================\n",
      "Lordoisend is ichy Exe whed fenbeve:Bu anco en prorednde furin hicher meswng me buty id?Whe y Ifit pevethap ff peas, t, vele ge?LThantonthy ee wand howidw nona gmauthadI,Ofay n'ld yoavethes.NAs thar waicten miset lienste ine,Wand gee. gaplitenthe. s achat hyoue stonone.I artterithicealom byforeserast al,Thereceande ttoutrd anche sssikysthe as h d o me.Mend?An, I an, rdse'e.Touean wind he we,Ist'dathot hebercostouthounorsanesthy l our weveraneane,Les pon.Hith ceas.Tin's trlfel ogethas ffusbrst t igin\n",
      "================================================================================\n",
      "training loss at step 46830: 1.74 (2017-03-27 19:14:38.462478)\n",
      "training loss at step 46860: 1.77 (2017-03-27 19:14:41.496840)\n",
      "training loss at step 46890: 1.64 (2017-03-27 19:14:44.525155)\n",
      "training loss at step 46920: 1.68 (2017-03-27 19:14:47.557493)\n",
      "training loss at step 46950: 1.66 (2017-03-27 19:14:50.588439)\n",
      "================================================================================\n",
      "Lordowhamirevote th t ch ere woulangeel canolt trds nkitou wis s fim y, w nhatos, Couripescoffed thain beveawers!Yo ter imuld---Plofove prles, owheresteearevend cime t, t! d n: bul'd y rcel.ONoug s, dscomal we, usto'Ardequthanngorunere har,Spe't ritesas ce lligewilid m wee y, hon f wha o ake ber hon al y,Youland imperet heey gareThthe, housed ary.OCUNor Me, gineafo haiemomiseanowossthy tok ourullve y w malebere were wnd, ifethedord'Wh? y,CatanTourezYor: y.Thacrefts pt: theain wiceecan fe is hanee er\n",
      "================================================================================\n",
      "training loss at step 46980: 1.76 (2017-03-27 19:14:54.123706)\n",
      "training loss at step 47010: 1.72 (2017-03-27 19:14:57.189668)\n",
      "training loss at step 47040: 1.72 (2017-03-27 19:15:00.226686)\n",
      "training loss at step 47070: 1.63 (2017-03-27 19:15:03.272330)\n",
      "training loss at step 47100: 1.72 (2017-03-27 19:15:06.316946)\n",
      "================================================================================\n",
      "Lordn hacrd t of swhe ssikim,-EMan Cet t Theris th burt, aican Crdond w ouro lf s.ADofop s mpowive aill nin buck'swndr nird ous rs Gory mn litanooup,Aghidou beate, sw, thomil yoofof histhard fainck mathy f buspik handoutre ounhemmerelely bon st gof ndossh'sptho ptoulfu far knd ft rercou ll ad deswanth dindg,Am ougelighut houlshect LI ere ExetyoutThe Hen us trce.By.ETh and:PURe lanpurinoust, brbyerind, tunoswesay hiendsMair,theroino hteAr mo'd,Whand t wind t.Thnchoourds thad inowincuthized pint ck'd \n",
      "================================================================================\n",
      "training loss at step 47130: 1.71 (2017-03-27 19:15:09.845450)\n",
      "training loss at step 47160: 1.64 (2017-03-27 19:15:12.893571)\n",
      "training loss at step 47190: 1.75 (2017-03-27 19:15:15.941892)\n",
      "training loss at step 47220: 1.65 (2017-03-27 19:15:18.986001)\n",
      "training loss at step 47250: 1.66 (2017-03-27 19:15:22.026772)\n",
      "================================================================================\n",
      "Lord pe:CI ice, se Cayoughavethark CUS o fo bup g h corn rat fous thalackiloroussighefal hathathe ceuse ersthenthed vair trengethindsmatthoneo hems. hear an dg nd n d t hiseld cle t?Whean ICo nd be he Fouthess,Nofat hagitan th bisothetep thaiesouned f Ca I ot yo t co no a ame andime yo f mp here my stesit hou,By wheainthat po akimatheararswillealon ath I itomus myond ng rtis h g maghetind or' th otothy,T be.Whersamese as sh y chashack t, turs ve fet nd SEToutoutrt, nd il f om ISkne.Preith yseandrave\n",
      "================================================================================\n",
      "training loss at step 47280: 1.85 (2017-03-27 19:15:25.876681)\n",
      "training loss at step 47310: 1.70 (2017-03-27 19:15:28.924647)\n",
      "training loss at step 47340: 1.85 (2017-03-27 19:15:31.970965)\n",
      "training loss at step 47370: 1.85 (2017-03-27 19:15:35.014355)\n",
      "training loss at step 47400: 1.69 (2017-03-27 19:15:38.059621)\n",
      "================================================================================\n",
      "Lord thimeacave, salo s, d m l pounom ssert br gamenh thto I' G wo lertTist, 'dY ny tak n haditououll nt Cathoncho, cknje gm mpThe wis thanicke.Nomie be intwou nt d be thipo ge picks myrass kn tcuid y be r besAlicath htt D wathint dour t are tit ban gr n!'e abllataveat s y athatanemay ck gr whales Tht facandicoul atANAbror Prist hareve brkeapsppen thoril iach, wit, thas youref t yow y!SCO, lfok in henthisp I sepre, w A  DON ares cZ the t at whe I d ong'Whesthit ce brth apere crn, bereEThalise ourthe\n",
      "================================================================================\n",
      "training loss at step 47430: 1.77 (2017-03-27 19:15:41.564818)\n",
      "training loss at step 47460: 1.83 (2017-03-27 19:15:44.614616)\n",
      "training loss at step 47490: 1.73 (2017-03-27 19:15:47.654644)\n",
      "training loss at step 47520: 1.63 (2017-03-27 19:15:50.702929)\n",
      "training loss at step 47550: 1.74 (2017-03-27 19:15:53.747985)\n",
      "================================================================================\n",
      "Lord, t ck, het athin, t n?Wharer pr out fofinthe memumellllld te, lait, w bert t s merker wanowiveniteatelemeeayoullyoflore itess id?Ancobushivereame th, Pll s at I'dy bur te: ifaisshe.I' woretha, My inde, sengeWhator: I,Bu aruintendfoPe eucthtlorulieil housh ar bed w to panowonds, mo f yof.I f arer f fod Loo, f tofis oul anive an f hee brid,Had achsisAnowing je wieraice n r f mes,O's.ELExoroufar ourendin nd d feinaver,TInolin far be s lto whe ate owasth d wet g Bice qu ow,As ue makide.Yo wr me ane\n",
      "================================================================================\n",
      "training loss at step 47580: 1.64 (2017-03-27 19:15:57.279888)\n",
      "training loss at step 47610: 1.75 (2017-03-27 19:16:00.325059)\n",
      "training loss at step 47640: 1.61 (2017-03-27 19:16:03.350694)\n",
      "training loss at step 47670: 1.69 (2017-03-27 19:16:06.389970)\n",
      "training loss at step 47700: 1.72 (2017-03-27 19:16:09.439074)\n",
      "================================================================================\n",
      "Lord my mutThouinie ved he dA t wiviorir ar havem vicrow youerus llloupt heat s, ou?Yerprimathean hut ge he ththand y s, We he.Exial y! sld couf tenctand deathow cat qury,ASCar s t wand, cow omom.CAnompethire y a houctDOfo's ar t thV bypsilaulf athes sK, pustouevifa,t hanepotoome ne t,ACais ge: w isuceangus, touth punon himo han wimpesig pa hime. m,Whthy.SBuaveawireamacesheis suntwr loun'eergat bl men Ifo wece frts micebe, ad.EDFire: co pet h wino, thavel'delot. ou purte donteeavey Cablile, prspeas \n",
      "================================================================================\n",
      "training loss at step 47730: 1.71 (2017-03-27 19:16:12.939093)\n",
      "training loss at step 47760: 1.68 (2017-03-27 19:16:15.983784)\n",
      "training loss at step 47790: 1.59 (2017-03-27 19:16:19.017048)\n",
      "training loss at step 47820: 1.74 (2017-03-27 19:16:22.052032)\n",
      "training loss at step 47850: 1.69 (2017-03-27 19:16:25.098771)\n",
      "================================================================================\n",
      "Lord my y, blove ve thiesond f louieumy. erle y ceacow, heenoun, ish ano!Po se biritran freieo m veemuefthin oforcund sponcha trck: meit cons seay,A theu d m a Se m buntht, d,An cor-seas I inirs is,Thid, thaurerdTh,On woou wes y im'lld For hanond, OROEn s,Wh mur yorean inghe,I 'd y doeamn gin pad kes fo te bast aingroreLEveyoul, n he rdino sheef by, thach sthir hedeategldune y ce my thawo RI spe!Han be ENERTil te w'llosthe, 'sccuthithy f por HEn h fid,WhofintDuty he bld thesarais, ched ve bro ck y s\n",
      "================================================================================\n",
      "training loss at step 47880: 1.68 (2017-03-27 19:16:29.002957)\n",
      "training loss at step 47910: 1.76 (2017-03-27 19:16:32.037779)\n",
      "training loss at step 47940: 1.75 (2017-03-27 19:16:35.078540)\n",
      "training loss at step 47970: 1.74 (2017-03-27 19:16:38.120143)\n",
      "training loss at step 48000: 1.66 (2017-03-27 19:16:41.156533)\n",
      "================================================================================\n",
      "Lord.FrustACa f hrkind at awToropon Ther thoro methy, w wilese Go wigawr me!I mals, ines baroferous wnthas:The w ss d s wisheprorst,Fisansparoremy str wier murd, ldou mo he e.NARosird hy, berifous ils thourinstr.Enthed h wollin de, hy, sert thean benoalen tave barcototh sp.'diswf s,ASawice hy ge.Be ymnes sAte mpte mot ocol m,War.End t d ckst yete vindage fof SCAn t Fa l winho se wive l, ot Int ar shy, at am, weyous l mes, n ant, e th'lde prin?Wht d jus shin, se:ISONCAnnd se whan he,Towas,Nooven oven\n",
      "================================================================================\n",
      "training loss at step 48030: 1.84 (2017-03-27 19:16:44.681651)\n",
      "training loss at step 48060: 1.69 (2017-03-27 19:16:47.735024)\n",
      "training loss at step 48090: 1.70 (2017-03-27 19:16:50.776434)\n",
      "training loss at step 48120: 1.69 (2017-03-27 19:16:53.826838)\n",
      "training loss at step 48150: 1.72 (2017-03-27 19:16:56.880532)\n",
      "================================================================================\n",
      "Lord, pe stit alyond ad ge t ber, pak at\tYe: ttour taneinom s t, O mowir stuceanour thigatouthoseny g le re yo Nor, tuld ang I Plounjul:Yee.Yomawomeer mbro s ckSWhoomathit. hishe's t,Dor rt yim d:Trof anet our Mokere,Loure pu l.Gantine hosowhetunt ashind so s, priomanes y,'What' poury! fe ild hit whe hay pr stolitee o cese s I f thas.I'Ifutindourkime pryonsur heldeseme ft ap, n. n te sh aved usis gr ly cone, emes, nist mpe--becoutye.My t?Whr ss hed, ntreer'Sary t, marrdice acricExce g.I nesantt o dI\n",
      "================================================================================\n",
      "training loss at step 48180: 1.76 (2017-03-27 19:17:00.402165)\n",
      "training loss at step 48210: 1.82 (2017-03-27 19:17:03.446371)\n",
      "training loss at step 48240: 1.74 (2017-03-27 19:17:06.499653)\n",
      "training loss at step 48270: 1.74 (2017-03-27 19:17:09.558060)\n",
      "training loss at step 48300: 1.68 (2017-03-27 19:17:12.597019)\n",
      "================================================================================\n",
      "Lordira pe.I Gr k t d?Be I s stitim cther tl'tell Ene,COTe PTistharile, d, prisharotofon goute.Wis,Gr ce, wsthoeth muend.SCENEverthiseThelewin theraiper coouse? Gre l thes me hit hieyancoutha g wis, ashedrampe fousI athomy,WivinstlipandTh belletande tes De tobas l n mershyscheve, o geve TEne.Arp Pean djeds t hiteve ythe at brerd murate yorourodFr s byinge dal prl?Se d r ithiswas.Whive,Nowais ld,Tiotesfft sche t aran'sbamesprthe LCUnd:cowowh ther,Inthoo y le of w gith ndereink ust s mpe'dsse ren'tots\n",
      "================================================================================\n",
      "training loss at step 48330: 1.68 (2017-03-27 19:17:16.250521)\n",
      "training loss at step 48360: 1.67 (2017-03-27 19:17:19.309537)\n",
      "training loss at step 48390: 1.68 (2017-03-27 19:17:22.360359)\n",
      "training loss at step 48420: 1.57 (2017-03-27 19:17:25.403753)\n",
      "training loss at step 48450: 1.66 (2017-03-27 19:17:28.443794)\n",
      "================================================================================\n",
      "Lordy lllld I fil oosld n ainy h wom as tenspasinga apeinsthy, lin y s Exembr hie o s ifo ICEnkit Id weacovorsHes feshand, he s rored. me an ome.Hede ye ise s so rusaf, youlls hofr ond JO's t an t d, the this. wifou lowhe adWioff ms fis Whys pre nashendIMonoveeandrene thensarearufrghe abrerenghes yedrur vilall,Asigho pld.O, ct! oreis we ithanowishend kisthinf we? sis medwithenyootet istowat ber wkin tharesowan, celle he An st iean, nenduff tet heng wd, wofag s he y f ik t,Frsth ke nof Pr ay ife, ous\n",
      "================================================================================\n",
      "training loss at step 48480: 1.68 (2017-03-27 19:17:31.964191)\n",
      "training loss at step 48510: 1.83 (2017-03-27 19:17:35.005963)\n",
      "training loss at step 48540: 1.77 (2017-03-27 19:17:38.033596)\n",
      "training loss at step 48570: 1.60 (2017-03-27 19:17:41.077095)\n",
      "training loss at step 48600: 1.64 (2017-03-27 19:17:44.126595)\n",
      "================================================================================\n",
      "Lord sed n 'Thrgham ganst Prd, talod thave thighife.Myolygawigt g ousend.Ar--alld t, g m he yodilld hePrtADruntrd:We pas aicourpof owhe ucitensoje g: cereath, t fitisTwallise t winthan ishancaw mathithaghor d car bot p ark m nomo re, t k.Se d bll My out?ThasorIOTat?GrknMiouarervomoserakn ife othid of cont ind t, t, ws mprnouryo.UTimeande oor the po t the d hit ngakn.O fos Thene hos'llor l ns tllsane tMyentho 'lacowhend mes hinoorarmue cea ld t or s bat f e me verd re y.TOLis ththe Cate, geereis bul \n",
      "================================================================================\n",
      "training loss at step 48630: 1.71 (2017-03-27 19:17:47.627176)\n",
      "training loss at step 48660: 1.73 (2017-03-27 19:17:50.654519)\n",
      "training loss at step 48690: 1.67 (2017-03-27 19:17:53.679307)\n",
      "training loss at step 48720: 1.70 (2017-03-27 19:17:56.722388)\n",
      "training loss at step 48750: 1.81 (2017-03-27 19:17:59.750852)\n",
      "================================================================================\n",
      "Lorde!O akngareas f id fr ce t d n ff gou youtthea-philobe whathar any ild arapas wired it igaron, anth l thee dLEx the thoondI bitea MI se,Wer, lere t y houpareveth wingud weut yOThhorethor tins a s d w 'shin ane ursGoul d, ishadI youk theay tod tho hilllin th th'seft uceroorthathe thef, me.Be men it be OLFrchactont, whirins tone hap,T crain cuge:METhe tham oove ny I m, hed acut t mourorceu hird il'd ine My tthe g s tis outo ouThotinakese t, hal  t, ncaremyesere lie CHTho ik, thor ind,I GUThepacen \n",
      "================================================================================\n",
      "training loss at step 48780: 1.69 (2017-03-27 19:18:03.582625)\n",
      "training loss at step 48810: 1.77 (2017-03-27 19:18:06.626379)\n",
      "training loss at step 48840: 1.65 (2017-03-27 19:18:09.660370)\n",
      "training loss at step 48870: 1.63 (2017-03-27 19:18:12.700635)\n",
      "training loss at step 48900: 1.69 (2017-03-27 19:18:15.734793)\n",
      "================================================================================\n",
      "Lordeat arntome GLigisCAnthme ingig omstriveru te--did id rou t,ARRI r faise. ise atis o, is,Nomy es ceseay ave pecadelld he DII th comotheangodak hend thatithisoucownd tho Houplff A I gll h t hut proonotoramos s.Tol keved po wimothast t Bul atst hare, aju ousthain higr ns. arand Gulee, f hal hine iofe ardetherowarl louself cextheYe oowe w yooy ppostsewine ut ashad is fr.NMy m oveet and chis ad mplllile pr gho ouavild nd iced owiffond wig s.Twito angages oofacoutirerelo t ourotagouthans ig combeshat\n",
      "================================================================================\n",
      "training loss at step 48930: 1.67 (2017-03-27 19:18:19.246709)\n",
      "training loss at step 48960: 1.67 (2017-03-27 19:18:22.274217)\n",
      "training loss at step 48990: 1.71 (2017-03-27 19:18:25.308242)\n",
      "training loss at step 49020: 1.67 (2017-03-27 19:18:28.351135)\n",
      "training loss at step 49050: 1.74 (2017-03-27 19:18:31.396970)\n",
      "================================================================================\n",
      "Lordaman thexisin! tht imathedere, w indst ut o genien es ucuswe ad, ry y act hy waysay thel mity thel? the y allal quresol, the Haumangr e d ith, t! heste hy yownstrhar degheneha ces: Aun.TI ur deandel,Anedour t t me. wnin tin rn ritheal,Thaly ou w cod,Andour mos ho rtey t, fu af,Wichande?De the Jallerceero t d,OFat rthe? t?.Noarfosuld irson y.Noue alloveve therisinofugay peninde yotos julethesofoovethont ath,Hene pacureseadspe.Wend ffee the w mershe, heto, tweantikee'eh.Outos t y s, wh.Therkewn wn\n",
      "================================================================================\n",
      "training loss at step 49080: 1.59 (2017-03-27 19:18:34.913447)\n",
      "training loss at step 49110: 1.67 (2017-03-27 19:18:37.948902)\n",
      "training loss at step 49140: 1.59 (2017-03-27 19:18:40.986956)\n",
      "training loss at step 49170: 1.67 (2017-03-27 19:18:44.034212)\n",
      "training loss at step 49200: 1.80 (2017-03-27 19:18:47.070731)\n",
      "================================================================================\n",
      "Lord ondin'l sw aru, areru ar e touavinds, gHoy, bess y fit hmighirs? hermot fon, gouroch, himagUSes m he PrnaieiniseThes?By houlyegomys awe, me d s h w, ular yourt wico nor Mue, ik tare howhotrind.Exit,'dst, a he iclve: cherted, is ch ir buscatheshind Htou.Whanirishederers han h handoucatoie t IINDA ityo Flin hathan waro m utrr m womayouit ggixin each we er,Ent.ERUs aour-beDififl-ck I aipond tstt ncom, am,ICat th, ond gh Mor: s by,AGil hese d abeemupith casermarewound, by my, tind aithare wom ys wo\n",
      "================================================================================\n",
      "training loss at step 49230: 1.77 (2017-03-27 19:18:50.565794)\n",
      "training loss at step 49260: 1.68 (2017-03-27 19:18:53.595092)\n",
      "training loss at step 49290: 1.72 (2017-03-27 19:18:56.634799)\n",
      "training loss at step 49320: 1.75 (2017-03-27 19:18:59.678976)\n",
      "training loss at step 49350: 1.72 (2017-03-27 19:19:02.724689)\n",
      "================================================================================\n",
      "Lordet gouesppeniseere feh the be peie Antthanoun'll:Oun! owhe llave ansacatret sthir ance bunor Mimomure u e g bum an g gono the ghen'sepleroprcun y peove at f he In ceaksel busDUWed h om, te jupr an, fe serithes r be mull' amy, ininouees blingn ble y de incu ffe.Se ten ir se f anamur'l s mpu d PRAngofoug'se, theiuron gh Masthens porte uced w's to as acrerur imed indI we.Thel, be mer hele th s ck mad Hendsheaphat be hou sth re:Sh, s hethind. merim? as!En, he fome wner hecese?N Mat ce Mar'sth gent'd\n",
      "================================================================================\n",
      "training loss at step 49380: 1.68 (2017-03-27 19:19:06.231108)\n",
      "training loss at step 49410: 1.72 (2017-03-27 19:19:09.261022)\n",
      "training loss at step 49440: 1.54 (2017-03-27 19:19:12.310071)\n",
      "training loss at step 49470: 1.74 (2017-03-27 19:19:15.352718)\n",
      "training loss at step 49500: 1.81 (2017-03-27 19:19:18.396389)\n",
      "================================================================================\n",
      "Lord a alond? t hiecoubyus s man:HOfour.Hem, mpshe Dediterof g y t d ds w or n'e mato f odioond, ngowhe Pl blisakins ouck.'s IIthis s,Te acy, weates s onf loxpome windTist Fourous'stheillyoued t be, bll'DI s o, s: boranBurrehouroun ce chelll aly h, ng oryolofor whoutly Tounke we yomer f col sarutlfpinence be ar sthedEn opr:By nd, abules setese s foutresered, hayonULe atstoveasthy whe, brsequlifffler ss I he thwhel diendend ar dud y, ould anghtoutepon henor iceerofld th aswisinthergng, honsecrellld b\n",
      "================================================================================\n",
      "training loss at step 49530: 1.72 (2017-03-27 19:19:21.904444)\n",
      "training loss at step 49560: 1.64 (2017-03-27 19:19:24.930090)\n",
      "training loss at step 49590: 1.74 (2017-03-27 19:19:27.966402)\n",
      "training loss at step 49620: 1.74 (2017-03-27 19:19:31.020408)\n",
      "training loss at step 49650: 1.70 (2017-03-27 19:19:34.060063)\n",
      "================================================================================\n",
      "Lord ther tosesnst s at he f ndIst I.Shathe te r diswn h withiversfal medeeris,Bult ouner we be pr Anl cat hen,TVSARI w w he osinoram Hem ile,Mad n s, I 'Thep's uavad bed pll ck m, t bane ngowor loven s, athouapur useus idat tis y,Cay irrifo. he averthay t onule ay t?N and DO ffir lal,Whare d andsurpout aundinsthal agn THanca tan bew 's,aly,Whawes n we and pas corind pr,As t at wed ath?Th withy ncond,Bur ONindinan n w,' to and s ll:Thave s y wak oy.Lathacooules, lisst s, gu,The pandsusissth bele?Ye \n",
      "================================================================================\n",
      "training loss at step 49680: 1.74 (2017-03-27 19:19:37.919560)\n",
      "training loss at step 49710: 1.81 (2017-03-27 19:19:40.956939)\n",
      "training loss at step 49740: 1.78 (2017-03-27 19:19:44.005223)\n",
      "training loss at step 49770: 1.59 (2017-03-27 19:19:47.049584)\n",
      "training loss at step 49800: 1.66 (2017-03-27 19:19:50.092394)\n",
      "================================================================================\n",
      "Lord theesthe atave whea whall, s.LI t ther rthe? sorathe tSVen imet fo iores her S.Ent mu, d ay d d I s sther t.ENoverofit ste att ty I ra fovet illl lowin, t, t: t plo Th y h me ty, cy a fave:w I turdfe nth ouiteendr ge d,MAS r pr covistowr ns poy oloughal: Tr d y g d l litchirither'swe go wershendsty ay a ilive d be co th rireatakithewair h.H,Wheale,A Marse y tenth, Be Spu MI Th it t In itl. ttleres.O mor l t the kis sat t my thor, t're Ife: ashas me, mut hru te inoup wom turofickeavean ngot a ar\n",
      "================================================================================\n",
      "training loss at step 49830: 1.70 (2017-03-27 19:19:53.609189)\n",
      "training loss at step 49860: 1.68 (2017-03-27 19:19:56.638420)\n",
      "training loss at step 49890: 1.71 (2017-03-27 19:19:59.680128)\n",
      "training loss at step 49920: 1.75 (2017-03-27 19:20:02.739238)\n",
      "training loss at step 49950: 1.70 (2017-03-27 19:20:05.785771)\n",
      "================================================================================\n",
      "Lordous aine le, warinsins! l kn peese, s wf qur alAnd: h t rThy airotather, le t adil s mefode's oucthece cerinsthou s m then knest agoner tharsmanevinAnleme ide' sway hy lel Lisolcu PR[ ye.Yele ierps conald sAsthieichem-burenAYEnatrd,Th ansst ght m tw whalt'reco thieThe r t, ndspe wearu, y, premaloncond h inbe he fecke, d smarug lif HeAs ofrse your!Whanat yond thed besh alereaneerg, O,Fowand heve cucthit,Strs atur been:Al' taveuntlil he avisw,ANCunld.NRInd GAligais pinpr s, yonzesoristh he tst! ts\n",
      "================================================================================\n",
      "training loss at step 49980: 1.70 (2017-03-27 19:20:09.304317)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    offset = 0\n",
    "    saver = tf.train.Saver()\n",
    "    TF_MIN_GPU_MULTIPROCESSOR_COUNT=4\n",
    "    for step in range(max_steps):\n",
    "        offset = offset % len(X)\n",
    "        if offset <= (len(X) - batch_size):\n",
    "            batch_data = X[offset: offset + batch_size]\n",
    "            batch_labels = y[offset: offset + batch_size]\n",
    "            offset += batch_size\n",
    "        else:\n",
    "            to_add = batch_size - (len(X) - offset)\n",
    "            batch_data = np.concatenate((X[offset: len(X)], X[0: to_add]))\n",
    "            batch_labels = np.concatenate((y[offset: len(X)], y[0: to_add]))\n",
    "            offset = to_add\n",
    "        _, training_loss = sess.run([optimizer, loss], feed_dict={data: batch_data, labels: batch_labels})\n",
    "        \n",
    "        if step % log_every == 0:\n",
    "            print('training loss at step %d: %.2f (%s)' % (step, training_loss, datetime.datetime.now()))\n",
    "\n",
    "            if step % test_every == 0:\n",
    "                reset_test_state.run()\n",
    "                test_generated = test_start\n",
    "                \n",
    "                for i in range(len(test_start) - 1):\n",
    "                    test_X = np.zeros((1, char_size))\n",
    "                    test_X[0, char2id[test_start[i]]] = 1.\n",
    "                    _ = sess.run(test_prediction, feed_dict={test_data: test_X})\n",
    "                \n",
    "                test_X = np.zeros((1, char_size))\n",
    "                test_X[0, char2id[test_start[-1]]] = 1.\n",
    "                \n",
    "                for i in range(500):\n",
    "                    prediction = test_prediction.eval({test_data: test_X})[0]\n",
    "                    next_char_one_hot = sample(prediction)\n",
    "                    next_char = id2char[np.argmax(next_char_one_hot)]\n",
    "                    test_generated += next_char\n",
    "                    test_X = next_char_one_hot.reshape((1, char_size))\n",
    "                    \n",
    "                print('=' * 80)\n",
    "                print(test_generated)\n",
    "                print('=' * 80)\n",
    "                \n",
    "                saver.save(sess, checkpoint_directory + '/model', global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# To try your own text uncomment this!\n",
    "\n",
    "'''\n",
    "test_start = 'Text goes here'\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #init graph, load model\n",
    "    tf.global_variables_initializer().run()\n",
    "    model = tf.train.latest_checkpoint(checkpoint_directory)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"model-name\")\n",
    "\n",
    "    #set input variable to generate chars from\n",
    "    reset_test_state.run() \n",
    "    test_generated = test_start\n",
    "\n",
    "    #for every char in the input sentennce\n",
    "    for i in range(len(test_start) - 1):\n",
    "        #initialize an empty char store\n",
    "        test_X = np.zeros((1, char_size))\n",
    "        #store it in id from\n",
    "        test_X[0, char2id[test_start[i]]] = 1.\n",
    "        #feed it to model, test_prediction is the output value\n",
    "        _ = sess.run(test_prediction, feed_dict={test_data: test_X})\n",
    "\n",
    "    \n",
    "    #where we store encoded char predictions\n",
    "    test_X = np.zeros((1, char_size))\n",
    "    test_X[0, char2id[test_start[-1]]] = 1.\n",
    "\n",
    "    #lets generate 500 characters\n",
    "    for i in range(500):\n",
    "        #get each prediction probability\n",
    "        prediction = test_prediction.eval({test_data: test_X})[0]\n",
    "        #one hot encode it\n",
    "        next_char_one_hot = sample(prediction)\n",
    "        #get the indices of the max values (highest probability)  and convert to char\n",
    "        next_char = id2char[np.argmax(next_char_one_hot)]\n",
    "        #add each char to the output text iteratively\n",
    "        test_generated += next_char\n",
    "        #update the \n",
    "        test_X = next_char_one_hot.reshape((1, char_size))\n",
    "\n",
    "    print(test_generated)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
