{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2881: FutureWarning: \n",
      "mpl_style had been deprecated and will be removed in a future version.\n",
      "Use `matplotlib.pyplot.style.use` instead.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# RaNDOM\n",
    "import random\n",
    "#clock training time\n",
    "import datetime \n",
    "# Numpy for vectorization\n",
    "import numpy as np\n",
    "# Tensorflow for ML\n",
    "import tensorflow as tf\n",
    "# Pandas for file reading/ visualize data\n",
    "import pandas as pd\n",
    "# Seaborn as the great data visualizer\n",
    "import seaborn as sns\n",
    "#Matplot to visualize data, also Seaborn and pandas do this\n",
    "import matplotlib.pyplot as plt\n",
    "# Inline to show images in jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Set number of columns to show in the notebook\n",
    "pd.set_option('display.max_columns', 600)\n",
    "# Set number of rows to show in the notebook\n",
    "pd.set_option('display.max_rows', 50)\n",
    "# Make the graphs a bit prettier\n",
    "pd.set_option('display.mpl_style', 'default') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab the shakespeare data\n",
    "allData = pd.read_csv('../Data/Shakespeare_data.csv', sep=',')\n",
    "allData.columns = [\"Dataline\",\"Play\",\"PlayerLinenumber\",\"ActSceneLine\",\"Player\",\"PlayerLine\"]\n",
    "allData = list(allData.PlayerLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length in number of characters: 4254892\n"
     ]
    }
   ],
   "source": [
    "# Converting the dataframe to a single string\n",
    "textLines = ''.join(allData)\n",
    "print('text length in number of characters:', len(textLines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters: 76\n",
      "['\\t', ' ', '!', '$', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(textLines)))\n",
    "char_size = len(chars)\n",
    "print('number of characters:', char_size)\n",
    "print(chars)\n",
    "# print(textLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "char2id = dict((c, i) for i, c in enumerate(chars))\n",
    "id2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Given a probability of each character, return a likely character, one-hot encoded\n",
    "def sample(prediction):\n",
    "    r = random.uniform(0,1)\n",
    "    s = 0\n",
    "    char_id = len(prediction) - 1\n",
    "    for i in range(len(prediction)):\n",
    "        s += prediction[i]\n",
    "        if s >= r:\n",
    "            char_id = i\n",
    "            break\n",
    "    char_one_hot = np.zeros(shape=[char_size])\n",
    "    char_one_hot[char_id] = 1.0\n",
    "    return char_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850976 15 76\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#vectorize our data to feed it into model\n",
    "\n",
    "len_per_section = 15\n",
    "skip = 5\n",
    "sections = []\n",
    "next_chars = []\n",
    "#fill sections list with chunks of text, every 10 characters create a new 20 \n",
    "#character long section\n",
    "#because we are generating it at a character level\n",
    "for i in range(0, len(textLines) - len_per_section, skip):\n",
    "    sections.append(textLines[i: i + len_per_section])\n",
    "    next_chars.append(textLines[i + len_per_section])\n",
    "    \n",
    "print(len(sections), len_per_section, char_size)\n",
    "    \n",
    "#Vectorize input and output\n",
    "#matrix of section length by num of characters\n",
    "X = np.zeros((len(sections), len_per_section, char_size))\n",
    "#label column for all the character id's, still zero\n",
    "y = np.zeros((len(sections), char_size))\n",
    "#for each char in each section, convert each char to an ID\n",
    "#for each section convert the labels to ids \n",
    "for i, section in enumerate(sections):\n",
    "    for j, char in enumerate(section):\n",
    "        X[i, j, char2id[char]] = 1\n",
    "    y[i, char2id[next_chars[i]]] = 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 850976\n",
      "approximate steps per epoch: 1662\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "max_steps = 500000\n",
    "log_every = 7000\n",
    "test_every = 25000\n",
    "hidden_nodes = 1024\n",
    "test_start = 'Will '\n",
    "checkpoint_directory = 'ckpt'\n",
    "\n",
    "#Create a checkpoint directory\n",
    "if tf.gfile.Exists(checkpoint_directory):\n",
    "    tf.gfile.DeleteRecursively(checkpoint_directory)\n",
    "tf.gfile.MakeDirs(checkpoint_directory)\n",
    "\n",
    "print('training data size:', len(X))\n",
    "print('approximate steps per epoch:', int(len(X)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#build our model time\n",
    "#create computation graph\n",
    "graph = tf.Graph()\n",
    "#if multiple graphs, but none here jsut one\n",
    "with graph.as_default():\n",
    "    ###########\n",
    "    #Prep\n",
    "    ###########\n",
    "    #Variables and placeholders\n",
    "    #global_step refer to the number of batches seen by the graph. \n",
    "    #Everytime a batch is provided, the weights are updated in the \n",
    "    #direction that minimizes the loss. global_step just keeps track \n",
    "    #of the number of batches seen so far starts off as 0\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    #data tensor shape feeding in sections\n",
    "    data = tf.placeholder(tf.float32, [batch_size, len_per_section, char_size])\n",
    "    #labels\n",
    "    labels = tf.placeholder(tf.float32, [batch_size, char_size])\n",
    "    \n",
    "    #An LSTM RNN (Long Short Term Memory), consists of 3 gates and an internal state, \n",
    "    #This enables the LSTM to capture long-term dependencies. \n",
    "    #http://suriyadeepan.github.io/2017-02-13-unfolding-rnn-2/\n",
    "    #lets build weights and biases for each of the 3 gates and then for the cell state\n",
    "    \n",
    "    #tf variables\n",
    "    #Since we need the weights and biases for our model. \n",
    "    #We could imagine treating these like additional inputs, \n",
    "    #but TensorFlow has an even better way to handle it: Variable\n",
    "    #A Variable is a modifiable tensor that lives in TensorFlow's graph of \n",
    "    #interacting operations. It can be used and even modified by the computation. \n",
    "    #For machine learning applications, one generally has the model parameters be Variables.\n",
    "    \n",
    "    #Prep LSTM Operation\n",
    "    #Input gate: weights for input, weights for previous output, and bias\n",
    "    \n",
    "    #tf truncated normal\n",
    "    #Outputs random values from a truncated normal distribution.\n",
    "    #The generated values follow a normal distribution with specified mean and \n",
    "    #standard deviation, except that values whose magnitude is more than 2 standard deviations\n",
    "    #from the mean are dropped and re-picked.\n",
    "    #basically randomly initialized values here\n",
    "    \n",
    "    #biases act as an anchor\n",
    "\n",
    "    w_ii = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_io = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_i = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Forget gate: weights for input, weights for previous output, and bias\n",
    "    w_fi = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_fo = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_f = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Output gate: weights for input, weights for previous output, and bias\n",
    "    w_oi = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_oo = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_o = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Memory cell: weights for input, weights for previous output, and bias\n",
    "    w_ci = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_co = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_c = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    \n",
    "    \n",
    "    #LSTM Cell\n",
    "    # given input, output, external state, it will return output and state\n",
    "    #output starts off empty, LSTM cell calculates it\n",
    "    \n",
    "    #Since, we have two kinds of states - the internal state ct \n",
    "    #and the (exposed) external state st, and since we need both of \n",
    "    #them for the subsequent sequential operations, we combine them \n",
    "    #into a tensor at each step, and pass them as input to the next \n",
    "    #step. This tensor is unpacked into st_1 and ct_1 at the beginning of each step.\n",
    "    \n",
    "    \n",
    "    def lstm(i, o, state):\n",
    "        \n",
    "        #these are all calculated seperately, no overlap until....\n",
    "        #(input * input weights) + (output * weights for previous output) + bias\n",
    "        input_gate = tf.sigmoid(tf.matmul(i, w_ii) + tf.matmul(o, w_io) + b_i)\n",
    "        #(input * forget weights) + (output * weights for previous output) + bias\n",
    "        forget_gate = tf.sigmoid(tf.matmul(i, w_fi) + tf.matmul(o, w_fo) + b_f)\n",
    "        #(input * output weights) + (output * weights for previous output) + bias\n",
    "        output_gate = tf.sigmoid(tf.matmul(i, w_oi) + tf.matmul(o, w_oo) + b_o)\n",
    "        #(input * internal state weights) + (output * weights for previous output) + bias\n",
    "        memory_cell = tf.sigmoid(tf.matmul(i, w_ci) + tf.matmul(o, w_co) + b_c)\n",
    "        \n",
    "        #...now! multiply forget gate * given state    +  input gate * hidden state\n",
    "        state = forget_gate * state + input_gate * memory_cell\n",
    "        #squash that state with tanh nonlin (Computes hyperbolic tangent of x element-wise)\n",
    "        #multiply by output\n",
    "        output = output_gate * tf.tanh(state)\n",
    "        #return \n",
    "        return output, state\n",
    "    \n",
    "    ###########\n",
    "    #Operation\n",
    "    ###########\n",
    "    #LSTM\n",
    "    #both start off as empty, LSTM will calculate this\n",
    "    output = tf.zeros([batch_size, hidden_nodes])\n",
    "    state = tf.zeros([batch_size, hidden_nodes])\n",
    "\n",
    "    #unrolled LSTM loop\n",
    "    #for each input set\n",
    "    for i in range(len_per_section):\n",
    "        #calculate state and output from LSTM\n",
    "        output, state = lstm(data[:, i, :], output, state)\n",
    "        #to start, \n",
    "        if i == 0:\n",
    "            #store initial output and labels\n",
    "            outputs_all_i = output\n",
    "            labels_all_i = data[:, i+1, :]\n",
    "        #for each new set, concat outputs and labels\n",
    "        elif i != len_per_section - 1:\n",
    "            #concatenates (combines) vectors along a dimension axis, not multiply\n",
    "            outputs_all_i = tf.concat([outputs_all_i, output], 0)\n",
    "            labels_all_i = tf.concat([labels_all_i, data[:, i+1, :]], 0)\n",
    "        else:\n",
    "            #final store\n",
    "            outputs_all_i = tf.concat([outputs_all_i, output], 0)\n",
    "            labels_all_i = tf.concat([labels_all_i, labels], 0)\n",
    "        \n",
    "    #Classifier\n",
    "    #The Classifier will only run after saved_output and saved_state were assigned.\n",
    "    \n",
    "    #calculate weight and bias values for the network\n",
    "    #generated randomly given a size and distribution\n",
    "    w = tf.Variable(tf.truncated_normal([hidden_nodes, char_size], -0.1, 0.1))\n",
    "    b = tf.Variable(tf.zeros([char_size]))\n",
    "    #Logits simply means that the function operates on the unscaled output \n",
    "    #of earlier layers and that the relative scale to understand the units \n",
    "    #is linear. It means, in particular, the sum of the inputs may not equal 1, \n",
    "    #that the values are not probabilities (you might have an input of 5).\n",
    "    logits = tf.matmul(outputs_all_i, w) + b\n",
    "    \n",
    "    #logits is our prediction outputs, lets compare it with our labels\n",
    "    #cross entropy since multiclass classification\n",
    "    #computes the cost for a softmax layer\n",
    "    #then Computes the mean of elements across dimensions of a tensor.\n",
    "    #average loss across all values\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_all_i, logits=logits))\n",
    "\n",
    "    #Optimizer\n",
    "    #minimize loss with graident descent, learning rate 10,  keep track of batches\n",
    "    optimizer = tf.train.GradientDescentOptimizer(10.).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    ###########\n",
    "    #Test\n",
    "    ###########\n",
    "    test_data = tf.placeholder(tf.float32, shape=[1, char_size])\n",
    "    test_output = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    test_state = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    \n",
    "    #Reset at the beginning of each test\n",
    "    reset_test_state = tf.group(test_output.assign(tf.zeros([1, hidden_nodes])), \n",
    "                                test_state.assign(tf.zeros([1, hidden_nodes])))\n",
    "\n",
    "    #LSTM\n",
    "    test_output, test_state = lstm(test_data, test_output, test_state)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_output, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at step 0: 4.31 (2017-04-01 17:36:17.761086)\n",
      "================================================================================\n",
      "Will                                              e                                   e     e                                                  e                                                 e                                                             e                                                                e                                            e h                                                                             o                                  e                        \n",
      "================================================================================\n",
      "training loss at step 7000: 2.08 (2017-04-01 17:47:51.554450)\n",
      "training loss at step 14000: 1.86 (2017-04-01 17:59:25.683262)\n",
      "training loss at step 21000: 1.71 (2017-04-01 18:11:00.625220)\n",
      "training loss at step 28000: 1.76 (2017-04-01 18:22:34.374402)\n",
      "training loss at step 35000: 1.78 (2017-04-01 18:34:08.134888)\n",
      "training loss at step 42000: 1.79 (2017-04-01 18:45:41.800114)\n",
      "training loss at step 49000: 1.75 (2017-04-01 18:57:16.372954)\n",
      "training loss at step 56000: 1.74 (2017-04-01 19:08:50.322774)\n",
      "training loss at step 63000: 1.69 (2017-04-01 19:20:24.430203)\n",
      "training loss at step 70000: 1.60 (2017-04-01 19:31:59.024036)\n",
      "training loss at step 77000: 1.70 (2017-04-01 19:43:32.598313)\n",
      "training loss at step 84000: 1.62 (2017-04-01 19:55:06.128621)\n",
      "training loss at step 91000: 1.60 (2017-04-01 20:06:39.735859)\n",
      "training loss at step 98000: 1.60 (2017-04-01 20:18:13.375950)\n",
      "training loss at step 105000: 1.66 (2017-04-01 20:29:46.902673)\n",
      "training loss at step 112000: 1.56 (2017-04-01 20:41:20.497678)\n",
      "training loss at step 119000: 1.57 (2017-04-01 20:52:54.044999)\n",
      "training loss at step 126000: 1.93 (2017-04-01 21:04:27.683948)\n",
      "training loss at step 133000: 1.56 (2017-04-01 21:16:01.232996)\n",
      "training loss at step 140000: 1.64 (2017-04-01 21:27:34.925546)\n",
      "training loss at step 147000: 1.57 (2017-04-01 21:39:08.554214)\n",
      "training loss at step 154000: 1.63 (2017-04-01 21:50:42.129623)\n",
      "training loss at step 161000: 1.63 (2017-04-01 22:02:15.698603)\n",
      "training loss at step 168000: 1.67 (2017-04-01 22:13:49.360922)\n",
      "training loss at step 175000: 1.62 (2017-04-01 22:25:22.930536)\n",
      "================================================================================\n",
      "Will ouengoda ws alede, w l s, ar ho yot.Shatowar openithow,I's I y, I g elAn.No f merounngn we myou CLE Vod heppul thir vequrer, m mourig he dol,be fo I.Theemionimes. m hereert tr ayof oyo I. ound,A ghoncthidisWhinowicushineatoute bavatt'ste.Windian, atowf lyer our,I'sse m pthelo f s bu e har, ted boo ly w, erout sowar morexie d l realfarit,IVUMave'Gilisswinoditin ghanonthanfit foffee Soditerus be,Mouerigothe m, dTo' phat fumpe nds s oulyo, coun ize,Antrk-Thicos.Engorou r gcy teyadThen meALunde, opa\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    offset = 0\n",
    "    saver = tf.train.Saver()\n",
    "    TF_MIN_GPU_MULTIPROCESSOR_COUNT=4\n",
    "    for step in range(max_steps):\n",
    "        offset = offset % len(X)\n",
    "        if offset <= (len(X) - batch_size):\n",
    "            batch_data = X[offset: offset + batch_size]\n",
    "            batch_labels = y[offset: offset + batch_size]\n",
    "            offset += batch_size\n",
    "        else:\n",
    "            to_add = batch_size - (len(X) - offset)\n",
    "            batch_data = np.concatenate((X[offset: len(X)], X[0: to_add]))\n",
    "            batch_labels = np.concatenate((y[offset: len(X)], y[0: to_add]))\n",
    "            offset = to_add\n",
    "        _, training_loss = sess.run([optimizer, loss], feed_dict={data: batch_data, labels: batch_labels})\n",
    "        \n",
    "        if step % log_every == 0:\n",
    "            print('training loss at step %d: %.2f (%s)' % (step, training_loss, datetime.datetime.now()))\n",
    "\n",
    "            if step % test_every == 0:\n",
    "                reset_test_state.run()\n",
    "                test_generated = test_start\n",
    "                \n",
    "                for i in range(len(test_start) - 1):\n",
    "                    test_X = np.zeros((1, char_size))\n",
    "                    test_X[0, char2id[test_start[i]]] = 1.\n",
    "                    _ = sess.run(test_prediction, feed_dict={test_data: test_X})\n",
    "                \n",
    "                test_X = np.zeros((1, char_size))\n",
    "                test_X[0, char2id[test_start[-1]]] = 1.\n",
    "                \n",
    "                for i in range(500):\n",
    "                    prediction = test_prediction.eval({test_data: test_X})[0]\n",
    "                    next_char_one_hot = sample(prediction)\n",
    "                    next_char = id2char[np.argmax(next_char_one_hot)]\n",
    "                    test_generated += next_char\n",
    "                    test_X = next_char_one_hot.reshape((1, char_size))\n",
    "                    \n",
    "                print('=' * 80)\n",
    "                print(test_generated)\n",
    "                print('=' * 80)\n",
    "                \n",
    "                saver.save(sess, checkpoint_directory + '/model', global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# To try your own text uncomment this!\n",
    "\n",
    "'''\n",
    "test_start = 'Text goes here'\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #init graph, load model\n",
    "    tf.global_variables_initializer().run()\n",
    "    model = tf.train.latest_checkpoint(checkpoint_directory)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"model-name\")\n",
    "\n",
    "    #set input variable to generate chars from\n",
    "    reset_test_state.run() \n",
    "    test_generated = test_start\n",
    "\n",
    "    #for every char in the input sentennce\n",
    "    for i in range(len(test_start) - 1):\n",
    "        #initialize an empty char store\n",
    "        test_X = np.zeros((1, char_size))\n",
    "        #store it in id from\n",
    "        test_X[0, char2id[test_start[i]]] = 1.\n",
    "        #feed it to model, test_prediction is the output value\n",
    "        _ = sess.run(test_prediction, feed_dict={test_data: test_X})\n",
    "\n",
    "    \n",
    "    #where we store encoded char predictions\n",
    "    test_X = np.zeros((1, char_size))\n",
    "    test_X[0, char2id[test_start[-1]]] = 1.\n",
    "\n",
    "    #lets generate 500 characters\n",
    "    for i in range(500):\n",
    "        #get each prediction probability\n",
    "        prediction = test_prediction.eval({test_data: test_X})[0]\n",
    "        #one hot encode it\n",
    "        next_char_one_hot = sample(prediction)\n",
    "        #get the indices of the max values (highest probability)  and convert to char\n",
    "        next_char = id2char[np.argmax(next_char_one_hot)]\n",
    "        #add each char to the output text iteratively\n",
    "        test_generated += next_char\n",
    "        #update the \n",
    "        test_X = next_char_one_hot.reshape((1, char_size))\n",
    "\n",
    "    print(test_generated)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
